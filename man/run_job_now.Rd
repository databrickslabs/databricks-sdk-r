% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/jobs.R
\name{run_job_now}
\alias{run_job_now}
\alias{jobsRunNow}
\title{Trigger a new job run.}
\usage{
run_job_now(
  client,
  job_id,
  dbt_commands = NULL,
  idempotency_token = NULL,
  jar_params = NULL,
  job_parameters = NULL,
  notebook_params = NULL,
  pipeline_params = NULL,
  python_named_params = NULL,
  python_params = NULL,
  queue = NULL,
  spark_submit_params = NULL,
  sql_params = NULL
)

jobsRunNow(
  client,
  job_id,
  dbt_commands = NULL,
  idempotency_token = NULL,
  jar_params = NULL,
  job_parameters = NULL,
  notebook_params = NULL,
  pipeline_params = NULL,
  python_named_params = NULL,
  python_params = NULL,
  queue = NULL,
  spark_submit_params = NULL,
  sql_params = NULL
)
}
\arguments{
\item{client}{Required. Instance of DatabricksClient()}

\item{job_id}{Required. The ID of the job to be executed.}

\item{dbt_commands}{An array of commands to execute for jobs with the dbt task, for example \verb{'dbt_commands': ['dbt deps', 'dbt seed', 'dbt run']}.}

\item{idempotency_token}{An optional token to guarantee the idempotency of job run requests.}

\item{jar_params}{A list of parameters for jobs with Spark JAR tasks, for example \verb{'jar_params': ['john doe', '35']}.}

\item{job_parameters}{Job-level parameters used in the run.}

\item{notebook_params}{A map from keys to values for jobs with notebook task, for example \verb{'notebook_params': \{'name': 'john doe', 'age': '35'\}}.}

\item{pipeline_params}{This field has no description yet.}

\item{python_named_params}{A map from keys to values for jobs with Python wheel task, for example \verb{'python_named_params': \{'name': 'task', 'data': 'dbfs:/path/to/data.json'\}}.}

\item{python_params}{A list of parameters for jobs with Python tasks, for example \verb{'python_params': ['john doe', '35']}.}

\item{queue}{The queue settings of the run.}

\item{spark_submit_params}{A list of parameters for jobs with spark submit task, for example \verb{'spark_submit_params': ['--class', 'org.apache.spark.examples.SparkPi']}.}

\item{sql_params}{A map from keys to values for jobs with SQL task, for example \verb{'sql_params': \{'name': 'john doe', 'age': '35'\}}.

See the \href{https://docs.databricks.com/api/workspace/jobs/runnow}{API documentation} for more
information on the request and response field structure.}
}
\description{
Run a job and return the \code{run_id} of the triggered run.
}
