[{"path":[]},{"path":"https://databrickslabs.github.io/databricks-sdk-r/CHANGELOG.html","id":"id_030","dir":"","previous_headings":"","what":"0.3.0","title":"Version changelog","text":"Added github pages (#19). Added pkgdown website (#20). API Changes: Added clusterPoliciesClusterPolicyId() function. Added clusterPoliciesPermissionLevels() function. Added clustersClusterId() function. Added clustersPermissionLevels() function. Added instancePoolsInstancePoolId() function. Added instancePoolsPermissionLevels() function. Changed permissionsSet() function start returning . Changed permissionsUpdate() function start returning . Added usersGetPasswordPermissionLevels() function. Added usersGetPasswordPermissions() function. Added usersSetPasswordPermissions() function. Added usersUpdatePasswordPermissions() function. Added jobsGetJobPermissionLevels() function. Added jobsGetJobPermissions() function. Added jobsSetJobPermissions() function. Added jobsUpdateJobPermissions() function. Added experimentsGetExperimentPermissionLevels() function. Added experimentsGetExperimentPermissions() function. Added experimentsSetExperimentPermissions() function. Added experimentsUpdateExperimentPermissions() function. Added modelRegistryGetRegisteredModelPermissionLevels() function. Added modelRegistryGetRegisteredModelPermissions() function. Added modelRegistrySetRegisteredModelPermissions() function. Added modelRegistryUpdateRegisteredModelPermissions() function. Added pipelinesGetPipelinePermissionLevels() function. Added pipelinesGetPipelinePermissions() function. Added pipelinesSetPipelinePermissions() function. Added pipelinesUpdatePipelinePermissions() function. Added servingEndpointsGetServingEndpointPermissionLevels() function. Added servingEndpointsGetServingEndpointPermissions() function. Added servingEndpointsSetServingEndpointPermissions() function. Added servingEndpointsUpdateServingEndpointPermissions() function. Added tokenManagementGetTokenPermissionLevels() function. Added tokenManagementGetTokenPermissions() function. Added tokenManagementSetTokenPermissions() function. Added tokenManagementUpdateTokenPermissions() function. Added warehousesGetWarehousePermissionLevels() function. Added warehousesGetWarehousePermissions() function. Added warehousesSetWarehousePermissions() function. Added warehousesUpdateWarehousePermissions() function. Added reposGetRepoPermissionLevels() function. Added reposGetRepoPermissions() function. Added reposSetRepoPermissions() function. Added reposUpdateRepoPermissions() function. Added workspacePermissionLevels() function. Added workspaceWorkspaceObjectId() function. OpenAPI SHA: ae082ae8b1bcc0bd41468e5f07810054e05b3dc7, Date: 2023-08-01","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/CHANGELOG.html","id":"id_020","dir":"","previous_headings":"","what":"0.2.0","title":"Version changelog","text":"Adding @export Roxygen, improving visibility (#16). API Changes: OpenAPI SHA: 2ff01e4fb3c2799518dfaff00c986f6737a4a742, Date: 2023-07-19","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/CHANGELOG.html","id":"id_010","dir":"","previous_headings":"","what":"0.1.0","title":"Version changelog","text":"Work towards getting R CMD check passing (#4). Drop renv (#11). Drop @include (#12). Embrace R namespaces (#13). Fix .NeedsOffsetDedupe error (#14). API Changes: Removed metastoresMaintenance() function. Added metastoresEnableOptimization() function. Added tablesUpdate() function. Changed clustersGet() function return . OpenAPI SHA: 0a1949ba96f71680dad30e06973eaae85b1307bb, Date: 2023-07-18","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/CHANGELOG.html","id":"id_001","dir":"","previous_headings":"","what":"0.0.1","title":"Version changelog","text":"Initial rollout","code":""},{"path":[]},{"path":"https://databrickslabs.github.io/databricks-sdk-r/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Developing SDK","title":"Developing SDK","text":"Please read Writing R Extensions manual case difficulties make check.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/CONTRIBUTING.html","id":"installing-tools","dir":"","previous_headings":"","what":"Installing tools","title":"Developing SDK","text":"Start make deps ’re running clean checkout. set dev workstation, install devtools package","code":"pip3 install -U radian  brew install r fribidi libgit2 install.packages(\"devtools\")"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/CONTRIBUTING.html","id":"devloop","dir":"","previous_headings":"","what":"Devloop","title":"Developing SDK","text":"console, execute get error #include <fribidi.h>, brew install fribidi. HTTP client devloop:","code":"library(devtools); load_all(\".\"); load_all(); DatabricksClient(profile = 'demo')$do('GET', '/api/2.0/scim/Me')"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/CONTRIBUTING.html","id":"debugging","dir":"","previous_headings":"Devloop","what":"Debugging","title":"Developing SDK","text":"insert browser() whenever necessary use Q quit interactiv debugging see https://adv-r.hadley.nz/debugging.html","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Serge Smertin. Author, maintainer. Databricks. Copyright holder, funder.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Smertin S (2024). databricks: Databricks SDK R (Experimental). R package version 0.3.0, https://databrickslabs.github.io/databricks-sdk-r/.","code":"@Manual{,   title = {databricks: Databricks SDK for R (Experimental)},   author = {Serge Smertin},   year = {2024},   note = {R package version 0.3.0},   url = {https://databrickslabs.github.io/databricks-sdk-r/}, }"},{"path":[]},{"path":"https://databrickslabs.github.io/databricks-sdk-r/index.html","id":"authentication","dir":"","previous_headings":"","what":"Authentication","title":"Databricks SDK for R (Experimental)","text":"’s recommended authenticate via .Renviron file using DATABRICKS_HOST DATABRICKS_TOKEN environment variables. can also use Databricks CLI Configuration Profiles DATABRICKS_CONFIG_FILE DATABRICKS_CONFIG_PROFILE environment variables, PAT Authentication works moment. need authentication methods, please fork GitHub repository send pull request feature suggestion. Example overriding authentication profile. Look databricks auth profiles know ones working.","code":"client <- DatabricksClient(profile=\"your-cli-profile\")"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/index.html","id":"complete-with-databricks-workspace-level-apis","dir":"","previous_headings":"","what":"Complete with Databricks workspace-level APIs","title":"Databricks SDK for R (Experimental)","text":"Databricks SDK R comes public workspace-level APIs consistent Databricks SDK Python, Databricks SDK Go, Databricks SDK Java. Databricks SDK R expose account-level APIs ’re recommended use Go, Python, Java SDK build account-level automation.","code":"library(dplyr) library(databricks) client <- DatabricksClient() running <- clustersList(client) %>% filter(state == 'RUNNING') context <- commandExecutionCreate(client, cluster_id=running$cluster_id, language='python') res <- commandExecutionExecute(client, cluster_id=running$cluster_id, context_id=context$id, language='sql', command='show tables') res"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/index.html","id":"pagination","dir":"","previous_headings":"","what":"Pagination","title":"Databricks SDK for R (Experimental)","text":"list methods (, return list results), consistently return data.frame entries pages, regardless underlying implementation.","code":"> clustersList(client)[1:10,c(\"cluster_id\", \"cluster_name\", \"state\")]              cluster_id                                      cluster_name      state 1  1109-110110-kjfoeopq                              DEFAULT Test Cluster TERMINATED 2  0110-221212-oqqpodoa                               GO_SDK Test Cluster TERMINATED 3  1109-012301-qlwlwqpq                               BRICKS Test Cluster TERMINATED 4  1109-110012-qpwoepqq                               VSCODE Test Cluster TERMINATED 5  0110-201022-oqooqpqp                               JS_SDK Test Cluster TERMINATED"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/index.html","id":"long-running-operations","dir":"","previous_headings":"","what":"Long-running operations","title":"Databricks SDK for R (Experimental)","text":"long-running operations poll Databricks backend entity reaches desired state:","code":"> clustersCreate(client, spark_version = \"12.x-snapshot-scala2.12\", cluster_name = \"r-sdk-cluster\", num_workers = 1, autotermination_minutes=20, node_type_id=\"i3.xlarge\") PENDING: Finding instances for new nodes, acquiring more instances if necessary"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/index.html","id":"interface-stability","dir":"","previous_headings":"","what":"Interface stability","title":"Databricks SDK for R (Experimental)","text":"API clients services generated specification files synchronized main platform. Databricks may minor documented backward-incompatible changes, renaming methods type names bring consistency.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/index.html","id":"project-support","dir":"","previous_headings":"","what":"Project Support","title":"Databricks SDK for R (Experimental)","text":"Please note projects databrickslabs github space provided exploration , formally supported Databricks Service Level Agreements (SLAs). provided -make guarantees kind. Please submit support ticket relating issues arising use projects. issues discovered use project filed GitHub Issues Repo. reviewed time permits, formal SLAs support.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/DatabricksClient.html","id":null,"dir":"Reference","previous_headings":"","what":"DatabricksClient is a constructor for class that performs any operations with\nDatabricks REST API and handle a subset of Unified Client Authentication. — DatabricksClient","title":"DatabricksClient is a constructor for class that performs any operations with\nDatabricks REST API and handle a subset of Unified Client Authentication. — DatabricksClient","text":"DatabricksClient constructor class performs operations Databricks REST API handle subset Unified Client Authentication.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/DatabricksClient.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DatabricksClient is a constructor for class that performs any operations with\nDatabricks REST API and handle a subset of Unified Client Authentication. — DatabricksClient","text":"","code":"DatabricksClient(profile = NULL, host = NULL, token = NULL, config_file = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/DatabricksClient.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DatabricksClient is a constructor for class that performs any operations with\nDatabricks REST API and handle a subset of Unified Client Authentication. — DatabricksClient","text":"profile configuration profile ~/.databrickscfg. Defaults DEFAULT host URL Databricks Workspace token Personal Access Token config_file path Databricks CLI configuration file. Defaults ~/.databrickscfg","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/accountAccessControlProxyGetAssignableRolesForResource.html","id":null,"dir":"Reference","previous_headings":"","what":"Get assignable roles for a resource. — accountAccessControlProxyGetAssignableRolesForResource","title":"Get assignable roles for a resource. — accountAccessControlProxyGetAssignableRolesForResource","text":"Gets roles can granted account-level resource. role grantable rule set resource can contain access rule role.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/accountAccessControlProxyGetAssignableRolesForResource.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get assignable roles for a resource. — accountAccessControlProxyGetAssignableRolesForResource","text":"","code":"accountAccessControlProxyGetAssignableRolesForResource(client, resource)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/accountAccessControlProxyGetAssignableRolesForResource.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get assignable roles for a resource. — accountAccessControlProxyGetAssignableRolesForResource","text":"client Required. Instance DatabricksClient() resource Required. resource name assignable roles listed.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/accountAccessControlProxyGetRuleSet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a rule set. — accountAccessControlProxyGetRuleSet","title":"Get a rule set. — accountAccessControlProxyGetRuleSet","text":"Get rule set name. rule set always attached resource contains list access rules said resource. Currently default rule set resource supported.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/accountAccessControlProxyGetRuleSet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a rule set. — accountAccessControlProxyGetRuleSet","text":"","code":"accountAccessControlProxyGetRuleSet(client, name, etag)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/accountAccessControlProxyGetRuleSet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a rule set. — accountAccessControlProxyGetRuleSet","text":"client Required. Instance DatabricksClient() name Required. ruleset name associated request. etag Required. Etag used versioning.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/accountAccessControlProxyUpdateRuleSet.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a rule set. — accountAccessControlProxyUpdateRuleSet","title":"Update a rule set. — accountAccessControlProxyUpdateRuleSet","text":"Replace rules rule set. First, use GET rule set request read current version rule set modifying . pattern helps prevent conflicts concurrent updates.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/accountAccessControlProxyUpdateRuleSet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a rule set. — accountAccessControlProxyUpdateRuleSet","text":"","code":"accountAccessControlProxyUpdateRuleSet(client, name, rule_set)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/accountAccessControlProxyUpdateRuleSet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a rule set. — accountAccessControlProxyUpdateRuleSet","text":"client Required. Instance DatabricksClient() name Required. Name rule set. rule_set Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/alertsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an alert. — alertsCreate","title":"Create an alert. — alertsCreate","text":"Creates alert. alert Databricks SQL object periodically runs query, evaluates condition result, notifies users notification destinations condition met.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/alertsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an alert. — alertsCreate","text":"","code":"alertsCreate(client, name, options, query_id, parent = NULL, rearm = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/alertsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an alert. — alertsCreate","text":"client Required. Instance DatabricksClient() name Required. Name alert. options Required. Alert configuration options. query_id Required. Query ID. parent identifier workspace folder containing object. rearm Number seconds triggered alert rearms can triggered .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/alertsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete an alert. — alertsDelete","title":"Delete an alert. — alertsDelete","text":"Deletes alert. Deleted alerts longer accessible restored. Note: Unlike queries dashboards, alerts moved trash.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/alertsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete an alert. — alertsDelete","text":"","code":"alertsDelete(client, alert_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/alertsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete an alert. — alertsDelete","text":"client Required. Instance DatabricksClient() alert_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/alertsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get an alert. — alertsGet","title":"Get an alert. — alertsGet","text":"Gets alert.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/alertsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get an alert. — alertsGet","text":"","code":"alertsGet(client, alert_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/alertsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get an alert. — alertsGet","text":"client Required. Instance DatabricksClient() alert_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/alertsList.html","id":null,"dir":"Reference","previous_headings":"","what":"Get alerts. — alertsList","title":"Get alerts. — alertsList","text":"Gets list alerts.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/alertsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get alerts. — alertsList","text":"","code":"alertsList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/alertsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update an alert. — alertsUpdate","title":"Update an alert. — alertsUpdate","text":"Updates alert.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/alertsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update an alert. — alertsUpdate","text":"","code":"alertsUpdate(client, name, options, query_id, alert_id, rearm = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/alertsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update an alert. — alertsUpdate","text":"client Required. Instance DatabricksClient() name Required. Name alert. options Required. Alert configuration options. query_id Required. Query ID. alert_id Required. rearm Number seconds triggered alert rearms can triggered .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a catalog. — catalogsCreate","title":"Create a catalog. — catalogsCreate","text":"Creates new catalog instance parent metastore caller metastore admin CREATE_CATALOG privilege.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a catalog. — catalogsCreate","text":"","code":"catalogsCreate(   client,   name,   comment = NULL,   connection_name = NULL,   properties = NULL,   provider_name = NULL,   share_name = NULL,   storage_root = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a catalog. — catalogsCreate","text":"client Required. Instance DatabricksClient() name Required. Name catalog. comment User-provided free-form text description. connection_name name connection external data source. properties map key-value properties attached securable. provider_name name delta sharing provider. share_name name share share provider. storage_root Storage root URL managed tables within catalog.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a catalog. — catalogsDelete","title":"Delete a catalog. — catalogsDelete","text":"Deletes catalog matches supplied name. caller must metastore admin owner catalog.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a catalog. — catalogsDelete","text":"","code":"catalogsDelete(client, name, force = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a catalog. — catalogsDelete","text":"client Required. Instance DatabricksClient() name Required. name catalog. force Force deletion even catalog empty.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a catalog. — catalogsGet","title":"Get a catalog. — catalogsGet","text":"Gets specified catalog metastore. caller must metastore admin, owner catalog, user USE_CATALOG privilege set account.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a catalog. — catalogsGet","text":"","code":"catalogsGet(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a catalog. — catalogsGet","text":"client Required. Instance DatabricksClient() name Required. name catalog.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsList.html","id":null,"dir":"Reference","previous_headings":"","what":"List catalogs. — catalogsList","title":"List catalogs. — catalogsList","text":"Gets array catalogs metastore. caller metastore admin, catalogs retrieved. Otherwise, catalogs owned caller (caller USE_CATALOG privilege) retrieved. guarantee specific ordering elements array.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List catalogs. — catalogsList","text":"","code":"catalogsList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List catalogs. — catalogsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a catalog. — catalogsUpdate","title":"Update a catalog. — catalogsUpdate","text":"Updates catalog matches supplied name. caller must either owner catalog, metastore admin (changing owner field catalog).","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a catalog. — catalogsUpdate","text":"","code":"catalogsUpdate(   client,   name,   comment = NULL,   isolation_mode = NULL,   owner = NULL,   properties = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/catalogsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a catalog. — catalogsUpdate","text":"client Required. Instance DatabricksClient() name Name catalog. comment User-provided free-form text description. isolation_mode Whether current securable accessible workspaces specific set workspaces. owner Username current owner catalog. properties map key-value properties attached securable.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a clean room. — cleanRoomsCreate","title":"Create a clean room. — cleanRoomsCreate","text":"Creates new clean room specified colaborators. caller must metastore admin CREATE_CLEAN_ROOM privilege metastore.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a clean room. — cleanRoomsCreate","text":"","code":"cleanRoomsCreate(client, name, remote_detailed_info, comment = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a clean room. — cleanRoomsCreate","text":"client Required. Instance DatabricksClient() name Required. Name clean room. remote_detailed_info Required. Central clean room details. comment User-provided free-form text description.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a clean room. — cleanRoomsDelete","title":"Delete a clean room. — cleanRoomsDelete","text":"Deletes data object clean room metastore. caller must owner clean room.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a clean room. — cleanRoomsDelete","text":"","code":"cleanRoomsDelete(client, name_arg)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a clean room. — cleanRoomsDelete","text":"client Required. Instance DatabricksClient() name_arg Required. name clean room.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a clean room. — cleanRoomsGet","title":"Get a clean room. — cleanRoomsGet","text":"Gets data object clean room metastore. caller must metastore admin owner clean room.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a clean room. — cleanRoomsGet","text":"","code":"cleanRoomsGet(client, name_arg, include_remote_details = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a clean room. — cleanRoomsGet","text":"client Required. Instance DatabricksClient() name_arg Required. name clean room. include_remote_details Whether include remote details (central) clean room.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsList.html","id":null,"dir":"Reference","previous_headings":"","what":"List clean rooms. — cleanRoomsList","title":"List clean rooms. — cleanRoomsList","text":"Gets array data object clean rooms metastore. caller must metastore admin owner clean room. guarantee specific ordering elements array.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List clean rooms. — cleanRoomsList","text":"","code":"cleanRoomsList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List clean rooms. — cleanRoomsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a clean room. — cleanRoomsUpdate","title":"Update a clean room. — cleanRoomsUpdate","text":"Updates clean room changes data objects request. caller must owner clean room metastore admin.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a clean room. — cleanRoomsUpdate","text":"","code":"cleanRoomsUpdate(   client,   name_arg,   catalog_updates = NULL,   comment = NULL,   name = NULL,   owner = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a clean room. — cleanRoomsUpdate","text":"client Required. Instance DatabricksClient() name_arg Required. name clean room. catalog_updates Array shared data object updates. comment User-provided free-form text description. name Name clean room. owner Username current owner clean room.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/cleanRoomsUpdate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update a clean room. — cleanRoomsUpdate","text":"caller metastore admin, owner field can updated. case clean room name changed updateCleanRoom requires caller clean room owner metastore admin. table added method, clean room owner must also SELECT privilege table. privilege must maintained indefinitely recipients able access table. Typically, use group clean room owner. Table removals update require additional privileges.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesClusterPolicyId.html","id":null,"dir":"Reference","previous_headings":"","what":"Get cluster policy permissions. — clusterPoliciesClusterPolicyId","title":"Get cluster policy permissions. — clusterPoliciesClusterPolicyId","text":"Gets permissions cluster policy. Cluster policies can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesClusterPolicyId.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get cluster policy permissions. — clusterPoliciesClusterPolicyId","text":"","code":"clusterPoliciesClusterPolicyId(client, cluster_policy_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesClusterPolicyId.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get cluster policy permissions. — clusterPoliciesClusterPolicyId","text":"client Required. Instance DatabricksClient() cluster_policy_id Required. cluster policy get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new policy. — clusterPoliciesCreate","title":"Create a new policy. — clusterPoliciesCreate","text":"Creates new policy prescribed settings.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new policy. — clusterPoliciesCreate","text":"","code":"clusterPoliciesCreate(   client,   name,   definition = NULL,   description = NULL,   max_clusters_per_user = NULL,   policy_family_definition_overrides = NULL,   policy_family_id = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new policy. — clusterPoliciesCreate","text":"client Required. Instance DatabricksClient() name Required. Cluster Policy name requested user. definition Policy definition document expressed Databricks Cluster Policy Definition Language. description Additional human-readable description cluster policy. max_clusters_per_user Max number clusters per user can active using policy. policy_family_definition_overrides Policy definition JSON document expressed Databricks Policy Definition Language. policy_family_id ID policy family.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a cluster policy. — clusterPoliciesDelete","title":"Delete a cluster policy. — clusterPoliciesDelete","text":"Delete policy cluster. Clusters governed policy can still run, edited.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a cluster policy. — clusterPoliciesDelete","text":"","code":"clusterPoliciesDelete(client, policy_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a cluster policy. — clusterPoliciesDelete","text":"client Required. Instance DatabricksClient() policy_id Required. ID policy delete.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesEdit.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a cluster policy. — clusterPoliciesEdit","title":"Update a cluster policy. — clusterPoliciesEdit","text":"Update existing policy cluster. operation may make clusters governed previous policy invalid.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesEdit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a cluster policy. — clusterPoliciesEdit","text":"","code":"clusterPoliciesEdit(   client,   policy_id,   name,   definition = NULL,   description = NULL,   max_clusters_per_user = NULL,   policy_family_definition_overrides = NULL,   policy_family_id = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesEdit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a cluster policy. — clusterPoliciesEdit","text":"client Required. Instance DatabricksClient() policy_id Required. ID policy update. name Required. Cluster Policy name requested user. definition Policy definition document expressed Databricks Cluster Policy Definition Language. description Additional human-readable description cluster policy. max_clusters_per_user Max number clusters per user can active using policy. policy_family_definition_overrides Policy definition JSON document expressed Databricks Policy Definition Language. policy_family_id ID policy family.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get entity. — clusterPoliciesGet","title":"Get entity. — clusterPoliciesGet","text":"Get cluster policy entity. Creation editing available admins .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get entity. — clusterPoliciesGet","text":"","code":"clusterPoliciesGet(client, policy_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get entity. — clusterPoliciesGet","text":"client Required. Instance DatabricksClient() policy_id Required. Canonical unique identifier cluster policy.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesList.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a cluster policy. — clusterPoliciesList","title":"Get a cluster policy. — clusterPoliciesList","text":"Returns list policies accessible requesting user.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a cluster policy. — clusterPoliciesList","text":"","code":"clusterPoliciesList(client, sort_column = NULL, sort_order = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a cluster policy. — clusterPoliciesList","text":"client Required. Instance DatabricksClient() sort_column cluster policy attribute sort . sort_order order policies get listed.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a cluster policy. — clusterPoliciesList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesPermissionLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Get cluster policy permission levels. — clusterPoliciesPermissionLevels","title":"Get cluster policy permission levels. — clusterPoliciesPermissionLevels","text":"Gets permission levels user can object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesPermissionLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get cluster policy permission levels. — clusterPoliciesPermissionLevels","text":"","code":"clusterPoliciesPermissionLevels(client, cluster_policy_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clusterPoliciesPermissionLevels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get cluster policy permission levels. — clusterPoliciesPermissionLevels","text":"client Required. Instance DatabricksClient() cluster_policy_id Required. cluster policy get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersChangeOwner.html","id":null,"dir":"Reference","previous_headings":"","what":"Change cluster owner. — clustersChangeOwner","title":"Change cluster owner. — clustersChangeOwner","text":"Change owner cluster. must admin perform operation.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersChangeOwner.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change cluster owner. — clustersChangeOwner","text":"","code":"clustersChangeOwner(client, cluster_id, owner_username)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersChangeOwner.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change cluster owner. — clustersChangeOwner","text":"client Required. Instance DatabricksClient() cluster_id Required. . owner_username Required. New owner cluster_id RPC.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersClusterId.html","id":null,"dir":"Reference","previous_headings":"","what":"Update cluster permissions. — clustersClusterId","title":"Update cluster permissions. — clustersClusterId","text":"Updates permissions cluster. Clusters can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersClusterId.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update cluster permissions. — clustersClusterId","text":"","code":"clustersClusterId(client, cluster_id, access_control_list = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersClusterId.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update cluster permissions. — clustersClusterId","text":"client Required. Instance DatabricksClient() cluster_id Required. cluster get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create new cluster. — clustersCreate","title":"Create new cluster. — clustersCreate","text":"long-running operation, blocks Clusters Databricks reach RUNNING state timeout 20 minutes, can change via timeout parameter. default, state Databricks Clusters reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create new cluster. — clustersCreate","text":"","code":"clustersCreate(   client,   spark_version,   apply_policy_default_values = NULL,   autoscale = NULL,   autotermination_minutes = NULL,   aws_attributes = NULL,   azure_attributes = NULL,   cluster_log_conf = NULL,   cluster_name = NULL,   cluster_source = NULL,   custom_tags = NULL,   driver_instance_pool_id = NULL,   driver_node_type_id = NULL,   enable_elastic_disk = NULL,   enable_local_disk_encryption = NULL,   gcp_attributes = NULL,   init_scripts = NULL,   instance_pool_id = NULL,   node_type_id = NULL,   num_workers = NULL,   policy_id = NULL,   runtime_engine = NULL,   spark_conf = NULL,   spark_env_vars = NULL,   ssh_public_keys = NULL,   workload_type = NULL,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create new cluster. — clustersCreate","text":"client Required. Instance DatabricksClient() spark_version Required. Spark version cluster, e.g. apply_policy_default_values Note: field true webapp requests. autoscale Parameters needed order automatically scale clusters based load. autotermination_minutes Automatically terminates cluster inactive time minutes. aws_attributes Attributes related clusters running Amazon Web Services. azure_attributes Attributes related clusters running Microsoft Azure. cluster_log_conf configuration delivering spark logs long-term storage destination. cluster_name Cluster name requested user. cluster_source Determines whether cluster created user UI, created Databricks Jobs Scheduler, API request. custom_tags Additional tags cluster resources. driver_instance_pool_id optional ID instance pool driver cluster belongs. driver_node_type_id node type Spark driver. enable_elastic_disk Autoscaling Local Storage: enabled, cluster dynamically acquire additional disk space Spark workers running low disk space. enable_local_disk_encryption Whether enable LUKS cluster VMs' local disks. gcp_attributes Attributes related clusters running Google Cloud Platform. init_scripts configuration storing init scripts. instance_pool_id optional ID instance pool cluster belongs. node_type_id field encodes, single value, resources available Spark nodes cluster. num_workers Number worker nodes cluster . policy_id ID cluster policy used create cluster applicable. runtime_engine Decides runtime engine use, e.g. spark_conf object containing set optional, user-specified Spark configuration key-value pairs. spark_env_vars object containing set optional, user-specified environment variable key-value pairs. ssh_public_keys SSH public key contents added Spark node cluster. workload_type","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersCreate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create new cluster. — clustersCreate","text":"Creates new Spark cluster. method acquire new instances cloud provider necessary. Note: Databricks may able acquire requested nodes, due cloud provider limitations (account limits, spot price, etc.) transient network issues. Databricks acquires least 85% requested -demand nodes, cluster creation succeed. Otherwise cluster terminate informative error message.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Terminate cluster. — clustersDelete","title":"Terminate cluster. — clustersDelete","text":"long-running operation, blocks Clusters Databricks reach TERMINATED state timeout 20 minutes, can change via timeout parameter. default, state Databricks Clusters reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Terminate cluster. — clustersDelete","text":"","code":"clustersDelete(client, cluster_id, timeout = 20, callback = cli_reporter)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Terminate cluster. — clustersDelete","text":"client Required. Instance DatabricksClient() cluster_id Required. cluster terminated.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersDelete.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Terminate cluster. — clustersDelete","text":"Terminates Spark cluster specified ID. cluster removed asynchronously. termination completed, cluster TERMINATED state. cluster already TERMINATING TERMINATED state, nothing happen.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersEdit.html","id":null,"dir":"Reference","previous_headings":"","what":"Update cluster configuration. — clustersEdit","title":"Update cluster configuration. — clustersEdit","text":"long-running operation, blocks Clusters Databricks reach RUNNING state timeout 20 minutes, can change via timeout parameter. default, state Databricks Clusters reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersEdit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update cluster configuration. — clustersEdit","text":"","code":"clustersEdit(   client,   cluster_id,   spark_version,   apply_policy_default_values = NULL,   autoscale = NULL,   autotermination_minutes = NULL,   aws_attributes = NULL,   azure_attributes = NULL,   cluster_log_conf = NULL,   cluster_name = NULL,   cluster_source = NULL,   custom_tags = NULL,   data_security_mode = NULL,   docker_image = NULL,   driver_instance_pool_id = NULL,   driver_node_type_id = NULL,   enable_elastic_disk = NULL,   enable_local_disk_encryption = NULL,   gcp_attributes = NULL,   init_scripts = NULL,   instance_pool_id = NULL,   node_type_id = NULL,   num_workers = NULL,   policy_id = NULL,   runtime_engine = NULL,   single_user_name = NULL,   spark_conf = NULL,   spark_env_vars = NULL,   ssh_public_keys = NULL,   workload_type = NULL,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersEdit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update cluster configuration. — clustersEdit","text":"client Required. Instance DatabricksClient() cluster_id Required. ID cluser. spark_version Required. Spark version cluster, e.g. apply_policy_default_values Note: field true webapp requests. autoscale Parameters needed order automatically scale clusters based load. autotermination_minutes Automatically terminates cluster inactive time minutes. aws_attributes Attributes related clusters running Amazon Web Services. azure_attributes Attributes related clusters running Microsoft Azure. cluster_log_conf configuration delivering spark logs long-term storage destination. cluster_name Cluster name requested user. cluster_source Determines whether cluster created user UI, created Databricks Jobs Scheduler, API request. custom_tags Additional tags cluster resources. data_security_mode describes enum. docker_image  driver_instance_pool_id optional ID instance pool driver cluster belongs. driver_node_type_id node type Spark driver. enable_elastic_disk Autoscaling Local Storage: enabled, cluster dynamically acquire additional disk space Spark workers running low disk space. enable_local_disk_encryption Whether enable LUKS cluster VMs' local disks. gcp_attributes Attributes related clusters running Google Cloud Platform. init_scripts configuration storing init scripts. instance_pool_id optional ID instance pool cluster belongs. node_type_id field encodes, single value, resources available Spark nodes cluster. num_workers Number worker nodes cluster . policy_id ID cluster policy used create cluster applicable. runtime_engine Decides runtime engine use, e.g. single_user_name Single user name data_security_mode SINGLE_USER. spark_conf object containing set optional, user-specified Spark configuration key-value pairs. spark_env_vars object containing set optional, user-specified environment variable key-value pairs. ssh_public_keys SSH public key contents added Spark node cluster. workload_type","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersEdit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update cluster configuration. — clustersEdit","text":"Updates configuration cluster match provided attributes size. cluster can updated RUNNING TERMINATED state. cluster updated RUNNING state, restarted new attributes can take effect. cluster updated TERMINATED state, remain TERMINATED. next time started using clusters/start API, new attributes take effect. attempt update cluster state rejected INVALID_STATE error code. Clusters created Databricks Jobs service edited.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersEvents.html","id":null,"dir":"Reference","previous_headings":"","what":"List cluster activity events. — clustersEvents","title":"List cluster activity events. — clustersEvents","text":"Retrieves list events activity cluster. API paginated. events read, response includes nparameters necessary request next page events.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersEvents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List cluster activity events. — clustersEvents","text":"","code":"clustersEvents(   client,   cluster_id,   end_time = NULL,   event_types = NULL,   limit = NULL,   offset = NULL,   order = NULL,   start_time = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersEvents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List cluster activity events. — clustersEvents","text":"client Required. Instance DatabricksClient() cluster_id Required. ID cluster retrieve events . end_time end time epoch milliseconds. event_types optional set event types filter . limit maximum number events include page events. offset offset result set. order order list events ; either 'ASC' 'DESC'. start_time start time epoch milliseconds.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersEvents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List cluster activity events. — clustersEvents","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get cluster info. — clustersGet","title":"Get cluster info. — clustersGet","text":"Retrieves information cluster given identifier. Clusters can described running, 60 days terminated.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get cluster info. — clustersGet","text":"","code":"clustersGet(client, cluster_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get cluster info. — clustersGet","text":"client Required. Instance DatabricksClient() cluster_id Required. cluster retrieve information.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersList.html","id":null,"dir":"Reference","previous_headings":"","what":"List all clusters. — clustersList","title":"List all clusters. — clustersList","text":"Return information pinned clusters, active clusters, 200 recently terminated -purpose clusters past 30 days, 30 recently terminated job clusters past 30 days.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List all clusters. — clustersList","text":"","code":"clustersList(client, can_use_client = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List all clusters. — clustersList","text":"client Required. Instance DatabricksClient() can_use_client Filter clusters based type client can used .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List all clusters. — clustersList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersList.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List all clusters. — clustersList","text":"example, 1 pinned cluster, 4 active clusters, 45 terminated -purpose clusters past 30 days, 50 terminated job clusters past 30 days, API returns 1 pinned cluster, 4 active clusters, 45 terminated -purpose clusters, 30 recently terminated job clusters.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersListNodeTypes.html","id":null,"dir":"Reference","previous_headings":"","what":"List node types. — clustersListNodeTypes","title":"List node types. — clustersListNodeTypes","text":"Returns list supported Spark node types. node types can used launch cluster.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersListNodeTypes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List node types. — clustersListNodeTypes","text":"","code":"clustersListNodeTypes(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersListZones.html","id":null,"dir":"Reference","previous_headings":"","what":"List availability zones. — clustersListZones","title":"List availability zones. — clustersListZones","text":"Returns list availability zones clusters can created (example, us-west-2a). zones can used launch cluster.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersListZones.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List availability zones. — clustersListZones","text":"","code":"clustersListZones(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersPermanentDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Permanently delete cluster. — clustersPermanentDelete","title":"Permanently delete cluster. — clustersPermanentDelete","text":"Permanently deletes Spark cluster. cluster terminated resources asynchronously removed.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersPermanentDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Permanently delete cluster. — clustersPermanentDelete","text":"","code":"clustersPermanentDelete(client, cluster_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersPermanentDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Permanently delete cluster. — clustersPermanentDelete","text":"client Required. Instance DatabricksClient() cluster_id Required. cluster deleted.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersPermanentDelete.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Permanently delete cluster. — clustersPermanentDelete","text":"addition, users longer see permanently deleted clusters cluster list, API users can longer perform action permanently deleted clusters.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersPermissionLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Get cluster permission levels. — clustersPermissionLevels","title":"Get cluster permission levels. — clustersPermissionLevels","text":"Gets permission levels user can object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersPermissionLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get cluster permission levels. — clustersPermissionLevels","text":"","code":"clustersPermissionLevels(client, cluster_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersPermissionLevels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get cluster permission levels. — clustersPermissionLevels","text":"client Required. Instance DatabricksClient() cluster_id Required. cluster get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersPin.html","id":null,"dir":"Reference","previous_headings":"","what":"Pin cluster. — clustersPin","title":"Pin cluster. — clustersPin","text":"Pinning cluster ensures cluster always returned ListClusters API. Pinning cluster already pinned effect. API can called workspace admins.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersPin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pin cluster. — clustersPin","text":"","code":"clustersPin(client, cluster_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersPin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pin cluster. — clustersPin","text":"client Required. Instance DatabricksClient() cluster_id Required. .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersResize.html","id":null,"dir":"Reference","previous_headings":"","what":"Resize cluster. — clustersResize","title":"Resize cluster. — clustersResize","text":"long-running operation, blocks Clusters Databricks reach RUNNING state timeout 20 minutes, can change via timeout parameter. default, state Databricks Clusters reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersResize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resize cluster. — clustersResize","text":"","code":"clustersResize(   client,   cluster_id,   autoscale = NULL,   num_workers = NULL,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersResize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resize cluster. — clustersResize","text":"client Required. Instance DatabricksClient() cluster_id Required. cluster resized. autoscale Parameters needed order automatically scale clusters based load. num_workers Number worker nodes cluster .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersResize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Resize cluster. — clustersResize","text":"Resizes cluster desired number workers. fail unless cluster RUNNING state.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersRestart.html","id":null,"dir":"Reference","previous_headings":"","what":"Restart cluster. — clustersRestart","title":"Restart cluster. — clustersRestart","text":"long-running operation, blocks Clusters Databricks reach RUNNING state timeout 20 minutes, can change via timeout parameter. default, state Databricks Clusters reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersRestart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restart cluster. — clustersRestart","text":"","code":"clustersRestart(   client,   cluster_id,   restart_user = NULL,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersRestart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restart cluster. — clustersRestart","text":"client Required. Instance DatabricksClient() cluster_id Required. cluster started. restart_user .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersRestart.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Restart cluster. — clustersRestart","text":"Restarts Spark cluster supplied ID. cluster currently RUNNING state, nothing happen.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersSparkVersions.html","id":null,"dir":"Reference","previous_headings":"","what":"List available Spark versions. — clustersSparkVersions","title":"List available Spark versions. — clustersSparkVersions","text":"Returns list available Spark versions. versions can used launch cluster.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersSparkVersions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List available Spark versions. — clustersSparkVersions","text":"","code":"clustersSparkVersions(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersStart.html","id":null,"dir":"Reference","previous_headings":"","what":"Start terminated cluster. — clustersStart","title":"Start terminated cluster. — clustersStart","text":"long-running operation, blocks Clusters Databricks reach RUNNING state timeout 20 minutes, can change via timeout parameter. default, state Databricks Clusters reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersStart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Start terminated cluster. — clustersStart","text":"","code":"clustersStart(client, cluster_id, timeout = 20, callback = cli_reporter)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersStart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Start terminated cluster. — clustersStart","text":"client Required. Instance DatabricksClient() cluster_id Required. cluster started.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersStart.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Start terminated cluster. — clustersStart","text":"Starts terminated Spark cluster supplied ID. works similar createCluster except: previous cluster id attributes preserved. * cluster starts last specified cluster size. * previous cluster autoscaling cluster, current cluster starts minimum number nodes. * cluster currently TERMINATED state, nothing happen. * Clusters launched run job started.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersUnpin.html","id":null,"dir":"Reference","previous_headings":"","what":"Unpin cluster. — clustersUnpin","title":"Unpin cluster. — clustersUnpin","text":"Unpinning cluster allow cluster eventually removed ListClusters API. Unpinning cluster pinned effect. API can called workspace admins.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersUnpin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unpin cluster. — clustersUnpin","text":"","code":"clustersUnpin(client, cluster_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/clustersUnpin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unpin cluster. — clustersUnpin","text":"client Required. Instance DatabricksClient() cluster_id Required. .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionCancel.html","id":null,"dir":"Reference","previous_headings":"","what":"Cancel a command. — commandExecutionCancel","title":"Cancel a command. — commandExecutionCancel","text":"long-running operation, blocks Command Execution Databricks reach Cancelled state timeout 20 minutes, can change via timeout parameter. default, state Databricks Command Execution reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionCancel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cancel a command. — commandExecutionCancel","text":"","code":"commandExecutionCancel(   client,   cluster_id = NULL,   command_id = NULL,   context_id = NULL,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionCancel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cancel a command. — commandExecutionCancel","text":"client Required. Instance DatabricksClient() cluster_id  command_id  context_id","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionCancel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cancel a command. — commandExecutionCancel","text":"Cancels currently running command within execution context. command ID obtained prior successful call execute.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionCommandStatus.html","id":null,"dir":"Reference","previous_headings":"","what":"Get command info. — commandExecutionCommandStatus","title":"Get command info. — commandExecutionCommandStatus","text":"Gets status , available, results currently executing command.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionCommandStatus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get command info. — commandExecutionCommandStatus","text":"","code":"commandExecutionCommandStatus(client, cluster_id, context_id, command_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionCommandStatus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get command info. — commandExecutionCommandStatus","text":"client Required. Instance DatabricksClient() cluster_id Required. context_id Required. command_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionCommandStatus.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get command info. — commandExecutionCommandStatus","text":"command ID obtained prior successful call execute.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionContextStatus.html","id":null,"dir":"Reference","previous_headings":"","what":"Get status. — commandExecutionContextStatus","title":"Get status. — commandExecutionContextStatus","text":"Gets status execution context.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionContextStatus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get status. — commandExecutionContextStatus","text":"","code":"commandExecutionContextStatus(client, cluster_id, context_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionContextStatus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get status. — commandExecutionContextStatus","text":"client Required. Instance DatabricksClient() cluster_id Required. context_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an execution context. — commandExecutionCreate","title":"Create an execution context. — commandExecutionCreate","text":"long-running operation, blocks Command Execution Databricks reach Running state timeout 20 minutes, can change via timeout parameter. default, state Databricks Command Execution reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an execution context. — commandExecutionCreate","text":"","code":"commandExecutionCreate(   client,   cluster_id = NULL,   language = NULL,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an execution context. — commandExecutionCreate","text":"client Required. Instance DatabricksClient() cluster_id Running cluster id. language","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionCreate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create an execution context. — commandExecutionCreate","text":"Creates execution context running cluster commands. successful, method returns ID new execution context.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionDestroy.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete an execution context. — commandExecutionDestroy","title":"Delete an execution context. — commandExecutionDestroy","text":"Deletes execution context.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionDestroy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete an execution context. — commandExecutionDestroy","text":"","code":"commandExecutionDestroy(client, cluster_id, context_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionDestroy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete an execution context. — commandExecutionDestroy","text":"client Required. Instance DatabricksClient() cluster_id Required. context_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionExecute.html","id":null,"dir":"Reference","previous_headings":"","what":"Run a command. — commandExecutionExecute","title":"Run a command. — commandExecutionExecute","text":"long-running operation, blocks Command Execution Databricks reach Finished Error state timeout 20 minutes, can change via timeout parameter. default, state Databricks Command Execution reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionExecute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run a command. — commandExecutionExecute","text":"","code":"commandExecutionExecute(   client,   cluster_id = NULL,   command = NULL,   context_id = NULL,   language = NULL,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionExecute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run a command. — commandExecutionExecute","text":"client Required. Instance DatabricksClient() cluster_id Running cluster id. command Executable code. context_id Running context id. language","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/commandExecutionExecute.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run a command. — commandExecutionExecute","text":"Runs cluster command given execution context, using provided language. successful, returns ID tracking status command's execution.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a connection. — connectionsCreate","title":"Create a connection. — connectionsCreate","text":"Creates new connection","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a connection. — connectionsCreate","text":"","code":"connectionsCreate(   client,   name,   connection_type,   options_kvpairs,   comment = NULL,   owner = NULL,   properties_kvpairs = NULL,   read_only = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a connection. — connectionsCreate","text":"client Required. Instance DatabricksClient() name Required. Name connection. connection_type Required. type connection. options_kvpairs Required. map key-value properties attached securable. comment User-provided free-form text description. owner Username current owner connection. properties_kvpairs object containing map key-value properties attached connection. read_only connection read .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsCreate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a connection. — connectionsCreate","text":"Creates new connection external data source. allows users specify connection details configurations interaction external server.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a connection. — connectionsDelete","title":"Delete a connection. — connectionsDelete","text":"Deletes connection matches supplied name.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a connection. — connectionsDelete","text":"","code":"connectionsDelete(client, name_arg)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a connection. — connectionsDelete","text":"client Required. Instance DatabricksClient() name_arg Required. name connection deleted.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a connection. — connectionsGet","title":"Get a connection. — connectionsGet","text":"Gets connection name.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a connection. — connectionsGet","text":"","code":"connectionsGet(client, name_arg)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a connection. — connectionsGet","text":"client Required. Instance DatabricksClient() name_arg Required. Name connection.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsList.html","id":null,"dir":"Reference","previous_headings":"","what":"List connections. — connectionsList","title":"List connections. — connectionsList","text":"List connections.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List connections. — connectionsList","text":"","code":"connectionsList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List connections. — connectionsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a connection. — connectionsUpdate","title":"Update a connection. — connectionsUpdate","text":"Updates connection matches supplied name.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a connection. — connectionsUpdate","text":"","code":"connectionsUpdate(client, name, options_kvpairs, name_arg)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/connectionsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a connection. — connectionsUpdate","text":"client Required. Instance DatabricksClient() name Required. Name connection. options_kvpairs Required. map key-value properties attached securable. name_arg Required. Name connection.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/currentUserMe.html","id":null,"dir":"Reference","previous_headings":"","what":"Get current user info. — currentUserMe","title":"Get current user info. — currentUserMe","text":"Get details current method caller's identity.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/currentUserMe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get current user info. — currentUserMe","text":"","code":"currentUserMe(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a dashboard object. — dashboardsCreate","title":"Create a dashboard object. — dashboardsCreate","text":"Create dashboard object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a dashboard object. — dashboardsCreate","text":"","code":"dashboardsCreate(   client,   is_favorite = NULL,   name = NULL,   parent = NULL,   tags = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a dashboard object. — dashboardsCreate","text":"client Required. Instance DatabricksClient() is_favorite Indicates whether query object appear current user's favorites list. name title dashboard appears list views top dashboard page. parent identifier workspace folder containing object. tags","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove a dashboard. — dashboardsDelete","title":"Remove a dashboard. — dashboardsDelete","text":"Moves dashboard trash. Trashed dashboards appear list views searches, shared.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove a dashboard. — dashboardsDelete","text":"","code":"dashboardsDelete(client, dashboard_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove a dashboard. — dashboardsDelete","text":"client Required. Instance DatabricksClient() dashboard_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve a definition. — dashboardsGet","title":"Retrieve a definition. — dashboardsGet","text":"Returns JSON representation dashboard object, including visualization query objects.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve a definition. — dashboardsGet","text":"","code":"dashboardsGet(client, dashboard_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve a definition. — dashboardsGet","text":"client Required. Instance DatabricksClient() dashboard_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsList.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dashboard objects. — dashboardsList","title":"Get dashboard objects. — dashboardsList","text":"Fetch paginated list dashboard objects.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dashboard objects. — dashboardsList","text":"","code":"dashboardsList(client, order = NULL, page = NULL, page_size = NULL, q = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dashboard objects. — dashboardsList","text":"client Required. Instance DatabricksClient() order Name dashboard attribute order . page Page number retrieve. page_size Number dashboards return per page. q Full text search term.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get dashboard objects. — dashboardsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsRestore.html","id":null,"dir":"Reference","previous_headings":"","what":"Restore a dashboard. — dashboardsRestore","title":"Restore a dashboard. — dashboardsRestore","text":"restored dashboard appears list views searches can shared.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsRestore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restore a dashboard. — dashboardsRestore","text":"","code":"dashboardsRestore(client, dashboard_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dashboardsRestore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restore a dashboard. — dashboardsRestore","text":"client Required. Instance DatabricksClient() dashboard_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dataSourcesList.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a list of SQL warehouses. — dataSourcesList","title":"Get a list of SQL warehouses. — dataSourcesList","text":"Retrieves full list SQL warehouses available workspace. fields appear API response enumerated clarity. However, need SQL warehouse's id create new queries .#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dataSourcesList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a list of SQL warehouses. — dataSourcesList","text":"","code":"dataSourcesList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/databricks-package.html","id":null,"dir":"Reference","previous_headings":"","what":"databricks: Databricks SDK for R (Experimental) — databricks-package","title":"databricks: Databricks SDK for R (Experimental) — databricks-package","text":"Call Databricks REST APIs R.","code":""},{"path":[]},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/databricks-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"databricks: Databricks SDK for R (Experimental) — databricks-package","text":"Maintainer: Serge Smertin serge.smertin@databricks.com contributors: Databricks [copyright holder, funder]","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsAddBlock.html","id":null,"dir":"Reference","previous_headings":"","what":"Append data block. — dbfsAddBlock","title":"Append data block. — dbfsAddBlock","text":"Appends block data stream specified input handle. handle exist, call throw exception RESOURCE_DOES_NOT_EXIST.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsAddBlock.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Append data block. — dbfsAddBlock","text":"","code":"dbfsAddBlock(client, handle, data)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsAddBlock.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Append data block. — dbfsAddBlock","text":"client Required. Instance DatabricksClient() handle Required. handle open stream. data Required. base64-encoded data append stream.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsAddBlock.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Append data block. — dbfsAddBlock","text":"block data exceeds 1 MB, call throw exception MAX_BLOCK_SIZE_EXCEEDED.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsClose.html","id":null,"dir":"Reference","previous_headings":"","what":"Close the stream. — dbfsClose","title":"Close the stream. — dbfsClose","text":"Closes stream specified input handle. handle exist, call throws exception RESOURCE_DOES_NOT_EXIST.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsClose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Close the stream. — dbfsClose","text":"","code":"dbfsClose(client, handle)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsClose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Close the stream. — dbfsClose","text":"client Required. Instance DatabricksClient() handle Required. handle open stream.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Open a stream. — dbfsCreate","title":"Open a stream. — dbfsCreate","text":"Opens stream write file returns handle stream. 10 minute idle timeout handle. file directory already exists given path overwrite set false, call throws exception RESOURCE_ALREADY_EXISTS.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Open a stream. — dbfsCreate","text":"","code":"dbfsCreate(client, path, overwrite = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Open a stream. — dbfsCreate","text":"client Required. Instance DatabricksClient() path Required. path new file. overwrite flag specifies whether overwrite existing file/files.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsCreate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Open a stream. — dbfsCreate","text":"typical workflow file upload : Issue create call get handle. 2. Issue one add-block calls handle . 3. Issue close call handle .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a file/directory. — dbfsDelete","title":"Delete a file/directory. — dbfsDelete","text":"Delete file directory (optionally recursively delete files directory). call throws exception IO_ERROR path non-empty directory recursive set false similar errors.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a file/directory. — dbfsDelete","text":"","code":"dbfsDelete(client, path, recursive = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a file/directory. — dbfsDelete","text":"client Required. Instance DatabricksClient() path Required. path file directory delete. recursive Whether recursively delete directory's contents.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsDelete.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Delete a file/directory. — dbfsDelete","text":"delete large number files, delete operation done increments. call returns response approximately 45 seconds error message (503 Service Unavailable) asking re-invoke delete operation directory structure fully deleted. operations delete 10K files, discourage using DBFS REST API, advise perform operations context cluster, using File system utility (dbutils.fs). dbutils.fs covers functional scope DBFS REST API, notebooks. Running operations using notebooks provides better control manageability, selective deletes, possibility automate periodic delete jobs.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsGetStatus.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the information of a file or directory. — dbfsGetStatus","title":"Get the information of a file or directory. — dbfsGetStatus","text":"Gets file information file directory. file directory exist, call throws exception RESOURCE_DOES_NOT_EXIST.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsGetStatus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the information of a file or directory. — dbfsGetStatus","text":"","code":"dbfsGetStatus(client, path)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsGetStatus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the information of a file or directory. — dbfsGetStatus","text":"client Required. Instance DatabricksClient() path Required. path file directory.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsList.html","id":null,"dir":"Reference","previous_headings":"","what":"List directory contents or file details. — dbfsList","title":"List directory contents or file details. — dbfsList","text":"List contents directory, details file. file directory exist, call throws exception RESOURCE_DOES_NOT_EXIST.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List directory contents or file details. — dbfsList","text":"","code":"dbfsList(client, path)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List directory contents or file details. — dbfsList","text":"client Required. Instance DatabricksClient() path Required. path file directory.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List directory contents or file details. — dbfsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsList.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List directory contents or file details. — dbfsList","text":"calling list large directory, list operation time approximately 60 seconds. strongly recommend using list directories containing less 10K files discourage using DBFS REST API operations list 10K files. Instead, recommend perform operations context cluster, using File system utility (dbutils.fs), provides functionality without timing .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsMkdirs.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a directory. — dbfsMkdirs","title":"Create a directory. — dbfsMkdirs","text":"Creates given directory necessary parent directories exist. file (directory) exists prefix input path, call throws exception RESOURCE_ALREADY_EXISTS. Note: operation fails, might succeeded creating necessary parent directories.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsMkdirs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a directory. — dbfsMkdirs","text":"","code":"dbfsMkdirs(client, path)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsMkdirs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a directory. — dbfsMkdirs","text":"client Required. Instance DatabricksClient() path Required. path new directory.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsMove.html","id":null,"dir":"Reference","previous_headings":"","what":"Move a file. — dbfsMove","title":"Move a file. — dbfsMove","text":"Moves file one location another location within DBFS. source file exist, call throws exception RESOURCE_DOES_NOT_EXIST. file already exists destination path, call throws exception RESOURCE_ALREADY_EXISTS. given source path directory, call always recursively moves files.',","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsMove.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Move a file. — dbfsMove","text":"","code":"dbfsMove(client, source_path, destination_path)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsMove.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Move a file. — dbfsMove","text":"client Required. Instance DatabricksClient() source_path Required. source path file directory. destination_path Required. destination path file directory.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsPut.html","id":null,"dir":"Reference","previous_headings":"","what":"Upload a file. — dbfsPut","title":"Upload a file. — dbfsPut","text":"Uploads file use multipart form post. mainly used streaming uploads, can also used convenient single call data upload.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsPut.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upload a file. — dbfsPut","text":"","code":"dbfsPut(client, path, contents = NULL, overwrite = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsPut.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upload a file. — dbfsPut","text":"client Required. Instance DatabricksClient() path Required. path new file. contents parameter might absent, instead posted file used. overwrite flag specifies whether overwrite existing file/files.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsPut.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Upload a file. — dbfsPut","text":"Alternatively can pass contents base64 string. amount data can passed (streaming) using contents parameter limited 1 MB. MAX_BLOCK_SIZE_EXCEEDED thrown limit exceeded. want upload large files, use streaming upload. details, see :method:dbfs/create, :method:dbfs/addBlock, :method:dbfs/close.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsRead.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the contents of a file. — dbfsRead","title":"Get the contents of a file. — dbfsRead","text":"Returns contents file. file exist, call throws exception RESOURCE_DOES_NOT_EXIST. path directory, read length negative, offset negative, call throws exception INVALID_PARAMETER_VALUE. read length exceeds 1 MB, call throws exception MAX_READ_SIZE_EXCEEDED.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsRead.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the contents of a file. — dbfsRead","text":"","code":"dbfsRead(client, path, length = NULL, offset = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsRead.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the contents of a file. — dbfsRead","text":"client Required. Instance DatabricksClient() path Required. path file read. length number bytes read starting offset. offset offset read bytes.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbfsRead.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the contents of a file. — dbfsRead","text":"offset + length exceeds number bytes file, reads contents end file.',","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbsqlPermissionsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get object ACL. — dbsqlPermissionsGet","title":"Get object ACL. — dbsqlPermissionsGet","text":"Gets JSON representation access control list (ACL) specified object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbsqlPermissionsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get object ACL. — dbsqlPermissionsGet","text":"","code":"dbsqlPermissionsGet(client, object_type, object_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbsqlPermissionsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get object ACL. — dbsqlPermissionsGet","text":"client Required. Instance DatabricksClient() object_type Required. type object permissions check. object_id Required. Object ID.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbsqlPermissionsSet.html","id":null,"dir":"Reference","previous_headings":"","what":"Set object ACL. — dbsqlPermissionsSet","title":"Set object ACL. — dbsqlPermissionsSet","text":"Sets access control list (ACL) specified object. operation complete rewrite ACL.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbsqlPermissionsSet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set object ACL. — dbsqlPermissionsSet","text":"","code":"dbsqlPermissionsSet(client, object_type, object_id, access_control_list = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbsqlPermissionsSet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set object ACL. — dbsqlPermissionsSet","text":"client Required. Instance DatabricksClient() object_type Required. type object permission set. object_id Required. Object ID. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbsqlPermissionsTransferOwnership.html","id":null,"dir":"Reference","previous_headings":"","what":"Transfer object ownership. — dbsqlPermissionsTransferOwnership","title":"Transfer object ownership. — dbsqlPermissionsTransferOwnership","text":"Transfers ownership dashboard, query, alert active user. Requires admin API key.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbsqlPermissionsTransferOwnership.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transfer object ownership. — dbsqlPermissionsTransferOwnership","text":"","code":"dbsqlPermissionsTransferOwnership(   client,   object_type,   object_id,   new_owner = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/dbsqlPermissionsTransferOwnership.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transfer object ownership. — dbsqlPermissionsTransferOwnership","text":"client Required. Instance DatabricksClient() object_type Required. type object change ownership. object_id Required. ID object change ownership. new_owner Email address new owner, must exist workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsCreateExperiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Create experiment. — experimentsCreateExperiment","title":"Create experiment. — experimentsCreateExperiment","text":"Creates experiment name. Returns ID newly created experiment. Validates another experiment name already exist fails another experiment name already exists.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsCreateExperiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create experiment. — experimentsCreateExperiment","text":"","code":"experimentsCreateExperiment(   client,   name,   artifact_location = NULL,   tags = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsCreateExperiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create experiment. — experimentsCreateExperiment","text":"client Required. Instance DatabricksClient() name Required. Experiment name. artifact_location Location artifacts experiment stored. tags collection tags set experiment.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsCreateExperiment.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create experiment. — experimentsCreateExperiment","text":"Throws RESOURCE_ALREADY_EXISTS experiment given name exists.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsCreateRun.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a run. — experimentsCreateRun","title":"Create a run. — experimentsCreateRun","text":"Creates new run within experiment. run usually single execution machine learning data ETL pipeline. MLflow uses runs track mlflowParam, mlflowMetric mlflowRunTag associated single execution.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsCreateRun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a run. — experimentsCreateRun","text":"","code":"experimentsCreateRun(   client,   experiment_id = NULL,   start_time = NULL,   tags = NULL,   user_id = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsCreateRun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a run. — experimentsCreateRun","text":"client Required. Instance DatabricksClient() experiment_id ID associated experiment. start_time Unix timestamp milliseconds run started. tags Additional metadata run. user_id ID user executing run.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsDeleteExperiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete an experiment. — experimentsDeleteExperiment","title":"Delete an experiment. — experimentsDeleteExperiment","text":"Marks experiment associated metadata, runs, metrics, params, tags deletion. experiment uses FileStore, artifacts associated experiment also deleted.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsDeleteExperiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete an experiment. — experimentsDeleteExperiment","text":"","code":"experimentsDeleteExperiment(client, experiment_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsDeleteExperiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete an experiment. — experimentsDeleteExperiment","text":"client Required. Instance DatabricksClient() experiment_id Required. ID associated experiment.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsDeleteRun.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a run. — experimentsDeleteRun","title":"Delete a run. — experimentsDeleteRun","text":"Marks run deletion.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsDeleteRun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a run. — experimentsDeleteRun","text":"","code":"experimentsDeleteRun(client, run_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsDeleteRun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a run. — experimentsDeleteRun","text":"client Required. Instance DatabricksClient() run_id Required. ID run delete.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsDeleteTag.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a tag. — experimentsDeleteTag","title":"Delete a tag. — experimentsDeleteTag","text":"Deletes tag run. Tags run metadata can updated run run completes.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsDeleteTag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a tag. — experimentsDeleteTag","text":"","code":"experimentsDeleteTag(client, run_id, key)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsDeleteTag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a tag. — experimentsDeleteTag","text":"client Required. Instance DatabricksClient() run_id Required. ID run tag logged . key Required. Name tag.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetByName.html","id":null,"dir":"Reference","previous_headings":"","what":"Get metadata. — experimentsGetByName","title":"Get metadata. — experimentsGetByName","text":"Gets metadata experiment.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetByName.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get metadata. — experimentsGetByName","text":"","code":"experimentsGetByName(client, experiment_name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetByName.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get metadata. — experimentsGetByName","text":"client Required. Instance DatabricksClient() experiment_name Required. Name associated experiment.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetByName.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get metadata. — experimentsGetByName","text":"endpoint return deleted experiments, prefers active experiment active deleted experiment share name. multiple deleted experiments share name, API return one . Throws RESOURCE_DOES_NOT_EXIST experiment specified name exists.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetExperiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Get an experiment. — experimentsGetExperiment","title":"Get an experiment. — experimentsGetExperiment","text":"Gets metadata experiment. method works deleted experiments.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetExperiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get an experiment. — experimentsGetExperiment","text":"","code":"experimentsGetExperiment(client, experiment_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetExperiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get an experiment. — experimentsGetExperiment","text":"client Required. Instance DatabricksClient() experiment_id Required. ID associated experiment.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetExperimentPermissionLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Get experiment permission levels. — experimentsGetExperimentPermissionLevels","title":"Get experiment permission levels. — experimentsGetExperimentPermissionLevels","text":"Gets permission levels user can object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetExperimentPermissionLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get experiment permission levels. — experimentsGetExperimentPermissionLevels","text":"","code":"experimentsGetExperimentPermissionLevels(client, experiment_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetExperimentPermissionLevels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get experiment permission levels. — experimentsGetExperimentPermissionLevels","text":"client Required. Instance DatabricksClient() experiment_id Required. experiment get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetExperimentPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get experiment permissions. — experimentsGetExperimentPermissions","title":"Get experiment permissions. — experimentsGetExperimentPermissions","text":"Gets permissions experiment. Experiments can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetExperimentPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get experiment permissions. — experimentsGetExperimentPermissions","text":"","code":"experimentsGetExperimentPermissions(client, experiment_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetExperimentPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get experiment permissions. — experimentsGetExperimentPermissions","text":"client Required. Instance DatabricksClient() experiment_id Required. experiment get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetHistory.html","id":null,"dir":"Reference","previous_headings":"","what":"Get history of a given metric within a run. — experimentsGetHistory","title":"Get history of a given metric within a run. — experimentsGetHistory","text":"Gets list values specified metric given run.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetHistory.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get history of a given metric within a run. — experimentsGetHistory","text":"","code":"experimentsGetHistory(   client,   metric_key,   max_results = NULL,   page_token = NULL,   run_id = NULL,   run_uuid = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetHistory.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get history of a given metric within a run. — experimentsGetHistory","text":"client Required. Instance DatabricksClient() metric_key Required. Name metric. max_results Maximum number Metric records return per paginated request. page_token Token indicating page metric histories fetch. run_id ID run fetch metric values. run_uuid Deprecated, use run_id instead ID run fetch metric values.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetRun.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a run. — experimentsGetRun","title":"Get a run. — experimentsGetRun","text":"Gets metadata, metrics, params, tags run. case multiple metrics key logged run, return value latest timestamp.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetRun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a run. — experimentsGetRun","text":"","code":"experimentsGetRun(client, run_id, run_uuid = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetRun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a run. — experimentsGetRun","text":"client Required. Instance DatabricksClient() run_id Required. ID run fetch. run_uuid Deprecated, use run_id instead ID run fetch.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsGetRun.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get a run. — experimentsGetRun","text":"multiple values latest timestamp, return maximum values.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsListArtifacts.html","id":null,"dir":"Reference","previous_headings":"","what":"Get all artifacts. — experimentsListArtifacts","title":"Get all artifacts. — experimentsListArtifacts","text":"List artifacts run. Takes optional artifact_path prefix. specified, response contains artifacts specified prefix.',","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsListArtifacts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get all artifacts. — experimentsListArtifacts","text":"","code":"experimentsListArtifacts(   client,   page_token = NULL,   path = NULL,   run_id = NULL,   run_uuid = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsListArtifacts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get all artifacts. — experimentsListArtifacts","text":"client Required. Instance DatabricksClient() page_token Token indicating page artifact results fetch. path Filter artifacts matching path (relative path root artifact directory). run_id ID run whose artifacts list. run_uuid Deprecated, use run_id instead ID run whose artifacts list.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsListArtifacts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get all artifacts. — experimentsListArtifacts","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsListExperiments.html","id":null,"dir":"Reference","previous_headings":"","what":"List experiments. — experimentsListExperiments","title":"List experiments. — experimentsListExperiments","text":"Gets list experiments.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsListExperiments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List experiments. — experimentsListExperiments","text":"","code":"experimentsListExperiments(   client,   max_results = NULL,   page_token = NULL,   view_type = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsListExperiments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List experiments. — experimentsListExperiments","text":"client Required. Instance DatabricksClient() max_results Maximum number experiments desired. page_token Token indicating page experiments fetch. view_type Qualifier type experiments returned.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsListExperiments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List experiments. — experimentsListExperiments","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogBatch.html","id":null,"dir":"Reference","previous_headings":"","what":"Log a batch. — experimentsLogBatch","title":"Log a batch. — experimentsLogBatch","text":"Logs batch metrics, params, tags run. data failed persisted, server respond error (non-200 status code).","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogBatch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log a batch. — experimentsLogBatch","text":"","code":"experimentsLogBatch(   client,   metrics = NULL,   params = NULL,   run_id = NULL,   tags = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogBatch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log a batch. — experimentsLogBatch","text":"client Required. Instance DatabricksClient() metrics Metrics log. params Params log. run_id ID run log . tags Tags log.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogBatch.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log a batch. — experimentsLogBatch","text":"case error (due internal server error invalid request), partial data may written. can write metrics, params, tags interleaving fashion, within given entity type guaranteed follow order specified request body. overwrite behavior metrics, params, tags follows: Metrics: metric values never overwritten. Logging metric (key, value, timestamp) appends set values metric provided key. Tags: tag values can overwritten successive writes tag key. , multiple tag values key provided API request, last-provided tag value written. Logging tag (key, value) permitted. Specifically, logging tag idempotent. Parameters: written, param values changed (attempting overwrite param value result error). However, logging param (key, value) permitted. Specifically, logging param idempotent. Request Limits ------------------------------- single JSON-serialized API request may 1 MB size contain: 1000 metrics, params, tags total * 1000 metrics * 100 params * 100 tags example, valid request might contain 900 metrics, 50 params, 50 tags, logging 900 metrics, 50 params, 51 tags invalid. following limits also apply metric, param, tag keys values: Metric keys, param keys, tag keys can 250 characters length Parameter tag values can 250 characters length","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogInputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Log inputs to a run. — experimentsLogInputs","title":"Log inputs to a run. — experimentsLogInputs","text":"NOTE: Experimental: API may change removed future release without warning.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogInputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log inputs to a run. — experimentsLogInputs","text":"","code":"experimentsLogInputs(client, datasets = NULL, run_id = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogInputs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log inputs to a run. — experimentsLogInputs","text":"client Required. Instance DatabricksClient() datasets Dataset inputs. run_id ID run log .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogMetric.html","id":null,"dir":"Reference","previous_headings":"","what":"Log a metric. — experimentsLogMetric","title":"Log a metric. — experimentsLogMetric","text":"Logs metric run. metric key-value pair (string key, float value) associated timestamp. Examples include various metrics represent ML model accuracy. metric can logged multiple times.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogMetric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log a metric. — experimentsLogMetric","text":"","code":"experimentsLogMetric(   client,   key,   value,   timestamp,   run_id = NULL,   run_uuid = NULL,   step = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogMetric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log a metric. — experimentsLogMetric","text":"client Required. Instance DatabricksClient() key Required. Name metric. value Required. Double value metric logged. timestamp Required. Unix timestamp milliseconds time metric logged. run_id ID run log metric. run_uuid Deprecated, use run_id instead ID run log metric. step Step log metric.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Log a model. — experimentsLogModel","title":"Log a model. — experimentsLogModel","text":"NOTE: Experimental: API may change removed future release without warning.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log a model. — experimentsLogModel","text":"","code":"experimentsLogModel(client, model_json = NULL, run_id = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log a model. — experimentsLogModel","text":"client Required. Instance DatabricksClient() model_json MLmodel file json format. run_id ID run log .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogParam.html","id":null,"dir":"Reference","previous_headings":"","what":"Log a param. — experimentsLogParam","title":"Log a param. — experimentsLogParam","text":"Logs param used run. param key-value pair (string key, string value). Examples include hyperparameters used ML model training constant dates values used ETL pipeline. param can logged run.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogParam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log a param. — experimentsLogParam","text":"","code":"experimentsLogParam(client, key, value, run_id = NULL, run_uuid = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsLogParam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log a param. — experimentsLogParam","text":"client Required. Instance DatabricksClient() key Required. Name param. value Required. String value param logged. run_id ID run log param. run_uuid Deprecated, use run_id instead ID run log param.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsRestoreExperiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Restores an experiment. — experimentsRestoreExperiment","title":"Restores an experiment. — experimentsRestoreExperiment","text":"Restore experiment marked deletion. also restores associated metadata, runs, metrics, params, tags. experiment uses FileStore, underlying artifacts associated experiment also restored.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsRestoreExperiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restores an experiment. — experimentsRestoreExperiment","text":"","code":"experimentsRestoreExperiment(client, experiment_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsRestoreExperiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restores an experiment. — experimentsRestoreExperiment","text":"client Required. Instance DatabricksClient() experiment_id Required. ID associated experiment.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsRestoreExperiment.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Restores an experiment. — experimentsRestoreExperiment","text":"Throws RESOURCE_DOES_NOT_EXIST experiment never created permanently deleted.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsRestoreRun.html","id":null,"dir":"Reference","previous_headings":"","what":"Restore a run. — experimentsRestoreRun","title":"Restore a run. — experimentsRestoreRun","text":"Restores deleted run.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsRestoreRun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restore a run. — experimentsRestoreRun","text":"","code":"experimentsRestoreRun(client, run_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsRestoreRun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restore a run. — experimentsRestoreRun","text":"client Required. Instance DatabricksClient() run_id Required. ID run restore.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSearchExperiments.html","id":null,"dir":"Reference","previous_headings":"","what":"Search experiments. — experimentsSearchExperiments","title":"Search experiments. — experimentsSearchExperiments","text":"Searches experiments satisfy specified search criteria.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSearchExperiments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search experiments. — experimentsSearchExperiments","text":"","code":"experimentsSearchExperiments(   client,   filter = NULL,   max_results = NULL,   order_by = NULL,   page_token = NULL,   view_type = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSearchExperiments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search experiments. — experimentsSearchExperiments","text":"client Required. Instance DatabricksClient() filter String representing SQL filter condition (e.g. max_results Maximum number experiments desired. order_by List columns ordering search results, can include experiment name last updated timestamp optional 'DESC' 'ASC' annotation, 'ASC' default. page_token Token indicating page experiments fetch. view_type Qualifier type experiments returned.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSearchExperiments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search experiments. — experimentsSearchExperiments","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSearchRuns.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for runs. — experimentsSearchRuns","title":"Search for runs. — experimentsSearchRuns","text":"Searches runs satisfy expressions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSearchRuns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for runs. — experimentsSearchRuns","text":"","code":"experimentsSearchRuns(   client,   experiment_ids = NULL,   filter = NULL,   max_results = NULL,   order_by = NULL,   page_token = NULL,   run_view_type = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSearchRuns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for runs. — experimentsSearchRuns","text":"client Required. Instance DatabricksClient() experiment_ids List experiment IDs search . filter filter expression params, metrics, tags, allows returning subset runs. max_results Maximum number runs desired. order_by List columns ordered , including attributes, params, metrics, tags optional 'DESC' 'ASC' annotation, 'ASC' default. page_token Token current page runs. run_view_type Whether display active, deleted, runs.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSearchRuns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for runs. — experimentsSearchRuns","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSearchRuns.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Search for runs. — experimentsSearchRuns","text":"Search expressions can use mlflowMetric mlflowParam keys.',","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSetExperimentPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Set experiment permissions. — experimentsSetExperimentPermissions","title":"Set experiment permissions. — experimentsSetExperimentPermissions","text":"Sets permissions experiment. Experiments can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSetExperimentPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set experiment permissions. — experimentsSetExperimentPermissions","text":"","code":"experimentsSetExperimentPermissions(   client,   experiment_id,   access_control_list = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSetExperimentPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set experiment permissions. — experimentsSetExperimentPermissions","text":"client Required. Instance DatabricksClient() experiment_id Required. experiment get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSetExperimentTag.html","id":null,"dir":"Reference","previous_headings":"","what":"Set a tag. — experimentsSetExperimentTag","title":"Set a tag. — experimentsSetExperimentTag","text":"Sets tag experiment. Experiment tags metadata can updated.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSetExperimentTag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set a tag. — experimentsSetExperimentTag","text":"","code":"experimentsSetExperimentTag(client, experiment_id, key, value)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSetExperimentTag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set a tag. — experimentsSetExperimentTag","text":"client Required. Instance DatabricksClient() experiment_id Required. ID experiment log tag. key Required. Name tag. value Required. String value tag logged.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSetTag.html","id":null,"dir":"Reference","previous_headings":"","what":"Set a tag. — experimentsSetTag","title":"Set a tag. — experimentsSetTag","text":"Sets tag run. Tags run metadata can updated run run completes.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSetTag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set a tag. — experimentsSetTag","text":"","code":"experimentsSetTag(client, key, value, run_id = NULL, run_uuid = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsSetTag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set a tag. — experimentsSetTag","text":"client Required. Instance DatabricksClient() key Required. Name tag. value Required. String value tag logged. run_id ID run log tag. run_uuid Deprecated, use run_id instead ID run log tag.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsUpdateExperiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Update an experiment. — experimentsUpdateExperiment","title":"Update an experiment. — experimentsUpdateExperiment","text":"Updates experiment metadata.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsUpdateExperiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update an experiment. — experimentsUpdateExperiment","text":"","code":"experimentsUpdateExperiment(client, experiment_id, new_name = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsUpdateExperiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update an experiment. — experimentsUpdateExperiment","text":"client Required. Instance DatabricksClient() experiment_id Required. ID associated experiment. new_name provided, experiment's name changed new name.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsUpdateExperimentPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Update experiment permissions. — experimentsUpdateExperimentPermissions","title":"Update experiment permissions. — experimentsUpdateExperimentPermissions","text":"Updates permissions experiment. Experiments can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsUpdateExperimentPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update experiment permissions. — experimentsUpdateExperimentPermissions","text":"","code":"experimentsUpdateExperimentPermissions(   client,   experiment_id,   access_control_list = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsUpdateExperimentPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update experiment permissions. — experimentsUpdateExperimentPermissions","text":"client Required. Instance DatabricksClient() experiment_id Required. experiment get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsUpdateRun.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a run. — experimentsUpdateRun","title":"Update a run. — experimentsUpdateRun","text":"Updates run metadata.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsUpdateRun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a run. — experimentsUpdateRun","text":"","code":"experimentsUpdateRun(   client,   end_time = NULL,   run_id = NULL,   run_uuid = NULL,   status = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/experimentsUpdateRun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a run. — experimentsUpdateRun","text":"client Required. Instance DatabricksClient() end_time Unix timestamp milliseconds run ended. run_id ID run update. run_uuid Deprecated, use run_id instead ID run update. status Updated status run.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an external location. — externalLocationsCreate","title":"Create an external location. — externalLocationsCreate","text":"Creates new external location entry metastore. caller must metastore admin CREATE_EXTERNAL_LOCATION privilege metastore associated storage credential.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an external location. — externalLocationsCreate","text":"","code":"externalLocationsCreate(   client,   name,   url,   credential_name,   access_point = NULL,   comment = NULL,   encryption_details = NULL,   read_only = NULL,   skip_validation = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an external location. — externalLocationsCreate","text":"client Required. Instance DatabricksClient() name Required. Name external location. url Required. Path URL external location. credential_name Required. Name storage credential used location. access_point AWS access point use accesing s3 external location. comment User-provided free-form text description. encryption_details Encryption options apply clients connecting cloud storage. read_only Indicates whether external location read-. skip_validation Skips validation storage credential associated external location.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete an external location. — externalLocationsDelete","title":"Delete an external location. — externalLocationsDelete","text":"Deletes specified external location metastore. caller must owner external location.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete an external location. — externalLocationsDelete","text":"","code":"externalLocationsDelete(client, name, force = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete an external location. — externalLocationsDelete","text":"client Required. Instance DatabricksClient() name Required. Name external location. force Force deletion even dependent external tables mounts.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get an external location. — externalLocationsGet","title":"Get an external location. — externalLocationsGet","text":"Gets external location metastore. caller must either metastore admin, owner external location, user privilege external location.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get an external location. — externalLocationsGet","text":"","code":"externalLocationsGet(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get an external location. — externalLocationsGet","text":"client Required. Instance DatabricksClient() name Required. Name external location.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsList.html","id":null,"dir":"Reference","previous_headings":"","what":"List external locations. — externalLocationsList","title":"List external locations. — externalLocationsList","text":"Gets array external locations (ExternalLocationInfo objects) metastore. caller must metastore admin, owner external location, user privilege external location. guarantee specific ordering elements array.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List external locations. — externalLocationsList","text":"","code":"externalLocationsList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List external locations. — externalLocationsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update an external location. — externalLocationsUpdate","title":"Update an external location. — externalLocationsUpdate","text":"Updates external location metastore. caller must owner external location, metastore admin. second case, admin can update name external location.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update an external location. — externalLocationsUpdate","text":"","code":"externalLocationsUpdate(   client,   name,   access_point = NULL,   comment = NULL,   credential_name = NULL,   encryption_details = NULL,   force = NULL,   owner = NULL,   read_only = NULL,   url = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/externalLocationsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update an external location. — externalLocationsUpdate","text":"client Required. Instance DatabricksClient() name Name external location. access_point AWS access point use accesing s3 external location. comment User-provided free-form text description. credential_name Name storage credential used location. encryption_details Encryption options apply clients connecting cloud storage. force Force update even changing url invalidates dependent external tables mounts. owner owner external location. read_only Indicates whether external location read-. url Path URL external location.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a function. — functionsCreate","title":"Create a function. — functionsCreate","text":"Creates new function","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a function. — functionsCreate","text":"","code":"functionsCreate(   client,   name,   catalog_name,   schema_name,   input_params,   data_type,   full_data_type,   return_params,   routine_body,   routine_definition,   routine_dependencies,   parameter_style,   is_deterministic,   sql_data_access,   is_null_call,   security_type,   specific_name,   comment = NULL,   external_language = NULL,   external_name = NULL,   properties = NULL,   sql_path = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a function. — functionsCreate","text":"client Required. Instance DatabricksClient() name Required. Name function, relative parent schema. catalog_name Required. Name parent catalog. schema_name Required. Name parent schema relative parent catalog. input_params Required. array FunctionParameterInfo definitions function's parameters. data_type Required. Scalar function return data type. full_data_type Required. Pretty printed function data type. return_params Required. Table function return parameters. routine_body Required. Function language. routine_definition Required. Function body. routine_dependencies Required. Function dependencies. parameter_style Required. Function parameter style. is_deterministic Required. Whether function deterministic. sql_data_access Required. Function SQL data access. is_null_call Required. Function null call. security_type Required. Function security type. specific_name Required. Specific name function; Reserved future use. comment User-provided free-form text description. external_language External function language. external_name External function name. properties map key-value properties attached securable. sql_path List schemes whose objects can referenced without qualification.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsCreate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a function. — functionsCreate","text":"user must following permissions order function created: - USE_CATALOG function's parent catalog - USE_SCHEMA CREATE_FUNCTION function's parent schema","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a function. — functionsDelete","title":"Delete a function. — functionsDelete","text":"Deletes function matches supplied name. deletion succeed, user must satisfy one following conditions: - owner function's parent catalog - owner function's parent schema USE_CATALOG privilege parent catalog - owner function USE_CATALOG privilege parent catalog USE_SCHEMA privilege parent schema","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a function. — functionsDelete","text":"","code":"functionsDelete(client, name, force = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a function. — functionsDelete","text":"client Required. Instance DatabricksClient() name Required. fully-qualified name function (form catalog_name.schema_name.function__name). force Force deletion even function notempty.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a function. — functionsGet","title":"Get a function. — functionsGet","text":"Gets function within parent catalog schema. fetch succeed, user must satisfy one following requirements: - metastore admin - owner function's parent catalog - USE_CATALOG privilege function's parent catalog owner function - USE_CATALOG privilege function's parent catalog, USE_SCHEMA privilege function's parent schema, EXECUTE privilege function ","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a function. — functionsGet","text":"","code":"functionsGet(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a function. — functionsGet","text":"client Required. Instance DatabricksClient() name Required. fully-qualified name function (form catalog_name.schema_name.function__name).","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsList.html","id":null,"dir":"Reference","previous_headings":"","what":"List functions. — functionsList","title":"List functions. — functionsList","text":"List functions within specified parent catalog schema. user metastore admin, functions returned output list. Otherwise, user must USE_CATALOG privilege catalog USE_SCHEMA privilege schema, output list contains functions either user EXECUTE privilege user owner. guarantee specific ordering elements array.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List functions. — functionsList","text":"","code":"functionsList(client, catalog_name, schema_name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List functions. — functionsList","text":"client Required. Instance DatabricksClient() catalog_name Required. Name parent catalog functions interest. schema_name Required. Parent schema functions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List functions. — functionsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a function. — functionsUpdate","title":"Update a function. — functionsUpdate","text":"Updates function matches supplied name. owner function can updated. user metastore admin, user must member group new function owner. - metastore admin - owner function's parent catalog - owner function's parent schema USE_CATALOG privilege parent catalog - owner function USE_CATALOG privilege parent catalog well USE_SCHEMA privilege function's parent schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a function. — functionsUpdate","text":"","code":"functionsUpdate(client, name, owner = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/functionsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a function. — functionsUpdate","text":"client Required. Instance DatabricksClient() name Required. fully-qualified name function (form catalog_name.schema_name.function__name). owner Username current owner function.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a credential entry. — gitCredentialsCreate","title":"Create a credential entry. — gitCredentialsCreate","text":"Creates Git credential entry user. one Git credential per user supported, attempts create credentials entry already exists fail. Use PATCH endpoint update existing credentials, DELETE endpoint delete existing credentials.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a credential entry. — gitCredentialsCreate","text":"","code":"gitCredentialsCreate(   client,   git_provider,   git_username = NULL,   personal_access_token = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a credential entry. — gitCredentialsCreate","text":"client Required. Instance DatabricksClient() git_provider Required. Git provider. git_username Git username. personal_access_token personal access token used authenticate corresponding Git provider.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a credential. — gitCredentialsDelete","title":"Delete a credential. — gitCredentialsDelete","text":"Deletes specified Git credential.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a credential. — gitCredentialsDelete","text":"","code":"gitCredentialsDelete(client, credential_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a credential. — gitCredentialsDelete","text":"client Required. Instance DatabricksClient() credential_id Required. ID corresponding credential access.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a credential entry. — gitCredentialsGet","title":"Get a credential entry. — gitCredentialsGet","text":"Gets Git credential specified credential ID.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a credential entry. — gitCredentialsGet","text":"","code":"gitCredentialsGet(client, credential_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a credential entry. — gitCredentialsGet","text":"client Required. Instance DatabricksClient() credential_id Required. ID corresponding credential access.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsList.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Git credentials. — gitCredentialsList","title":"Get Git credentials. — gitCredentialsList","text":"Lists calling user's Git credentials. One credential per user supported.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Git credentials. — gitCredentialsList","text":"","code":"gitCredentialsList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Git credentials. — gitCredentialsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a credential. — gitCredentialsUpdate","title":"Update a credential. — gitCredentialsUpdate","text":"Updates specified Git credential.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a credential. — gitCredentialsUpdate","text":"","code":"gitCredentialsUpdate(   client,   credential_id,   git_provider = NULL,   git_username = NULL,   personal_access_token = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/gitCredentialsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a credential. — gitCredentialsUpdate","text":"client Required. Instance DatabricksClient() credential_id Required. ID corresponding credential access. git_provider Git provider. git_username Git username. personal_access_token personal access token used authenticate corresponding Git provider.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create init script. — globalInitScriptsCreate","title":"Create init script. — globalInitScriptsCreate","text":"Creates new global init script workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create init script. — globalInitScriptsCreate","text":"","code":"globalInitScriptsCreate(client, name, script, enabled = NULL, position = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create init script. — globalInitScriptsCreate","text":"client Required. Instance DatabricksClient() name Required. name script. script Required. Base64-encoded content script. enabled Specifies whether script enabled. position position global init script, 0 represents first script run, 1 second script run, ascending order.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete init script. — globalInitScriptsDelete","title":"Delete init script. — globalInitScriptsDelete","text":"Deletes global init script.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete init script. — globalInitScriptsDelete","text":"","code":"globalInitScriptsDelete(client, script_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete init script. — globalInitScriptsDelete","text":"client Required. Instance DatabricksClient() script_id Required. ID global init script.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get an init script. — globalInitScriptsGet","title":"Get an init script. — globalInitScriptsGet","text":"Gets details script, including Base64-encoded contents.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get an init script. — globalInitScriptsGet","text":"","code":"globalInitScriptsGet(client, script_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get an init script. — globalInitScriptsGet","text":"client Required. Instance DatabricksClient() script_id Required. ID global init script.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsList.html","id":null,"dir":"Reference","previous_headings":"","what":"Get init scripts. — globalInitScriptsList","title":"Get init scripts. — globalInitScriptsList","text":"Get list global init scripts workspace. returns properties script script contents. retrieve contents script, use get global init script operation.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get init scripts. — globalInitScriptsList","text":"","code":"globalInitScriptsList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get init scripts. — globalInitScriptsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update init script. — globalInitScriptsUpdate","title":"Update init script. — globalInitScriptsUpdate","text":"Updates global init script, specifying fields change. fields optional. Unspecified fields retain current value.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update init script. — globalInitScriptsUpdate","text":"","code":"globalInitScriptsUpdate(   client,   name,   script,   script_id,   enabled = NULL,   position = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/globalInitScriptsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update init script. — globalInitScriptsUpdate","text":"client Required. Instance DatabricksClient() name Required. name script. script Required. Base64-encoded content script. script_id Required. ID global init script. enabled Specifies whether script enabled. position position script, 0 represents first script run, 1 second script run, ascending order.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/grantsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get permissions. — grantsGet","title":"Get permissions. — grantsGet","text":"Gets permissions securable.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/grantsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get permissions. — grantsGet","text":"","code":"grantsGet(client, securable_type, full_name, principal = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/grantsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get permissions. — grantsGet","text":"client Required. Instance DatabricksClient() securable_type Required. Type securable. full_name Required. Full name securable. principal provided, permissions specified principal (user group) returned.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/grantsGetEffective.html","id":null,"dir":"Reference","previous_headings":"","what":"Get effective permissions. — grantsGetEffective","title":"Get effective permissions. — grantsGetEffective","text":"Gets effective permissions securable.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/grantsGetEffective.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get effective permissions. — grantsGetEffective","text":"","code":"grantsGetEffective(client, securable_type, full_name, principal = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/grantsGetEffective.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get effective permissions. — grantsGetEffective","text":"client Required. Instance DatabricksClient() securable_type Required. Type securable. full_name Required. Full name securable. principal provided, effective permissions specified principal (user group) returned.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/grantsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update permissions. — grantsUpdate","title":"Update permissions. — grantsUpdate","text":"Updates permissions securable.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/grantsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update permissions. — grantsUpdate","text":"","code":"grantsUpdate(client, securable_type, full_name, changes = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/grantsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update permissions. — grantsUpdate","text":"client Required. Instance DatabricksClient() securable_type Required. Type securable. full_name Required. Full name securable. changes Array permissions change objects.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new group. — groupsCreate","title":"Create a new group. — groupsCreate","text":"Creates group Databricks workspace unique name, using supplied group details.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new group. — groupsCreate","text":"","code":"groupsCreate(   client,   display_name = NULL,   entitlements = NULL,   external_id = NULL,   groups = NULL,   id = NULL,   members = NULL,   meta = NULL,   roles = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new group. — groupsCreate","text":"client Required. Instance DatabricksClient() display_name String represents human-readable group name. entitlements  external_id  groups  id Databricks group ID. members  meta Container group identifier. roles","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a group. — groupsDelete","title":"Delete a group. — groupsDelete","text":"Deletes group Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a group. — groupsDelete","text":"","code":"groupsDelete(client, id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a group. — groupsDelete","text":"client Required. Instance DatabricksClient() id Required. Unique ID group Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get group details. — groupsGet","title":"Get group details. — groupsGet","text":"Gets information specific group Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get group details. — groupsGet","text":"","code":"groupsGet(client, id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get group details. — groupsGet","text":"client Required. Instance DatabricksClient() id Required. Unique ID group Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsList.html","id":null,"dir":"Reference","previous_headings":"","what":"List group details. — groupsList","title":"List group details. — groupsList","text":"Gets details groups associated Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List group details. — groupsList","text":"","code":"groupsList(   client,   attributes = NULL,   count = NULL,   excluded_attributes = NULL,   filter = NULL,   sort_by = NULL,   sort_order = NULL,   start_index = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List group details. — groupsList","text":"client Required. Instance DatabricksClient() attributes Comma-separated list attributes return response. count Desired number results per page. excluded_attributes Comma-separated list attributes exclude response. filter Query results filtered. sort_by Attribute sort results. sort_order order sort results. start_index Specifies index first result.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List group details. — groupsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsPatch.html","id":null,"dir":"Reference","previous_headings":"","what":"Update group details. — groupsPatch","title":"Update group details. — groupsPatch","text":"Partially updates details group.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsPatch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update group details. — groupsPatch","text":"","code":"groupsPatch(client, id, operations = NULL, schema = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsPatch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update group details. — groupsPatch","text":"client Required. Instance DatabricksClient() id Required. Unique ID group Databricks workspace. operations  schema schema patch request.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace a group. — groupsUpdate","title":"Replace a group. — groupsUpdate","text":"Updates details group replacing entire group entity.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace a group. — groupsUpdate","text":"","code":"groupsUpdate(   client,   id,   display_name = NULL,   entitlements = NULL,   external_id = NULL,   groups = NULL,   members = NULL,   meta = NULL,   roles = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/groupsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace a group. — groupsUpdate","text":"client Required. Instance DatabricksClient() id Databricks group ID. display_name String represents human-readable group name. entitlements  external_id  groups  members  meta Container group identifier. roles","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new instance pool. — instancePoolsCreate","title":"Create a new instance pool. — instancePoolsCreate","text":"Creates new instance pool using idle ready--use cloud instances.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new instance pool. — instancePoolsCreate","text":"","code":"instancePoolsCreate(   client,   instance_pool_name,   node_type_id,   aws_attributes = NULL,   azure_attributes = NULL,   custom_tags = NULL,   disk_spec = NULL,   enable_elastic_disk = NULL,   gcp_attributes = NULL,   idle_instance_autotermination_minutes = NULL,   instance_pool_fleet_attributes = NULL,   max_capacity = NULL,   min_idle_instances = NULL,   preloaded_docker_images = NULL,   preloaded_spark_versions = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new instance pool. — instancePoolsCreate","text":"client Required. Instance DatabricksClient() instance_pool_name Required. Pool name requested user. node_type_id Required. field encodes, single value, resources available Spark nodes cluster. aws_attributes Attributes related instance pools running Amazon Web Services. azure_attributes Attributes related instance pools running Azure. custom_tags Additional tags pool resources. disk_spec Defines specification disks attached spark containers. enable_elastic_disk Autoscaling Local Storage: enabled, instances pool dynamically acquire additional disk space Spark workers running low disk space. gcp_attributes Attributes related instance pools running Google Cloud Platform. idle_instance_autotermination_minutes Automatically terminates extra instances pool cache inactive time minutes min_idle_instances requirement already met. instance_pool_fleet_attributes fleet related setting power instance pool. max_capacity Maximum number outstanding instances keep pool, including instances used clusters idle instances. min_idle_instances Minimum number idle instances keep instance pool. preloaded_docker_images Custom Docker Image BYOC. preloaded_spark_versions list preloaded Spark image versions pool.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete an instance pool. — instancePoolsDelete","title":"Delete an instance pool. — instancePoolsDelete","text":"Deletes instance pool permanently. idle instances pool terminated asynchronously.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete an instance pool. — instancePoolsDelete","text":"","code":"instancePoolsDelete(client, instance_pool_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete an instance pool. — instancePoolsDelete","text":"client Required. Instance DatabricksClient() instance_pool_id Required. instance pool terminated.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsEdit.html","id":null,"dir":"Reference","previous_headings":"","what":"Edit an existing instance pool. — instancePoolsEdit","title":"Edit an existing instance pool. — instancePoolsEdit","text":"Modifies configuration existing instance pool.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsEdit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Edit an existing instance pool. — instancePoolsEdit","text":"","code":"instancePoolsEdit(   client,   instance_pool_id,   instance_pool_name,   node_type_id,   aws_attributes = NULL,   azure_attributes = NULL,   custom_tags = NULL,   disk_spec = NULL,   enable_elastic_disk = NULL,   gcp_attributes = NULL,   idle_instance_autotermination_minutes = NULL,   instance_pool_fleet_attributes = NULL,   max_capacity = NULL,   min_idle_instances = NULL,   preloaded_docker_images = NULL,   preloaded_spark_versions = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsEdit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Edit an existing instance pool. — instancePoolsEdit","text":"client Required. Instance DatabricksClient() instance_pool_id Required. Instance pool ID. instance_pool_name Required. Pool name requested user. node_type_id Required. field encodes, single value, resources available Spark nodes cluster. aws_attributes Attributes related instance pools running Amazon Web Services. azure_attributes Attributes related instance pools running Azure. custom_tags Additional tags pool resources. disk_spec Defines specification disks attached spark containers. enable_elastic_disk Autoscaling Local Storage: enabled, instances pool dynamically acquire additional disk space Spark workers running low disk space. gcp_attributes Attributes related instance pools running Google Cloud Platform. idle_instance_autotermination_minutes Automatically terminates extra instances pool cache inactive time minutes min_idle_instances requirement already met. instance_pool_fleet_attributes fleet related setting power instance pool. max_capacity Maximum number outstanding instances keep pool, including instances used clusters idle instances. min_idle_instances Minimum number idle instances keep instance pool. preloaded_docker_images Custom Docker Image BYOC. preloaded_spark_versions list preloaded Spark image versions pool.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get instance pool information. — instancePoolsGet","title":"Get instance pool information. — instancePoolsGet","text":"Retrieve information instance pool based identifier.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get instance pool information. — instancePoolsGet","text":"","code":"instancePoolsGet(client, instance_pool_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get instance pool information. — instancePoolsGet","text":"client Required. Instance DatabricksClient() instance_pool_id Required. canonical unique identifier instance pool.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsInstancePoolId.html","id":null,"dir":"Reference","previous_headings":"","what":"Set instance pool permissions. — instancePoolsInstancePoolId","title":"Set instance pool permissions. — instancePoolsInstancePoolId","text":"Sets permissions instance pool. Instance pools can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsInstancePoolId.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set instance pool permissions. — instancePoolsInstancePoolId","text":"","code":"instancePoolsInstancePoolId(   client,   instance_pool_id,   access_control_list = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsInstancePoolId.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set instance pool permissions. — instancePoolsInstancePoolId","text":"client Required. Instance DatabricksClient() instance_pool_id Required. instance pool get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsList.html","id":null,"dir":"Reference","previous_headings":"","what":"List instance pool info. — instancePoolsList","title":"List instance pool info. — instancePoolsList","text":"Gets list instance pools statistics.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List instance pool info. — instancePoolsList","text":"","code":"instancePoolsList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List instance pool info. — instancePoolsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsPermissionLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Get instance pool permission levels. — instancePoolsPermissionLevels","title":"Get instance pool permission levels. — instancePoolsPermissionLevels","text":"Gets permission levels user can object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsPermissionLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get instance pool permission levels. — instancePoolsPermissionLevels","text":"","code":"instancePoolsPermissionLevels(client, instance_pool_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instancePoolsPermissionLevels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get instance pool permission levels. — instancePoolsPermissionLevels","text":"client Required. Instance DatabricksClient() instance_pool_id Required. instance pool get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesAdd.html","id":null,"dir":"Reference","previous_headings":"","what":"Register an instance profile. — instanceProfilesAdd","title":"Register an instance profile. — instanceProfilesAdd","text":"UI, can select instance profile launching clusters. API available admin users.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesAdd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Register an instance profile. — instanceProfilesAdd","text":"","code":"instanceProfilesAdd(   client,   instance_profile_arn,   iam_role_arn = NULL,   is_meta_instance_profile = NULL,   skip_validation = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesAdd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Register an instance profile. — instanceProfilesAdd","text":"client Required. Instance DatabricksClient() instance_profile_arn Required. AWS ARN instance profile register Databricks. iam_role_arn AWS IAM role ARN role associated instance profile. is_meta_instance_profile Boolean flag indicating whether instance profile used credential passthrough scenarios. skip_validation default, Databricks validates sufficient permissions launch instances instance profile.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesEdit.html","id":null,"dir":"Reference","previous_headings":"","what":"Edit an instance profile. — instanceProfilesEdit","title":"Edit an instance profile. — instanceProfilesEdit","text":"supported field change optional IAM role ARN associated instance profile. required specify IAM role ARN following true:","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesEdit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Edit an instance profile. — instanceProfilesEdit","text":"","code":"instanceProfilesEdit(   client,   instance_profile_arn,   iam_role_arn = NULL,   is_meta_instance_profile = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesEdit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Edit an instance profile. — instanceProfilesEdit","text":"client Required. Instance DatabricksClient() instance_profile_arn Required. AWS ARN instance profile register Databricks. iam_role_arn AWS IAM role ARN role associated instance profile. is_meta_instance_profile Boolean flag indicating whether instance profile used credential passthrough scenarios.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesEdit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Edit an instance profile. — instanceProfilesEdit","text":"role name instance profile name match. name part last slash ARN. * want use instance profile Databricks SQL Serverless. understand fields AWS console, see Enable serverless SQL warehouses. API available admin users.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesList.html","id":null,"dir":"Reference","previous_headings":"","what":"List available instance profiles. — instanceProfilesList","title":"List available instance profiles. — instanceProfilesList","text":"List instance profiles calling user can use launch cluster.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List available instance profiles. — instanceProfilesList","text":"","code":"instanceProfilesList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List available instance profiles. — instanceProfilesList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesList.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List available instance profiles. — instanceProfilesList","text":"API available users.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesRemove.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove the instance profile. — instanceProfilesRemove","title":"Remove the instance profile. — instanceProfilesRemove","text":"Remove instance profile provided ARN. Existing clusters instance profile continue function.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesRemove.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove the instance profile. — instanceProfilesRemove","text":"","code":"instanceProfilesRemove(client, instance_profile_arn)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesRemove.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove the instance profile. — instanceProfilesRemove","text":"client Required. Instance DatabricksClient() instance_profile_arn Required. ARN instance profile remove.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/instanceProfilesRemove.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Remove the instance profile. — instanceProfilesRemove","text":"API accessible admin users.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create access list. — ipAccessListsCreate","title":"Create access list. — ipAccessListsCreate","text":"Creates IP access list workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create access list. — ipAccessListsCreate","text":"","code":"ipAccessListsCreate(client, label, list_type, ip_addresses)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create access list. — ipAccessListsCreate","text":"client Required. Instance DatabricksClient() label Required. Label IP access list. list_type Required. describes enum. ip_addresses Required. Array IP addresses CIDR values added IP access list.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsCreate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create access list. — ipAccessListsCreate","text":"list can allow list block list. See top file description server treats allow lists block lists runtime. creating updating IP access list: allow lists block lists combined, API supports maximum 1000 IP/CIDR values, one CIDR counts single value. Attempts exceed number return error 400 error_code value QUOTA_EXCEEDED. new list block calling user's current IP, error 400 returned error_code value INVALID_STATE. can take minutes changes take effect. Note: new IP access list effect enable feature. See :method:workspaceconf/setStatus","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete access list. — ipAccessListsDelete","title":"Delete access list. — ipAccessListsDelete","text":"Deletes IP access list, specified list ID.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete access list. — ipAccessListsDelete","text":"","code":"ipAccessListsDelete(client, ip_access_list_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete access list. — ipAccessListsDelete","text":"client Required. Instance DatabricksClient() ip_access_list_id Required. ID corresponding IP access list modify.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get access list. — ipAccessListsGet","title":"Get access list. — ipAccessListsGet","text":"Gets IP access list, specified list ID.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get access list. — ipAccessListsGet","text":"","code":"ipAccessListsGet(client, ip_access_list_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get access list. — ipAccessListsGet","text":"client Required. Instance DatabricksClient() ip_access_list_id Required. ID corresponding IP access list modify.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsList.html","id":null,"dir":"Reference","previous_headings":"","what":"Get access lists. — ipAccessListsList","title":"Get access lists. — ipAccessListsList","text":"Gets IP access lists specified workspace.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get access lists. — ipAccessListsList","text":"","code":"ipAccessListsList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get access lists. — ipAccessListsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsReplace.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace access list. — ipAccessListsReplace","title":"Replace access list. — ipAccessListsReplace","text":"Replaces IP access list, specified ID.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsReplace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace access list. — ipAccessListsReplace","text":"","code":"ipAccessListsReplace(   client,   label,   list_type,   ip_addresses,   enabled,   ip_access_list_id,   list_id = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsReplace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace access list. — ipAccessListsReplace","text":"client Required. Instance DatabricksClient() label Required. Label IP access list. list_type Required. describes enum. ip_addresses Required. Array IP addresses CIDR values added IP access list. enabled Required. Specifies whether IP access list enabled. ip_access_list_id Required. ID corresponding IP access list modify. list_id Universally unique identifier (UUID) IP access list.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsReplace.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Replace access list. — ipAccessListsReplace","text":"list can include allow lists block lists. See top file description server treats allow lists block lists run time. replacing IP access list: * allow lists block lists combined, API supports maximum 1000 IP/CIDR values, one CIDR counts single value. Attempts exceed number return error 400 error_code value QUOTA_EXCEEDED. * resulting list block calling user's current IP, error 400 returned error_code value INVALID_STATE. can take minutes changes take effect. Note resulting IP access list effect enable feature. See :method:workspaceconf/setStatus.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update access list. — ipAccessListsUpdate","title":"Update access list. — ipAccessListsUpdate","text":"Updates existing IP access list, specified ID.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update access list. — ipAccessListsUpdate","text":"","code":"ipAccessListsUpdate(   client,   label,   list_type,   ip_addresses,   enabled,   ip_access_list_id,   list_id = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update access list. — ipAccessListsUpdate","text":"client Required. Instance DatabricksClient() label Required. Label IP access list. list_type Required. describes enum. ip_addresses Required. Array IP addresses CIDR values added IP access list. enabled Required. Specifies whether IP access list enabled. ip_access_list_id Required. ID corresponding IP access list modify. list_id Universally unique identifier (UUID) IP access list.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/ipAccessListsUpdate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update access list. — ipAccessListsUpdate","text":"list can include allow lists block lists. See top file description server treats allow lists block lists run time. updating IP access list: allow lists block lists combined, API supports maximum 1000 IP/CIDR values, one CIDR counts single value. Attempts exceed number return error 400 error_code value QUOTA_EXCEEDED. updated list block calling user's current IP, error 400 returned error_code value INVALID_STATE. can take minutes changes take effect. Note resulting IP access list effect enable feature. See :method:workspaceconf/setStatus.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsCancelAllRuns.html","id":null,"dir":"Reference","previous_headings":"","what":"Cancel all runs of a job. — jobsCancelAllRuns","title":"Cancel all runs of a job. — jobsCancelAllRuns","text":"Cancels active runs job. runs canceled asynchronously, prevent new runs started.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsCancelAllRuns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cancel all runs of a job. — jobsCancelAllRuns","text":"","code":"jobsCancelAllRuns(client, job_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsCancelAllRuns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cancel all runs of a job. — jobsCancelAllRuns","text":"client Required. Instance DatabricksClient() job_id Required. canonical identifier job cancel runs .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsCancelRun.html","id":null,"dir":"Reference","previous_headings":"","what":"Cancel a job run. — jobsCancelRun","title":"Cancel a job run. — jobsCancelRun","text":"long-running operation, blocks Jobs Databricks reach TERMINATED SKIPPED state timeout 20 minutes, can change via timeout parameter. default, state Databricks Jobs reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsCancelRun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cancel a job run. — jobsCancelRun","text":"","code":"jobsCancelRun(client, run_id, timeout = 20, callback = cli_reporter)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsCancelRun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cancel a job run. — jobsCancelRun","text":"client Required. Instance DatabricksClient() run_id Required. field required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsCancelRun.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cancel a job run. — jobsCancelRun","text":"Cancels job run. run canceled asynchronously, may still running request completes.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new job. — jobsCreate","title":"Create a new job. — jobsCreate","text":"Create new job.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new job. — jobsCreate","text":"","code":"jobsCreate(   client,   access_control_list = NULL,   compute = NULL,   continuous = NULL,   email_notifications = NULL,   format = NULL,   git_source = NULL,   health = NULL,   job_clusters = NULL,   max_concurrent_runs = NULL,   name = NULL,   notification_settings = NULL,   parameters = NULL,   run_as = NULL,   schedule = NULL,   tags = NULL,   tasks = NULL,   timeout_seconds = NULL,   trigger = NULL,   webhook_notifications = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new job. — jobsCreate","text":"client Required. Instance DatabricksClient() access_control_list List permissions set job. compute list compute requirements can referenced tasks job. continuous optional continuous property job. email_notifications optional set email addresses notified runs job begin complete well job deleted. format Used tell format job. git_source optional specification remote repository containing notebooks used job's notebook tasks. health optional set health rules can defined job. job_clusters list job cluster specifications can shared reused tasks job. max_concurrent_runs optional maximum allowed number concurrent runs job. name optional name job. notification_settings Optional notification settings used sending notifications email_notifications webhook_notifications job. parameters Job-level parameter definitions. run_as Write-setting, available Create/Update/Reset Submit calls. schedule optional periodic schedule job. tags map tags associated job. tasks list task specifications executed job. timeout_seconds optional timeout applied run job. trigger Trigger settings job. webhook_notifications collection system notification IDs notify run begins completes.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a job. — jobsDelete","title":"Delete a job. — jobsDelete","text":"Deletes job.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a job. — jobsDelete","text":"","code":"jobsDelete(client, job_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a job. — jobsDelete","text":"client Required. Instance DatabricksClient() job_id Required. canonical identifier job delete.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsDeleteRun.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a job run. — jobsDeleteRun","title":"Delete a job run. — jobsDeleteRun","text":"Deletes non-active run. Returns error run active.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsDeleteRun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a job run. — jobsDeleteRun","text":"","code":"jobsDeleteRun(client, run_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsDeleteRun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a job run. — jobsDeleteRun","text":"client Required. Instance DatabricksClient() run_id Required. canonical identifier run retrieve metadata.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsExportRun.html","id":null,"dir":"Reference","previous_headings":"","what":"Export and retrieve a job run. — jobsExportRun","title":"Export and retrieve a job run. — jobsExportRun","text":"Export retrieve job run task.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsExportRun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export and retrieve a job run. — jobsExportRun","text":"","code":"jobsExportRun(client, run_id, views_to_export = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsExportRun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export and retrieve a job run. — jobsExportRun","text":"client Required. Instance DatabricksClient() run_id Required. canonical identifier run. views_to_export views export (CODE, DASHBOARDS, ).","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a single job. — jobsGet","title":"Get a single job. — jobsGet","text":"Retrieves details single job.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a single job. — jobsGet","text":"","code":"jobsGet(client, job_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a single job. — jobsGet","text":"client Required. Instance DatabricksClient() job_id Required. canonical identifier job retrieve information .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGetJobPermissionLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Get job permission levels. — jobsGetJobPermissionLevels","title":"Get job permission levels. — jobsGetJobPermissionLevels","text":"Gets permission levels user can object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGetJobPermissionLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get job permission levels. — jobsGetJobPermissionLevels","text":"","code":"jobsGetJobPermissionLevels(client, job_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGetJobPermissionLevels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get job permission levels. — jobsGetJobPermissionLevels","text":"client Required. Instance DatabricksClient() job_id Required. job get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGetJobPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get job permissions. — jobsGetJobPermissions","title":"Get job permissions. — jobsGetJobPermissions","text":"Gets permissions job. Jobs can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGetJobPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get job permissions. — jobsGetJobPermissions","text":"","code":"jobsGetJobPermissions(client, job_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGetJobPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get job permissions. — jobsGetJobPermissions","text":"client Required. Instance DatabricksClient() job_id Required. job get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGetRun.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a single job run. — jobsGetRun","title":"Get a single job run. — jobsGetRun","text":"long-running operation, blocks Jobs Databricks reach TERMINATED SKIPPED state timeout 20 minutes, can change via timeout parameter. default, state Databricks Jobs reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGetRun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a single job run. — jobsGetRun","text":"","code":"jobsGetRun(   client,   run_id,   include_history = NULL,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGetRun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a single job run. — jobsGetRun","text":"client Required. Instance DatabricksClient() run_id Required. canonical identifier run retrieve metadata. include_history Whether include repair history response.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGetRun.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get a single job run. — jobsGetRun","text":"Retrieve metadata run.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGetRunOutput.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the output for a single run. — jobsGetRunOutput","title":"Get the output for a single run. — jobsGetRunOutput","text":"Retrieve output metadata single task run. notebook task returns value dbutils.notebook.exit() call, can use endpoint retrieve value. Databricks restricts API returning first 5 MB output. return larger result, can store job results cloud storage service.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGetRunOutput.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the output for a single run. — jobsGetRunOutput","text":"","code":"jobsGetRunOutput(client, run_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGetRunOutput.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the output for a single run. — jobsGetRunOutput","text":"client Required. Instance DatabricksClient() run_id Required. canonical identifier run.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsGetRunOutput.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the output for a single run. — jobsGetRunOutput","text":"endpoint validates run_id parameter valid returns HTTP status code 400 run_id parameter invalid. Runs automatically removed 60 days. want reference beyond 60 days, must save old run results expire.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsList.html","id":null,"dir":"Reference","previous_headings":"","what":"List jobs. — jobsList","title":"List jobs. — jobsList","text":"Retrieves list jobs.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List jobs. — jobsList","text":"","code":"jobsList(   client,   expand_tasks = NULL,   limit = NULL,   name = NULL,   offset = NULL,   page_token = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List jobs. — jobsList","text":"client Required. Instance DatabricksClient() expand_tasks Whether include task cluster details response. limit number jobs return. name filter list based exact (case insensitive) job name. offset offset first job return, relative recently created job. page_token Use next_page_token prev_page_token returned previous request list next previous page jobs respectively.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List jobs. — jobsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsListRuns.html","id":null,"dir":"Reference","previous_headings":"","what":"List job runs. — jobsListRuns","title":"List job runs. — jobsListRuns","text":"List runs descending order start time.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsListRuns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List job runs. — jobsListRuns","text":"","code":"jobsListRuns(   client,   active_only = NULL,   completed_only = NULL,   expand_tasks = NULL,   job_id = NULL,   limit = NULL,   offset = NULL,   page_token = NULL,   run_type = NULL,   start_time_from = NULL,   start_time_to = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsListRuns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List job runs. — jobsListRuns","text":"client Required. Instance DatabricksClient() active_only active_only true, active runs included results; otherwise, lists active completed runs. completed_only completed_only true, completed runs included results; otherwise, lists active completed runs. expand_tasks Whether include task cluster details response. job_id job list runs. limit number runs return. offset offset first run return, relative recent run. page_token Use next_page_token prev_page_token returned previous request list next previous page runs respectively. run_type type runs return. start_time_from Show runs started value. start_time_to Show runs started value.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsListRuns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List job runs. — jobsListRuns","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsRepairRun.html","id":null,"dir":"Reference","previous_headings":"","what":"Repair a job run. — jobsRepairRun","title":"Repair a job run. — jobsRepairRun","text":"long-running operation, blocks Jobs Databricks reach TERMINATED SKIPPED state timeout 20 minutes, can change via timeout parameter. default, state Databricks Jobs reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsRepairRun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repair a job run. — jobsRepairRun","text":"","code":"jobsRepairRun(   client,   run_id,   dbt_commands = NULL,   jar_params = NULL,   latest_repair_id = NULL,   notebook_params = NULL,   pipeline_params = NULL,   python_named_params = NULL,   python_params = NULL,   rerun_all_failed_tasks = NULL,   rerun_dependent_tasks = NULL,   rerun_tasks = NULL,   spark_submit_params = NULL,   sql_params = NULL,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsRepairRun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Repair a job run. — jobsRepairRun","text":"client Required. Instance DatabricksClient() run_id Required. job run ID run repair. dbt_commands array commands execute jobs dbt task, example 'dbt_commands': ['dbt deps', 'dbt seed', 'dbt run']. jar_params list parameters jobs Spark JAR tasks, example \\'jar_params\\': [\\'john doe\\', \\'35\\']. latest_repair_id ID latest repair. notebook_params map keys values jobs notebook task, example \\'notebook_params\\': {\\'name\\': \\'john doe\\', \\'age\\': \\'35\\'}. pipeline_params  python_named_params map keys values jobs Python wheel task, example 'python_named_params': {'name': 'task', 'data': 'dbfs:/path//data.json'}. python_params list parameters jobs Python tasks, example \\'python_params\\': [\\'john doe\\', \\'35\\']. rerun_all_failed_tasks true, repair failed tasks. rerun_dependent_tasks true, repair tasks depend tasks rerun_tasks, even previously successful. rerun_tasks task keys task runs repair. spark_submit_params list parameters jobs spark submit task, example \\'spark_submit_params\\': [\\'--class\\', \\'org.apache.spark.examples.SparkPi\\']. sql_params map keys values jobs SQL task, example 'sql_params': {'name': 'john doe', 'age': '35'}.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsRepairRun.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Repair a job run. — jobsRepairRun","text":"Re-run one tasks. Tasks re-run part original job run. use current job task settings, can viewed history original job run.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsReset.html","id":null,"dir":"Reference","previous_headings":"","what":"Overwrites all settings for a job. — jobsReset","title":"Overwrites all settings for a job. — jobsReset","text":"Overwrites settings specific job. Use Update endpoint update job settings partially.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsReset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Overwrites all settings for a job. — jobsReset","text":"","code":"jobsReset(client, job_id, new_settings)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsReset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Overwrites all settings for a job. — jobsReset","text":"client Required. Instance DatabricksClient() job_id Required. canonical identifier job reset. new_settings Required. new settings job.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsRunNow.html","id":null,"dir":"Reference","previous_headings":"","what":"Trigger a new job run. — jobsRunNow","title":"Trigger a new job run. — jobsRunNow","text":"long-running operation, blocks Jobs Databricks reach TERMINATED SKIPPED state timeout 20 minutes, can change via timeout parameter. default, state Databricks Jobs reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsRunNow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trigger a new job run. — jobsRunNow","text":"","code":"jobsRunNow(   client,   job_id,   dbt_commands = NULL,   idempotency_token = NULL,   jar_params = NULL,   job_parameters = NULL,   notebook_params = NULL,   pipeline_params = NULL,   python_named_params = NULL,   python_params = NULL,   spark_submit_params = NULL,   sql_params = NULL,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsRunNow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trigger a new job run. — jobsRunNow","text":"client Required. Instance DatabricksClient() job_id Required. ID job executed. dbt_commands array commands execute jobs dbt task, example 'dbt_commands': ['dbt deps', 'dbt seed', 'dbt run']. idempotency_token optional token guarantee idempotency job run requests. jar_params list parameters jobs Spark JAR tasks, example \\'jar_params\\': [\\'john doe\\', \\'35\\']. job_parameters Job-level parameters used run. notebook_params map keys values jobs notebook task, example \\'notebook_params\\': {\\'name\\': \\'john doe\\', \\'age\\': \\'35\\'}. pipeline_params  python_named_params map keys values jobs Python wheel task, example 'python_named_params': {'name': 'task', 'data': 'dbfs:/path//data.json'}. python_params list parameters jobs Python tasks, example \\'python_params\\': [\\'john doe\\', \\'35\\']. spark_submit_params list parameters jobs spark submit task, example \\'spark_submit_params\\': [\\'--class\\', \\'org.apache.spark.examples.SparkPi\\']. sql_params map keys values jobs SQL task, example 'sql_params': {'name': 'john doe', 'age': '35'}.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsRunNow.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Trigger a new job run. — jobsRunNow","text":"Run job return run_id triggered run.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsSetJobPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Set job permissions. — jobsSetJobPermissions","title":"Set job permissions. — jobsSetJobPermissions","text":"Sets permissions job. Jobs can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsSetJobPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set job permissions. — jobsSetJobPermissions","text":"","code":"jobsSetJobPermissions(client, job_id, access_control_list = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsSetJobPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set job permissions. — jobsSetJobPermissions","text":"client Required. Instance DatabricksClient() job_id Required. job get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsSubmit.html","id":null,"dir":"Reference","previous_headings":"","what":"Create and trigger a one-time run. — jobsSubmit","title":"Create and trigger a one-time run. — jobsSubmit","text":"long-running operation, blocks Jobs Databricks reach TERMINATED SKIPPED state timeout 20 minutes, can change via timeout parameter. default, state Databricks Jobs reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsSubmit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create and trigger a one-time run. — jobsSubmit","text":"","code":"jobsSubmit(   client,   access_control_list = NULL,   email_notifications = NULL,   git_source = NULL,   health = NULL,   idempotency_token = NULL,   notification_settings = NULL,   run_name = NULL,   tasks = NULL,   timeout_seconds = NULL,   webhook_notifications = NULL,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsSubmit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create and trigger a one-time run. — jobsSubmit","text":"client Required. Instance DatabricksClient() access_control_list List permissions set job. email_notifications optional set email addresses notified run begins completes. git_source optional specification remote repository containing notebooks used job's notebook tasks. health optional set health rules can defined job. idempotency_token optional token can used guarantee idempotency job run requests. notification_settings Optional notification settings used sending notifications webhook_notifications run. run_name optional name run. tasks  timeout_seconds optional timeout applied run job. webhook_notifications collection system notification IDs notify run begins completes.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsSubmit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create and trigger a one-time run. — jobsSubmit","text":"Submit one-time run. endpoint allows submit workload directly without creating job. Runs submitted using endpoint don’t display UI. Use jobs/runs/get API check run state job submitted.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Partially update a job. — jobsUpdate","title":"Partially update a job. — jobsUpdate","text":"Add, update, remove specific settings existing job. Use ResetJob overwrite job settings.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partially update a job. — jobsUpdate","text":"","code":"jobsUpdate(client, job_id, fields_to_remove = NULL, new_settings = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partially update a job. — jobsUpdate","text":"client Required. Instance DatabricksClient() job_id Required. canonical identifier job update. fields_to_remove Remove top-level fields job settings. new_settings new settings job.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsUpdateJobPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Update job permissions. — jobsUpdateJobPermissions","title":"Update job permissions. — jobsUpdateJobPermissions","text":"Updates permissions job. Jobs can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsUpdateJobPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update job permissions. — jobsUpdateJobPermissions","text":"","code":"jobsUpdateJobPermissions(client, job_id, access_control_list = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/jobsUpdateJobPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update job permissions. — jobsUpdateJobPermissions","text":"client Required. Instance DatabricksClient() job_id Required. job get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/librariesAllClusterStatuses.html","id":null,"dir":"Reference","previous_headings":"","what":"Get all statuses. — librariesAllClusterStatuses","title":"Get all statuses. — librariesAllClusterStatuses","text":"Get status libraries clusters. status available libraries installed cluster via API libraries UI well libraries set installed clusters via libraries UI.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/librariesAllClusterStatuses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get all statuses. — librariesAllClusterStatuses","text":"","code":"librariesAllClusterStatuses(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/librariesClusterStatus.html","id":null,"dir":"Reference","previous_headings":"","what":"Get status. — librariesClusterStatus","title":"Get status. — librariesClusterStatus","text":"Get status libraries cluster. status available libraries installed cluster via API libraries UI well libraries set installed clusters via libraries UI. order returned libraries follows.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/librariesClusterStatus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get status. — librariesClusterStatus","text":"","code":"librariesClusterStatus(client, cluster_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/librariesClusterStatus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get status. — librariesClusterStatus","text":"client Required. Instance DatabricksClient() cluster_id Required. Unique identifier cluster whose status retrieved.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/librariesClusterStatus.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get status. — librariesClusterStatus","text":"Libraries set installed cluster returned first. Within group, final order order libraries added cluster. Libraries set installed clusters returned next. Within group order guarantee. Libraries previously requested cluster clusters, now marked removal. Within group order guarantee.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/librariesInstall.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a library. — librariesInstall","title":"Add a library. — librariesInstall","text":"Add libraries installed cluster. installation asynchronous; happens background completion request.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/librariesInstall.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a library. — librariesInstall","text":"","code":"librariesInstall(client, cluster_id, libraries)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/librariesInstall.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a library. — librariesInstall","text":"client Required. Instance DatabricksClient() cluster_id Required. Unique identifier cluster install libraries. libraries Required. libraries install.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/librariesInstall.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add a library. — librariesInstall","text":"Note: actual set libraries installed cluster union libraries specified via method libraries set installed clusters via libraries UI.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/librariesUninstall.html","id":null,"dir":"Reference","previous_headings":"","what":"Uninstall libraries. — librariesUninstall","title":"Uninstall libraries. — librariesUninstall","text":"Set libraries uninstalled cluster. libraries uninstalled cluster restarted. Uninstalling libraries installed cluster impact error.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/librariesUninstall.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uninstall libraries. — librariesUninstall","text":"","code":"librariesUninstall(client, cluster_id, libraries)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/librariesUninstall.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uninstall libraries. — librariesUninstall","text":"client Required. Instance DatabricksClient() cluster_id Required. Unique identifier cluster uninstall libraries. libraries Required. libraries uninstall.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresAssign.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an assignment. — metastoresAssign","title":"Create an assignment. — metastoresAssign","text":"Creates new metastore assignment. assignment workspace_id exists, overwritten new metastore_id default_catalog_name. caller must account admin.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresAssign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an assignment. — metastoresAssign","text":"","code":"metastoresAssign(client, metastore_id, default_catalog_name, workspace_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresAssign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an assignment. — metastoresAssign","text":"client Required. Instance DatabricksClient() metastore_id Required. unique ID metastore. default_catalog_name Required. name default catalog metastore. workspace_id Required. workspace ID.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a metastore. — metastoresCreate","title":"Create a metastore. — metastoresCreate","text":"Creates new metastore based provided name storage root path.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a metastore. — metastoresCreate","text":"","code":"metastoresCreate(client, name, storage_root, region = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a metastore. — metastoresCreate","text":"client Required. Instance DatabricksClient() name Required. user-specified name metastore. storage_root Required. storage root URL metastore. region Cloud region metastore serves (e.g., us-west-2, westus).","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresCurrent.html","id":null,"dir":"Reference","previous_headings":"","what":"Get metastore assignment for workspace. — metastoresCurrent","title":"Get metastore assignment for workspace. — metastoresCurrent","text":"Gets metastore assignment workspace accessed.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresCurrent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get metastore assignment for workspace. — metastoresCurrent","text":"","code":"metastoresCurrent(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a metastore. — metastoresDelete","title":"Delete a metastore. — metastoresDelete","text":"Deletes metastore. caller must metastore admin.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a metastore. — metastoresDelete","text":"","code":"metastoresDelete(client, id, force = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a metastore. — metastoresDelete","text":"client Required. Instance DatabricksClient() id Required. Unique ID metastore. force Force deletion even metastore empty.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresEnableOptimization.html","id":null,"dir":"Reference","previous_headings":"","what":"Toggle predictive optimization on the metastore. — metastoresEnableOptimization","title":"Toggle predictive optimization on the metastore. — metastoresEnableOptimization","text":"Enables disables predictive optimization metastore.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresEnableOptimization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Toggle predictive optimization on the metastore. — metastoresEnableOptimization","text":"","code":"metastoresEnableOptimization(client, metastore_id, enable)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresEnableOptimization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Toggle predictive optimization on the metastore. — metastoresEnableOptimization","text":"client Required. Instance DatabricksClient() metastore_id Required. Unique identifier metastore. enable Required. Whether enable predictive optimization metastore.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a metastore. — metastoresGet","title":"Get a metastore. — metastoresGet","text":"Gets metastore matches supplied ID. caller must metastore admin retrieve info.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a metastore. — metastoresGet","text":"","code":"metastoresGet(client, id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a metastore. — metastoresGet","text":"client Required. Instance DatabricksClient() id Required. Unique ID metastore.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresList.html","id":null,"dir":"Reference","previous_headings":"","what":"List metastores. — metastoresList","title":"List metastores. — metastoresList","text":"Gets array available metastores (MetastoreInfo objects). caller must admin retrieve info. guarantee specific ordering elements array.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List metastores. — metastoresList","text":"","code":"metastoresList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List metastores. — metastoresList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a metastore summary. — metastoresSummary","title":"Get a metastore summary. — metastoresSummary","text":"Gets information metastore. summary includes storage credential, cloud vendor, cloud region, global metastore ID.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a metastore summary. — metastoresSummary","text":"","code":"metastoresSummary(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresUnassign.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete an assignment. — metastoresUnassign","title":"Delete an assignment. — metastoresUnassign","text":"Deletes metastore assignment. caller must account administrator.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresUnassign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete an assignment. — metastoresUnassign","text":"","code":"metastoresUnassign(client, workspace_id, metastore_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresUnassign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete an assignment. — metastoresUnassign","text":"client Required. Instance DatabricksClient() workspace_id Required. workspace ID. metastore_id Required. Query ID metastore delete.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a metastore. — metastoresUpdate","title":"Update a metastore. — metastoresUpdate","text":"Updates information specific metastore. caller must metastore admin.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a metastore. — metastoresUpdate","text":"","code":"metastoresUpdate(   client,   id,   delta_sharing_organization_name = NULL,   delta_sharing_recipient_token_lifetime_in_seconds = NULL,   delta_sharing_scope = NULL,   name = NULL,   owner = NULL,   privilege_model_version = NULL,   storage_root_credential_id = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a metastore. — metastoresUpdate","text":"client Required. Instance DatabricksClient() id Required. Unique ID metastore. delta_sharing_organization_name organization name Delta Sharing entity, used Databricks--Databricks Delta Sharing official name. delta_sharing_recipient_token_lifetime_in_seconds lifetime delta sharing recipient token seconds. delta_sharing_scope scope Delta Sharing enabled metastore. name user-specified name metastore. owner owner metastore. privilege_model_version Privilege model version metastore, form major.minor (e.g., 1.0). storage_root_credential_id UUID storage credential access metastore storage_root.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresUpdateAssignment.html","id":null,"dir":"Reference","previous_headings":"","what":"Update an assignment. — metastoresUpdateAssignment","title":"Update an assignment. — metastoresUpdateAssignment","text":"Updates metastore assignment. operation can used update metastore_id default_catalog_name specified Workspace, Workspace already assigned metastore. caller must account admin update metastore_id; otherwise, caller can Workspace admin.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresUpdateAssignment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update an assignment. — metastoresUpdateAssignment","text":"","code":"metastoresUpdateAssignment(   client,   workspace_id,   default_catalog_name = NULL,   metastore_id = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/metastoresUpdateAssignment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update an assignment. — metastoresUpdateAssignment","text":"client Required. Instance DatabricksClient() workspace_id Required. workspace ID. default_catalog_name name default catalog metastore. metastore_id unique ID metastore.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryApproveTransitionRequest.html","id":null,"dir":"Reference","previous_headings":"","what":"Approve transition request. — modelRegistryApproveTransitionRequest","title":"Approve transition request. — modelRegistryApproveTransitionRequest","text":"Approves model version stage transition request.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryApproveTransitionRequest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Approve transition request. — modelRegistryApproveTransitionRequest","text":"","code":"modelRegistryApproveTransitionRequest(   client,   name,   version,   stage,   archive_existing_versions,   comment = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryApproveTransitionRequest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Approve transition request. — modelRegistryApproveTransitionRequest","text":"client Required. Instance DatabricksClient() name Required. Name model. version Required. Version model. stage Required. Target stage transition. archive_existing_versions Required. Specifies whether archive current model versions target stage. comment User-provided comment action.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateComment.html","id":null,"dir":"Reference","previous_headings":"","what":"Post a comment. — modelRegistryCreateComment","title":"Post a comment. — modelRegistryCreateComment","text":"Posts comment model version. comment can submitted either user programmatically display relevant information model. example, test results deployment errors.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateComment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Post a comment. — modelRegistryCreateComment","text":"","code":"modelRegistryCreateComment(client, name, version, comment)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateComment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Post a comment. — modelRegistryCreateComment","text":"client Required. Instance DatabricksClient() name Required. Name model. version Required. Version model. comment Required. User-provided comment action.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a model. — modelRegistryCreateModel","title":"Create a model. — modelRegistryCreateModel","text":"Creates new registered model name specified request body.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a model. — modelRegistryCreateModel","text":"","code":"modelRegistryCreateModel(client, name, description = NULL, tags = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a model. — modelRegistryCreateModel","text":"client Required. Instance DatabricksClient() name Required. Register models name. description Optional description registered model. tags Additional metadata registered model.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateModel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a model. — modelRegistryCreateModel","text":"Throws RESOURCE_ALREADY_EXISTS registered model given name exists.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateModelVersion.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a model version. — modelRegistryCreateModelVersion","title":"Create a model version. — modelRegistryCreateModelVersion","text":"Creates model version.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateModelVersion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a model version. — modelRegistryCreateModelVersion","text":"","code":"modelRegistryCreateModelVersion(   client,   name,   source,   description = NULL,   run_id = NULL,   run_link = NULL,   tags = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateModelVersion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a model version. — modelRegistryCreateModelVersion","text":"client Required. Instance DatabricksClient() name Required. Register model name. source Required. URI indicating location model artifacts. description Optional description model version. run_id MLflow run ID correlation, source generated experiment run MLflow tracking server. run_link MLflow run link - exact link run generated model version, potentially hosted another instance MLflow. tags Additional metadata model version.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateTransitionRequest.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a transition request. — modelRegistryCreateTransitionRequest","title":"Make a transition request. — modelRegistryCreateTransitionRequest","text":"Creates model version stage transition request.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateTransitionRequest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a transition request. — modelRegistryCreateTransitionRequest","text":"","code":"modelRegistryCreateTransitionRequest(   client,   name,   version,   stage,   comment = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateTransitionRequest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a transition request. — modelRegistryCreateTransitionRequest","text":"client Required. Instance DatabricksClient() name Required. Name model. version Required. Version model. stage Required. Target stage transition. comment User-provided comment action.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateWebhook.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a webhook. — modelRegistryCreateWebhook","title":"Create a webhook. — modelRegistryCreateWebhook","text":"NOTE: endpoint Public Preview.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateWebhook.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a webhook. — modelRegistryCreateWebhook","text":"","code":"modelRegistryCreateWebhook(   client,   events,   description = NULL,   http_url_spec = NULL,   job_spec = NULL,   model_name = NULL,   status = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateWebhook.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a webhook. — modelRegistryCreateWebhook","text":"client Required. Instance DatabricksClient() events Required. Events can trigger registry webhook: * MODEL_VERSION_CREATED: new model version created associated model. description User-specified description webhook. http_url_spec  job_spec  model_name Name model whose events trigger webhook. status describes enum.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryCreateWebhook.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a webhook. — modelRegistryCreateWebhook","text":"Creates registry webhook.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteComment.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a comment. — modelRegistryDeleteComment","title":"Delete a comment. — modelRegistryDeleteComment","text":"Deletes comment model version.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteComment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a comment. — modelRegistryDeleteComment","text":"","code":"modelRegistryDeleteComment(client, id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteComment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a comment. — modelRegistryDeleteComment","text":"client Required. Instance DatabricksClient() id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a model. — modelRegistryDeleteModel","title":"Delete a model. — modelRegistryDeleteModel","text":"Deletes registered model.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a model. — modelRegistryDeleteModel","text":"","code":"modelRegistryDeleteModel(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a model. — modelRegistryDeleteModel","text":"client Required. Instance DatabricksClient() name Required. Registered model unique name identifier.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteModelTag.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a model tag. — modelRegistryDeleteModelTag","title":"Delete a model tag. — modelRegistryDeleteModelTag","text":"Deletes tag registered model.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteModelTag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a model tag. — modelRegistryDeleteModelTag","text":"","code":"modelRegistryDeleteModelTag(client, name, key)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteModelTag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a model tag. — modelRegistryDeleteModelTag","text":"client Required. Instance DatabricksClient() name Required. Name registered model tag logged . key Required. Name tag.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteModelVersion.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a model version. — modelRegistryDeleteModelVersion","title":"Delete a model version. — modelRegistryDeleteModelVersion","text":"Deletes model version.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteModelVersion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a model version. — modelRegistryDeleteModelVersion","text":"","code":"modelRegistryDeleteModelVersion(client, name, version)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteModelVersion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a model version. — modelRegistryDeleteModelVersion","text":"client Required. Instance DatabricksClient() name Required. Name registered model. version Required. Model version number.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteModelVersionTag.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a model version tag. — modelRegistryDeleteModelVersionTag","title":"Delete a model version tag. — modelRegistryDeleteModelVersionTag","text":"Deletes model version tag.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteModelVersionTag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a model version tag. — modelRegistryDeleteModelVersionTag","text":"","code":"modelRegistryDeleteModelVersionTag(client, name, version, key)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteModelVersionTag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a model version tag. — modelRegistryDeleteModelVersionTag","text":"client Required. Instance DatabricksClient() name Required. Name registered model tag logged . version Required. Model version number tag logged . key Required. Name tag.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteTransitionRequest.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a transition request. — modelRegistryDeleteTransitionRequest","title":"Delete a transition request. — modelRegistryDeleteTransitionRequest","text":"Cancels model version stage transition request.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteTransitionRequest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a transition request. — modelRegistryDeleteTransitionRequest","text":"","code":"modelRegistryDeleteTransitionRequest(   client,   name,   version,   stage,   creator,   comment = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteTransitionRequest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a transition request. — modelRegistryDeleteTransitionRequest","text":"client Required. Instance DatabricksClient() name Required. Name model. version Required. Version model. stage Required. Target stage transition request. creator Required. Username user created request. comment User-provided comment action.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteWebhook.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a webhook. — modelRegistryDeleteWebhook","title":"Delete a webhook. — modelRegistryDeleteWebhook","text":"NOTE: endpoint Public Preview.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteWebhook.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a webhook. — modelRegistryDeleteWebhook","text":"","code":"modelRegistryDeleteWebhook(client, id = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteWebhook.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a webhook. — modelRegistryDeleteWebhook","text":"client Required. Instance DatabricksClient() id Webhook ID required delete registry webhook.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryDeleteWebhook.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Delete a webhook. — modelRegistryDeleteWebhook","text":"Deletes registry webhook.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetLatestVersions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the latest version. — modelRegistryGetLatestVersions","title":"Get the latest version. — modelRegistryGetLatestVersions","text":"Gets latest version registered model.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetLatestVersions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the latest version. — modelRegistryGetLatestVersions","text":"","code":"modelRegistryGetLatestVersions(client, name, stages = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetLatestVersions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the latest version. — modelRegistryGetLatestVersions","text":"client Required. Instance DatabricksClient() name Required. Registered model unique name identifier. stages List stages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetLatestVersions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the latest version. — modelRegistryGetLatestVersions","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Get model. — modelRegistryGetModel","title":"Get model. — modelRegistryGetModel","text":"Get details model. Databricks workspace version MLflow endpoint also returns model's Databricks workspace ID permission level requesting user model.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get model. — modelRegistryGetModel","text":"","code":"modelRegistryGetModel(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get model. — modelRegistryGetModel","text":"client Required. Instance DatabricksClient() name Required. Registered model unique name identifier.","code":""},{"path":[]},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetModelVersion.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a model version. — modelRegistryGetModelVersion","title":"Get a model version. — modelRegistryGetModelVersion","text":"Get model version.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetModelVersion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a model version. — modelRegistryGetModelVersion","text":"","code":"modelRegistryGetModelVersion(client, name, version)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetModelVersion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a model version. — modelRegistryGetModelVersion","text":"client Required. Instance DatabricksClient() name Required. Name registered model. version Required. Model version number.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetModelVersionDownloadUri.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a model version URI. — modelRegistryGetModelVersionDownloadUri","title":"Get a model version URI. — modelRegistryGetModelVersionDownloadUri","text":"Gets URI download model version.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetModelVersionDownloadUri.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a model version URI. — modelRegistryGetModelVersionDownloadUri","text":"","code":"modelRegistryGetModelVersionDownloadUri(client, name, version)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetModelVersionDownloadUri.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a model version URI. — modelRegistryGetModelVersionDownloadUri","text":"client Required. Instance DatabricksClient() name Required. Name registered model. version Required. Model version number.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetRegisteredModelPermissionLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Get registered model permission levels. — modelRegistryGetRegisteredModelPermissionLevels","title":"Get registered model permission levels. — modelRegistryGetRegisteredModelPermissionLevels","text":"Gets permission levels user can object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetRegisteredModelPermissionLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get registered model permission levels. — modelRegistryGetRegisteredModelPermissionLevels","text":"","code":"modelRegistryGetRegisteredModelPermissionLevels(client, registered_model_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetRegisteredModelPermissionLevels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get registered model permission levels. — modelRegistryGetRegisteredModelPermissionLevels","text":"client Required. Instance DatabricksClient() registered_model_id Required. registered model get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetRegisteredModelPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get registered model permissions. — modelRegistryGetRegisteredModelPermissions","title":"Get registered model permissions. — modelRegistryGetRegisteredModelPermissions","text":"Gets permissions registered model. Registered models can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetRegisteredModelPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get registered model permissions. — modelRegistryGetRegisteredModelPermissions","text":"","code":"modelRegistryGetRegisteredModelPermissions(client, registered_model_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryGetRegisteredModelPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get registered model permissions. — modelRegistryGetRegisteredModelPermissions","text":"client Required. Instance DatabricksClient() registered_model_id Required. registered model get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryListModels.html","id":null,"dir":"Reference","previous_headings":"","what":"List models. — modelRegistryListModels","title":"List models. — modelRegistryListModels","text":"Lists available registered models, limit specified max_results.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryListModels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List models. — modelRegistryListModels","text":"","code":"modelRegistryListModels(client, max_results = NULL, page_token = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryListModels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List models. — modelRegistryListModels","text":"client Required. Instance DatabricksClient() max_results Maximum number registered models desired. page_token Pagination token go next page based previous query.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryListModels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List models. — modelRegistryListModels","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryListTransitionRequests.html","id":null,"dir":"Reference","previous_headings":"","what":"List transition requests. — modelRegistryListTransitionRequests","title":"List transition requests. — modelRegistryListTransitionRequests","text":"Gets list open stage transition requests model version.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryListTransitionRequests.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List transition requests. — modelRegistryListTransitionRequests","text":"","code":"modelRegistryListTransitionRequests(client, name, version)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryListTransitionRequests.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List transition requests. — modelRegistryListTransitionRequests","text":"client Required. Instance DatabricksClient() name Required. Name model. version Required. Version model.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryListTransitionRequests.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List transition requests. — modelRegistryListTransitionRequests","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryListWebhooks.html","id":null,"dir":"Reference","previous_headings":"","what":"List registry webhooks. — modelRegistryListWebhooks","title":"List registry webhooks. — modelRegistryListWebhooks","text":"NOTE: endpoint Public Preview.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryListWebhooks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List registry webhooks. — modelRegistryListWebhooks","text":"","code":"modelRegistryListWebhooks(   client,   events = NULL,   model_name = NULL,   page_token = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryListWebhooks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List registry webhooks. — modelRegistryListWebhooks","text":"client Required. Instance DatabricksClient() events events specified, webhook one specified trigger events included output. model_name specified, webhooks associated specified events listed, regardless associated model. page_token Token indicating page artifact results fetch.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryListWebhooks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List registry webhooks. — modelRegistryListWebhooks","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryListWebhooks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List registry webhooks. — modelRegistryListWebhooks","text":"Lists registry webhooks.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryRejectTransitionRequest.html","id":null,"dir":"Reference","previous_headings":"","what":"Reject a transition request. — modelRegistryRejectTransitionRequest","title":"Reject a transition request. — modelRegistryRejectTransitionRequest","text":"Rejects model version stage transition request.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryRejectTransitionRequest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reject a transition request. — modelRegistryRejectTransitionRequest","text":"","code":"modelRegistryRejectTransitionRequest(   client,   name,   version,   stage,   comment = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryRejectTransitionRequest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reject a transition request. — modelRegistryRejectTransitionRequest","text":"client Required. Instance DatabricksClient() name Required. Name model. version Required. Version model. stage Required. Target stage transition. comment User-provided comment action.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryRenameModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Rename a model. — modelRegistryRenameModel","title":"Rename a model. — modelRegistryRenameModel","text":"Renames registered model.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryRenameModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rename a model. — modelRegistryRenameModel","text":"","code":"modelRegistryRenameModel(client, name, new_name = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryRenameModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rename a model. — modelRegistryRenameModel","text":"client Required. Instance DatabricksClient() name Required. Registered model unique name identifier. new_name provided, updates name registered_model.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySearchModelVersions.html","id":null,"dir":"Reference","previous_headings":"","what":"Searches model versions. — modelRegistrySearchModelVersions","title":"Searches model versions. — modelRegistrySearchModelVersions","text":"Searches specific model versions based supplied filter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySearchModelVersions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Searches model versions. — modelRegistrySearchModelVersions","text":"","code":"modelRegistrySearchModelVersions(   client,   filter = NULL,   max_results = NULL,   order_by = NULL,   page_token = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySearchModelVersions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Searches model versions. — modelRegistrySearchModelVersions","text":"client Required. Instance DatabricksClient() filter String filter condition, like 'name='-model-name''. max_results Maximum number models desired. order_by List columns ordered including model name, version, stage optional 'DESC' 'ASC' annotation, 'ASC' default. page_token Pagination token go next page based previous search query.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySearchModelVersions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Searches model versions. — modelRegistrySearchModelVersions","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySearchModels.html","id":null,"dir":"Reference","previous_headings":"","what":"Search models. — modelRegistrySearchModels","title":"Search models. — modelRegistrySearchModels","text":"Search registered models based specified filter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySearchModels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search models. — modelRegistrySearchModels","text":"","code":"modelRegistrySearchModels(   client,   filter = NULL,   max_results = NULL,   order_by = NULL,   page_token = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySearchModels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search models. — modelRegistrySearchModels","text":"client Required. Instance DatabricksClient() filter String filter condition, like 'name LIKE '-model-name''. max_results Maximum number models desired. order_by List columns ordering search results, can include model name last updated timestamp optional 'DESC' 'ASC' annotation, 'ASC' default. page_token Pagination token go next page based previous search query.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySearchModels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search models. — modelRegistrySearchModels","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySetModelTag.html","id":null,"dir":"Reference","previous_headings":"","what":"Set a tag. — modelRegistrySetModelTag","title":"Set a tag. — modelRegistrySetModelTag","text":"Sets tag registered model.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySetModelTag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set a tag. — modelRegistrySetModelTag","text":"","code":"modelRegistrySetModelTag(client, name, key, value)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySetModelTag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set a tag. — modelRegistrySetModelTag","text":"client Required. Instance DatabricksClient() name Required. Unique name model. key Required. Name tag. value Required. String value tag logged.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySetModelVersionTag.html","id":null,"dir":"Reference","previous_headings":"","what":"Set a version tag. — modelRegistrySetModelVersionTag","title":"Set a version tag. — modelRegistrySetModelVersionTag","text":"Sets model version tag.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySetModelVersionTag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set a version tag. — modelRegistrySetModelVersionTag","text":"","code":"modelRegistrySetModelVersionTag(client, name, version, key, value)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySetModelVersionTag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set a version tag. — modelRegistrySetModelVersionTag","text":"client Required. Instance DatabricksClient() name Required. Unique name model. version Required. Model version number. key Required. Name tag. value Required. String value tag logged.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySetRegisteredModelPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Set registered model permissions. — modelRegistrySetRegisteredModelPermissions","title":"Set registered model permissions. — modelRegistrySetRegisteredModelPermissions","text":"Sets permissions registered model. Registered models can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySetRegisteredModelPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set registered model permissions. — modelRegistrySetRegisteredModelPermissions","text":"","code":"modelRegistrySetRegisteredModelPermissions(   client,   registered_model_id,   access_control_list = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistrySetRegisteredModelPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set registered model permissions. — modelRegistrySetRegisteredModelPermissions","text":"client Required. Instance DatabricksClient() registered_model_id Required. registered model get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryTestRegistryWebhook.html","id":null,"dir":"Reference","previous_headings":"","what":"Test a webhook. — modelRegistryTestRegistryWebhook","title":"Test a webhook. — modelRegistryTestRegistryWebhook","text":"NOTE: endpoint Public Preview.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryTestRegistryWebhook.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test a webhook. — modelRegistryTestRegistryWebhook","text":"","code":"modelRegistryTestRegistryWebhook(client, id, event = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryTestRegistryWebhook.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test a webhook. — modelRegistryTestRegistryWebhook","text":"client Required. Instance DatabricksClient() id Required. Webhook ID. event event specified, test trigger uses specified event.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryTestRegistryWebhook.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test a webhook. — modelRegistryTestRegistryWebhook","text":"Tests registry webhook.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryTransitionStage.html","id":null,"dir":"Reference","previous_headings":"","what":"Transition a stage. — modelRegistryTransitionStage","title":"Transition a stage. — modelRegistryTransitionStage","text":"Transition model version's stage. Databricks workspace version MLflow endpoint also accepts comment associated transition recorded.',","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryTransitionStage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transition a stage. — modelRegistryTransitionStage","text":"","code":"modelRegistryTransitionStage(   client,   name,   version,   stage,   archive_existing_versions,   comment = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryTransitionStage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transition a stage. — modelRegistryTransitionStage","text":"client Required. Instance DatabricksClient() name Required. Name model. version Required. Version model. stage Required. Target stage transition. archive_existing_versions Required. Specifies whether archive current model versions target stage. comment User-provided comment action.","code":""},{"path":[]},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateComment.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a comment. — modelRegistryUpdateComment","title":"Update a comment. — modelRegistryUpdateComment","text":"Post edit comment model version.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateComment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a comment. — modelRegistryUpdateComment","text":"","code":"modelRegistryUpdateComment(client, id, comment)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateComment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a comment. — modelRegistryUpdateComment","text":"client Required. Instance DatabricksClient() id Required. Unique identifier activity. comment Required. User-provided comment action.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Update model. — modelRegistryUpdateModel","title":"Update model. — modelRegistryUpdateModel","text":"Updates registered model.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update model. — modelRegistryUpdateModel","text":"","code":"modelRegistryUpdateModel(client, name, description = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update model. — modelRegistryUpdateModel","text":"client Required. Instance DatabricksClient() name Required. Registered model unique name identifier. description provided, updates description registered_model.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateModelVersion.html","id":null,"dir":"Reference","previous_headings":"","what":"Update model version. — modelRegistryUpdateModelVersion","title":"Update model version. — modelRegistryUpdateModelVersion","text":"Updates model version.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateModelVersion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update model version. — modelRegistryUpdateModelVersion","text":"","code":"modelRegistryUpdateModelVersion(client, name, version, description = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateModelVersion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update model version. — modelRegistryUpdateModelVersion","text":"client Required. Instance DatabricksClient() name Required. Name registered model. version Required. Model version number. description provided, updates description registered_model.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateRegisteredModelPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Update registered model permissions. — modelRegistryUpdateRegisteredModelPermissions","title":"Update registered model permissions. — modelRegistryUpdateRegisteredModelPermissions","text":"Updates permissions registered model. Registered models can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateRegisteredModelPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update registered model permissions. — modelRegistryUpdateRegisteredModelPermissions","text":"","code":"modelRegistryUpdateRegisteredModelPermissions(   client,   registered_model_id,   access_control_list = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateRegisteredModelPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update registered model permissions. — modelRegistryUpdateRegisteredModelPermissions","text":"client Required. Instance DatabricksClient() registered_model_id Required. registered model get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateWebhook.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a webhook. — modelRegistryUpdateWebhook","title":"Update a webhook. — modelRegistryUpdateWebhook","text":"NOTE: endpoint Public Preview.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateWebhook.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a webhook. — modelRegistryUpdateWebhook","text":"","code":"modelRegistryUpdateWebhook(   client,   id,   description = NULL,   events = NULL,   http_url_spec = NULL,   job_spec = NULL,   status = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateWebhook.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a webhook. — modelRegistryUpdateWebhook","text":"client Required. Instance DatabricksClient() id Required. Webhook ID. description User-specified description webhook. events Events can trigger registry webhook: * MODEL_VERSION_CREATED: new model version created associated model. http_url_spec  job_spec  status describes enum.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/modelRegistryUpdateWebhook.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update a webhook. — modelRegistryUpdateWebhook","text":"Updates registry webhook.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/permissionsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get object permissions. — permissionsGet","title":"Get object permissions. — permissionsGet","text":"Gets permissions object. Objects can inherit permissions parent objects root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/permissionsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get object permissions. — permissionsGet","text":"","code":"permissionsGet(client, request_object_type, request_object_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/permissionsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get object permissions. — permissionsGet","text":"client Required. Instance DatabricksClient() request_object_type Required. . request_object_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/permissionsGetPermissionLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Get object permission levels. — permissionsGetPermissionLevels","title":"Get object permission levels. — permissionsGetPermissionLevels","text":"Gets permission levels user can object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/permissionsGetPermissionLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get object permission levels. — permissionsGetPermissionLevels","text":"","code":"permissionsGetPermissionLevels(client, request_object_type, request_object_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/permissionsGetPermissionLevels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get object permission levels. — permissionsGetPermissionLevels","text":"client Required. Instance DatabricksClient() request_object_type Required. . request_object_id Required. .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/permissionsSet.html","id":null,"dir":"Reference","previous_headings":"","what":"Set object permissions. — permissionsSet","title":"Set object permissions. — permissionsSet","text":"Sets permissions object. Objects can inherit permissions parent objects root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/permissionsSet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set object permissions. — permissionsSet","text":"","code":"permissionsSet(   client,   request_object_type,   request_object_id,   access_control_list = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/permissionsSet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set object permissions. — permissionsSet","text":"client Required. Instance DatabricksClient() request_object_type Required. . request_object_id Required. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/permissionsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update object permissions. — permissionsUpdate","title":"Update object permissions. — permissionsUpdate","text":"Updates permissions object. Objects can inherit permissions parent objects root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/permissionsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update object permissions. — permissionsUpdate","text":"","code":"permissionsUpdate(   client,   request_object_type,   request_object_id,   access_control_list = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/permissionsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update object permissions. — permissionsUpdate","text":"client Required. Instance DatabricksClient() request_object_type Required. . request_object_id Required. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a pipeline. — pipelinesCreate","title":"Create a pipeline. — pipelinesCreate","text":"Creates new data processing pipeline based requested configuration. successful, method returns ID new pipeline.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a pipeline. — pipelinesCreate","text":"","code":"pipelinesCreate(   client,   allow_duplicate_names = NULL,   catalog = NULL,   channel = NULL,   clusters = NULL,   configuration = NULL,   continuous = NULL,   development = NULL,   dry_run = NULL,   edition = NULL,   filters = NULL,   id = NULL,   libraries = NULL,   name = NULL,   photon = NULL,   serverless = NULL,   storage = NULL,   target = NULL,   trigger = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a pipeline. — pipelinesCreate","text":"client Required. Instance DatabricksClient() allow_duplicate_names false, deployment fail name conflicts another pipeline. catalog catalog Unity Catalog publish data pipeline . channel DLT Release Channel specifies version use. clusters Cluster settings pipeline deployment. configuration String-String configuration pipeline execution. continuous Whether pipeline continuous triggered. development Whether pipeline Development mode. dry_run  edition Pipeline product edition. filters Filters Pipeline packages include deployed graph. id Unique identifier pipeline. libraries Libraries code needed deployment. name Friendly identifier pipeline. photon Whether Photon enabled pipeline. serverless Whether serverless compute enabled pipeline. storage DBFS root directory storing checkpoints tables. target Target schema (database) add tables pipeline . trigger pipeline trigger use.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a pipeline. — pipelinesDelete","title":"Delete a pipeline. — pipelinesDelete","text":"Deletes pipeline.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a pipeline. — pipelinesDelete","text":"","code":"pipelinesDelete(client, pipeline_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a pipeline. — pipelinesDelete","text":"client Required. Instance DatabricksClient() pipeline_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a pipeline. — pipelinesGet","title":"Get a pipeline. — pipelinesGet","text":"Get pipeline.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a pipeline. — pipelinesGet","text":"","code":"pipelinesGet(client, pipeline_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a pipeline. — pipelinesGet","text":"client Required. Instance DatabricksClient() pipeline_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesGetPipelinePermissionLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Get pipeline permission levels. — pipelinesGetPipelinePermissionLevels","title":"Get pipeline permission levels. — pipelinesGetPipelinePermissionLevels","text":"Gets permission levels user can object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesGetPipelinePermissionLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get pipeline permission levels. — pipelinesGetPipelinePermissionLevels","text":"","code":"pipelinesGetPipelinePermissionLevels(client, pipeline_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesGetPipelinePermissionLevels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get pipeline permission levels. — pipelinesGetPipelinePermissionLevels","text":"client Required. Instance DatabricksClient() pipeline_id Required. pipeline get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesGetPipelinePermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get pipeline permissions. — pipelinesGetPipelinePermissions","title":"Get pipeline permissions. — pipelinesGetPipelinePermissions","text":"Gets permissions pipeline. Pipelines can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesGetPipelinePermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get pipeline permissions. — pipelinesGetPipelinePermissions","text":"","code":"pipelinesGetPipelinePermissions(client, pipeline_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesGetPipelinePermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get pipeline permissions. — pipelinesGetPipelinePermissions","text":"client Required. Instance DatabricksClient() pipeline_id Required. pipeline get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesGetUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a pipeline update. — pipelinesGetUpdate","title":"Get a pipeline update. — pipelinesGetUpdate","text":"Gets update active pipeline.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesGetUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a pipeline update. — pipelinesGetUpdate","text":"","code":"pipelinesGetUpdate(client, pipeline_id, update_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesGetUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a pipeline update. — pipelinesGetUpdate","text":"client Required. Instance DatabricksClient() pipeline_id Required. ID pipeline. update_id Required. ID update.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesListPipelineEvents.html","id":null,"dir":"Reference","previous_headings":"","what":"List pipeline events. — pipelinesListPipelineEvents","title":"List pipeline events. — pipelinesListPipelineEvents","text":"Retrieves events pipeline.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesListPipelineEvents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List pipeline events. — pipelinesListPipelineEvents","text":"","code":"pipelinesListPipelineEvents(   client,   pipeline_id,   filter = NULL,   max_results = NULL,   order_by = NULL,   page_token = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesListPipelineEvents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List pipeline events. — pipelinesListPipelineEvents","text":"client Required. Instance DatabricksClient() pipeline_id Required. filter Criteria select subset results, expressed using SQL-like syntax. max_results Max number entries return single page. order_by string indicating sort order timestamp results, example, 'timestamp asc'. page_token Page token returned previous call.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesListPipelineEvents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List pipeline events. — pipelinesListPipelineEvents","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesListPipelines.html","id":null,"dir":"Reference","previous_headings":"","what":"List pipelines. — pipelinesListPipelines","title":"List pipelines. — pipelinesListPipelines","text":"Lists pipelines defined Delta Live Tables system.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesListPipelines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List pipelines. — pipelinesListPipelines","text":"","code":"pipelinesListPipelines(   client,   filter = NULL,   max_results = NULL,   order_by = NULL,   page_token = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesListPipelines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List pipelines. — pipelinesListPipelines","text":"client Required. Instance DatabricksClient() filter Select subset results based specified criteria. max_results maximum number entries return single page. order_by list strings specifying order results. page_token Page token returned previous call.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesListPipelines.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List pipelines. — pipelinesListPipelines","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesListUpdates.html","id":null,"dir":"Reference","previous_headings":"","what":"List pipeline updates. — pipelinesListUpdates","title":"List pipeline updates. — pipelinesListUpdates","text":"List updates active pipeline.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesListUpdates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List pipeline updates. — pipelinesListUpdates","text":"","code":"pipelinesListUpdates(   client,   pipeline_id,   max_results = NULL,   page_token = NULL,   until_update_id = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesListUpdates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List pipeline updates. — pipelinesListUpdates","text":"client Required. Instance DatabricksClient() pipeline_id Required. pipeline return updates . max_results Max number entries return single page. page_token Page token returned previous call. until_update_id present, returns updates including update_id.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesReset.html","id":null,"dir":"Reference","previous_headings":"","what":"Reset a pipeline. — pipelinesReset","title":"Reset a pipeline. — pipelinesReset","text":"long-running operation, blocks Pipelines Databricks reach RUNNING state timeout 20 minutes, can change via timeout parameter. default, state Databricks Pipelines reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesReset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reset a pipeline. — pipelinesReset","text":"","code":"pipelinesReset(client, pipeline_id, timeout = 20, callback = cli_reporter)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesReset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reset a pipeline. — pipelinesReset","text":"client Required. Instance DatabricksClient() pipeline_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesReset.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reset a pipeline. — pipelinesReset","text":"Resets pipeline.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesSetPipelinePermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Set pipeline permissions. — pipelinesSetPipelinePermissions","title":"Set pipeline permissions. — pipelinesSetPipelinePermissions","text":"Sets permissions pipeline. Pipelines can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesSetPipelinePermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set pipeline permissions. — pipelinesSetPipelinePermissions","text":"","code":"pipelinesSetPipelinePermissions(   client,   pipeline_id,   access_control_list = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesSetPipelinePermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set pipeline permissions. — pipelinesSetPipelinePermissions","text":"client Required. Instance DatabricksClient() pipeline_id Required. pipeline get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesStartUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Queue a pipeline update. — pipelinesStartUpdate","title":"Queue a pipeline update. — pipelinesStartUpdate","text":"Starts queues pipeline update.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesStartUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Queue a pipeline update. — pipelinesStartUpdate","text":"","code":"pipelinesStartUpdate(   client,   pipeline_id,   cause = NULL,   full_refresh = NULL,   full_refresh_selection = NULL,   refresh_selection = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesStartUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Queue a pipeline update. — pipelinesStartUpdate","text":"client Required. Instance DatabricksClient() pipeline_id Required. cause  full_refresh true, update reset tables running. full_refresh_selection list tables update fullRefresh. refresh_selection list tables update without fullRefresh.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesStop.html","id":null,"dir":"Reference","previous_headings":"","what":"Stop a pipeline. — pipelinesStop","title":"Stop a pipeline. — pipelinesStop","text":"long-running operation, blocks Pipelines Databricks reach IDLE state timeout 20 minutes, can change via timeout parameter. default, state Databricks Pipelines reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesStop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stop a pipeline. — pipelinesStop","text":"","code":"pipelinesStop(client, pipeline_id, timeout = 20, callback = cli_reporter)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesStop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stop a pipeline. — pipelinesStop","text":"client Required. Instance DatabricksClient() pipeline_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesStop.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Stop a pipeline. — pipelinesStop","text":"Stops pipeline.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Edit a pipeline. — pipelinesUpdate","title":"Edit a pipeline. — pipelinesUpdate","text":"Updates pipeline supplied configuration.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Edit a pipeline. — pipelinesUpdate","text":"","code":"pipelinesUpdate(   client,   pipeline_id,   allow_duplicate_names = NULL,   catalog = NULL,   channel = NULL,   clusters = NULL,   configuration = NULL,   continuous = NULL,   development = NULL,   edition = NULL,   expected_last_modified = NULL,   filters = NULL,   id = NULL,   libraries = NULL,   name = NULL,   photon = NULL,   serverless = NULL,   storage = NULL,   target = NULL,   trigger = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Edit a pipeline. — pipelinesUpdate","text":"client Required. Instance DatabricksClient() pipeline_id Unique identifier pipeline. allow_duplicate_names false, deployment fail name changed conflicts name another pipeline. catalog catalog Unity Catalog publish data pipeline . channel DLT Release Channel specifies version use. clusters Cluster settings pipeline deployment. configuration String-String configuration pipeline execution. continuous Whether pipeline continuous triggered. development Whether pipeline Development mode. edition Pipeline product edition. expected_last_modified present, last-modified time pipeline settings edit. filters Filters Pipeline packages include deployed graph. id Unique identifier pipeline. libraries Libraries code needed deployment. name Friendly identifier pipeline. photon Whether Photon enabled pipeline. serverless Whether serverless compute enabled pipeline. storage DBFS root directory storing checkpoints tables. target Target schema (database) add tables pipeline . trigger pipeline trigger use.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesUpdatePipelinePermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Update pipeline permissions. — pipelinesUpdatePipelinePermissions","title":"Update pipeline permissions. — pipelinesUpdatePipelinePermissions","text":"Updates permissions pipeline. Pipelines can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesUpdatePipelinePermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update pipeline permissions. — pipelinesUpdatePipelinePermissions","text":"","code":"pipelinesUpdatePipelinePermissions(   client,   pipeline_id,   access_control_list = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/pipelinesUpdatePipelinePermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update pipeline permissions. — pipelinesUpdatePipelinePermissions","text":"client Required. Instance DatabricksClient() pipeline_id Required. pipeline get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/policyFamiliesGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get policy family information. — policyFamiliesGet","title":"Get policy family information. — policyFamiliesGet","text":"Retrieve information policy family based identifier.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/policyFamiliesGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get policy family information. — policyFamiliesGet","text":"","code":"policyFamiliesGet(client, policy_family_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/policyFamiliesGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get policy family information. — policyFamiliesGet","text":"client Required. Instance DatabricksClient() policy_family_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/policyFamiliesList.html","id":null,"dir":"Reference","previous_headings":"","what":"List policy families. — policyFamiliesList","title":"List policy families. — policyFamiliesList","text":"Retrieve list policy families. API paginated.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/policyFamiliesList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List policy families. — policyFamiliesList","text":"","code":"policyFamiliesList(client, max_results = NULL, page_token = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/policyFamiliesList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List policy families. — policyFamiliesList","text":"client Required. Instance DatabricksClient() max_results max number policy families return. page_token token can used get next page results.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/policyFamiliesList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List policy families. — policyFamiliesList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an auth provider. — providersCreate","title":"Create an auth provider. — providersCreate","text":"Creates new authentication provider minimally based name authentication type. caller must admin metastore.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an auth provider. — providersCreate","text":"","code":"providersCreate(   client,   name,   authentication_type,   comment = NULL,   recipient_profile_str = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an auth provider. — providersCreate","text":"client Required. Instance DatabricksClient() name Required. name Provider. authentication_type Required. delta sharing authentication type. comment Description provider. recipient_profile_str field required authentication_type TOKEN provided.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a provider. — providersDelete","title":"Delete a provider. — providersDelete","text":"Deletes authentication provider, caller metastore admin owner provider.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a provider. — providersDelete","text":"","code":"providersDelete(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a provider. — providersDelete","text":"client Required. Instance DatabricksClient() name Required. Name provider.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a provider. — providersGet","title":"Get a provider. — providersGet","text":"Gets specific authentication provider. caller must supply name provider, must either metastore admin owner provider.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a provider. — providersGet","text":"","code":"providersGet(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a provider. — providersGet","text":"client Required. Instance DatabricksClient() name Required. Name provider.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersList.html","id":null,"dir":"Reference","previous_headings":"","what":"List providers. — providersList","title":"List providers. — providersList","text":"Gets array available authentication providers. caller must either metastore admin owner providers. Providers owned caller included response. guarantee specific ordering elements array.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List providers. — providersList","text":"","code":"providersList(client, data_provider_global_metastore_id = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List providers. — providersList","text":"client Required. Instance DatabricksClient() data_provider_global_metastore_id provided, providers returned.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List providers. — providersList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersListShares.html","id":null,"dir":"Reference","previous_headings":"","what":"List shares by Provider. — providersListShares","title":"List shares by Provider. — providersListShares","text":"Gets array specified provider's shares within metastore :","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersListShares.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List shares by Provider. — providersListShares","text":"","code":"providersListShares(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersListShares.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List shares by Provider. — providersListShares","text":"client Required. Instance DatabricksClient() name Required. Name provider list shares.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersListShares.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List shares by Provider. — providersListShares","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersListShares.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List shares by Provider. — providersListShares","text":"caller metastore admin, * caller owner.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a provider. — providersUpdate","title":"Update a provider. — providersUpdate","text":"Updates information authentication provider, caller metastore admin owner provider. update changes provider name, caller must metastore admin owner provider.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a provider. — providersUpdate","text":"","code":"providersUpdate(   client,   name,   comment = NULL,   owner = NULL,   recipient_profile_str = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/providersUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a provider. — providersUpdate","text":"client Required. Instance DatabricksClient() name name Provider. comment Description provider. owner Username Provider owner. recipient_profile_str field required authentication_type TOKEN provided.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new query definition. — queriesCreate","title":"Create a new query definition. — queriesCreate","text":"Creates new query definition. Queries created endpoint belong authenticated user making request.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new query definition. — queriesCreate","text":"","code":"queriesCreate(   client,   data_source_id = NULL,   description = NULL,   name = NULL,   options = NULL,   parent = NULL,   query = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new query definition. — queriesCreate","text":"client Required. Instance DatabricksClient() data_source_id Data source ID. description General description conveys additional information query usage notes. name title query appears list views, widget headings, query page. options Exclusively used storing list parameter definitions. parent identifier workspace folder containing object. query text query run.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesCreate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a new query definition. — queriesCreate","text":"data_source_id field specifies ID SQL warehouse run query . can use Data Sources API see complete list available SQL warehouses. can copy data_source_id existing query. Note: add visualization create query.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a query. — queriesDelete","title":"Delete a query. — queriesDelete","text":"Moves query trash. Trashed queries immediately disappear searches list views, used alerts. trash deleted 30 days.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a query. — queriesDelete","text":"","code":"queriesDelete(client, query_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a query. — queriesDelete","text":"client Required. Instance DatabricksClient() query_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a query definition. — queriesGet","title":"Get a query definition. — queriesGet","text":"Retrieve query object definition along contextual permissions information currently authenticated user.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a query definition. — queriesGet","text":"","code":"queriesGet(client, query_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a query definition. — queriesGet","text":"client Required. Instance DatabricksClient() query_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesList.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a list of queries. — queriesList","title":"Get a list of queries. — queriesList","text":"Gets list queries. Optionally, list can filtered search term.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a list of queries. — queriesList","text":"","code":"queriesList(client, order = NULL, page = NULL, page_size = NULL, q = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a list of queries. — queriesList","text":"client Required. Instance DatabricksClient() order Name query attribute order . page Page number retrieve. page_size Number queries return per page. q Full text search term.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a list of queries. — queriesList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesRestore.html","id":null,"dir":"Reference","previous_headings":"","what":"Restore a query. — queriesRestore","title":"Restore a query. — queriesRestore","text":"Restore query moved trash. restored query appears list views searches. can use restored queries alerts.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesRestore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restore a query. — queriesRestore","text":"","code":"queriesRestore(client, query_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesRestore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restore a query. — queriesRestore","text":"client Required. Instance DatabricksClient() query_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Change a query definition. — queriesUpdate","title":"Change a query definition. — queriesUpdate","text":"Modify query definition.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change a query definition. — queriesUpdate","text":"","code":"queriesUpdate(   client,   query_id,   data_source_id = NULL,   description = NULL,   name = NULL,   options = NULL,   query = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change a query definition. — queriesUpdate","text":"client Required. Instance DatabricksClient() query_id Required. data_source_id Data source ID. description General description conveys additional information query usage notes. name title query appears list views, widget headings, query page. options Exclusively used storing list parameter definitions. query text query run.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queriesUpdate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Change a query definition. — queriesUpdate","text":"Note: undo operation.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queryHistoryList.html","id":null,"dir":"Reference","previous_headings":"","what":"List Queries. — queryHistoryList","title":"List Queries. — queryHistoryList","text":"List history queries SQL warehouses.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queryHistoryList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List Queries. — queryHistoryList","text":"","code":"queryHistoryList(   client,   filter_by = NULL,   include_metrics = NULL,   max_results = NULL,   page_token = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queryHistoryList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List Queries. — queryHistoryList","text":"client Required. Instance DatabricksClient() filter_by filter limit query history results. include_metrics Whether include metrics query. max_results Limit number results returned one page. page_token token can used get next page results.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queryHistoryList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List Queries. — queryHistoryList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/queryHistoryList.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List Queries. — queryHistoryList","text":"can filter user ID, warehouse ID, status, time range.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientActivationGetActivationUrlInfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a share activation URL. — recipientActivationGetActivationUrlInfo","title":"Get a share activation URL. — recipientActivationGetActivationUrlInfo","text":"Gets activation URL share.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientActivationGetActivationUrlInfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a share activation URL. — recipientActivationGetActivationUrlInfo","text":"","code":"recipientActivationGetActivationUrlInfo(client, activation_url)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientActivationGetActivationUrlInfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a share activation URL. — recipientActivationGetActivationUrlInfo","text":"client Required. Instance DatabricksClient() activation_url Required. one time activation url.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientActivationRetrieveToken.html","id":null,"dir":"Reference","previous_headings":"","what":"Get an access token. — recipientActivationRetrieveToken","title":"Get an access token. — recipientActivationRetrieveToken","text":"Retrieve access token activation url. public API without authentication.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientActivationRetrieveToken.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get an access token. — recipientActivationRetrieveToken","text":"","code":"recipientActivationRetrieveToken(client, activation_url)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientActivationRetrieveToken.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get an access token. — recipientActivationRetrieveToken","text":"client Required. Instance DatabricksClient() activation_url Required. one time activation url.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a share recipient. — recipientsCreate","title":"Create a share recipient. — recipientsCreate","text":"Creates new recipient delta sharing authentication type metastore. caller must metastore admin CREATE_RECIPIENT privilege metastore.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a share recipient. — recipientsCreate","text":"","code":"recipientsCreate(   client,   name,   authentication_type,   comment = NULL,   data_recipient_global_metastore_id = NULL,   ip_access_list = NULL,   owner = NULL,   properties_kvpairs = NULL,   sharing_code = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a share recipient. — recipientsCreate","text":"client Required. Instance DatabricksClient() name Required. Name Recipient. authentication_type Required. delta sharing authentication type. comment Description recipient. data_recipient_global_metastore_id global Unity Catalog metastore id provided data recipient. ip_access_list IP Access List. owner Username recipient owner. properties_kvpairs Recipient properties map string key-value pairs. sharing_code one-time sharing code provided data recipient.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a share recipient. — recipientsDelete","title":"Delete a share recipient. — recipientsDelete","text":"Deletes specified recipient metastore. caller must owner recipient.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a share recipient. — recipientsDelete","text":"","code":"recipientsDelete(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a share recipient. — recipientsDelete","text":"client Required. Instance DatabricksClient() name Required. Name recipient.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a share recipient. — recipientsGet","title":"Get a share recipient. — recipientsGet","text":"Gets share recipient metastore :","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a share recipient. — recipientsGet","text":"","code":"recipientsGet(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a share recipient. — recipientsGet","text":"client Required. Instance DatabricksClient() name Required. Name recipient.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsGet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get a share recipient. — recipientsGet","text":"caller owner share recipient, : * metastore admin","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsList.html","id":null,"dir":"Reference","previous_headings":"","what":"List share recipients. — recipientsList","title":"List share recipients. — recipientsList","text":"Gets array share recipients within current metastore :","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List share recipients. — recipientsList","text":"","code":"recipientsList(client, data_recipient_global_metastore_id = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List share recipients. — recipientsList","text":"client Required. Instance DatabricksClient() data_recipient_global_metastore_id provided, recipients returned.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List share recipients. — recipientsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsList.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List share recipients. — recipientsList","text":"caller metastore admin, * caller owner. guarantee specific ordering elements array.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsRotateToken.html","id":null,"dir":"Reference","previous_headings":"","what":"Rotate a token. — recipientsRotateToken","title":"Rotate a token. — recipientsRotateToken","text":"Refreshes specified recipient's delta sharing authentication token provided token info. caller must owner recipient.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsRotateToken.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rotate a token. — recipientsRotateToken","text":"","code":"recipientsRotateToken(client, existing_token_expire_in_seconds, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsRotateToken.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rotate a token. — recipientsRotateToken","text":"client Required. Instance DatabricksClient() existing_token_expire_in_seconds Required. expiration time bearer token ISO 8601 format. name Required. name recipient.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsSharePermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get recipient share permissions. — recipientsSharePermissions","title":"Get recipient share permissions. — recipientsSharePermissions","text":"Gets share permissions specified Recipient. caller must metastore admin owner Recipient.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsSharePermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get recipient share permissions. — recipientsSharePermissions","text":"","code":"recipientsSharePermissions(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsSharePermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get recipient share permissions. — recipientsSharePermissions","text":"client Required. Instance DatabricksClient() name Required. name Recipient.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a share recipient. — recipientsUpdate","title":"Update a share recipient. — recipientsUpdate","text":"Updates existing recipient metastore. caller must metastore admin owner recipient. recipient name updated, user must metastore admin owner recipient.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a share recipient. — recipientsUpdate","text":"","code":"recipientsUpdate(   client,   name,   comment = NULL,   ip_access_list = NULL,   owner = NULL,   properties_kvpairs = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/recipientsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a share recipient. — recipientsUpdate","text":"client Required. Instance DatabricksClient() name Name Recipient. comment Description recipient. ip_access_list IP Access List. owner Username recipient owner. properties_kvpairs Recipient properties map string key-value pairs.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a repo. — reposCreate","title":"Create a repo. — reposCreate","text":"Creates repo workspace links remote Git repo specified. Note repos created programmatically must linked remote Git repo, unlike repos created browser.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a repo. — reposCreate","text":"","code":"reposCreate(client, url, provider, path = NULL, sparse_checkout = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a repo. — reposCreate","text":"client Required. Instance DatabricksClient() url Required. URL Git repository linked. provider Required. Git provider. path Desired path repo workspace. sparse_checkout specified, repo created sparse checkout enabled.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a repo. — reposDelete","title":"Delete a repo. — reposDelete","text":"Deletes specified repo.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a repo. — reposDelete","text":"","code":"reposDelete(client, repo_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a repo. — reposDelete","text":"client Required. Instance DatabricksClient() repo_id Required. ID corresponding repo access.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a repo. — reposGet","title":"Get a repo. — reposGet","text":"Returns repo given repo ID.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a repo. — reposGet","text":"","code":"reposGet(client, repo_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a repo. — reposGet","text":"client Required. Instance DatabricksClient() repo_id Required. ID corresponding repo access.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposGetRepoPermissionLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Get repo permission levels. — reposGetRepoPermissionLevels","title":"Get repo permission levels. — reposGetRepoPermissionLevels","text":"Gets permission levels user can object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposGetRepoPermissionLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get repo permission levels. — reposGetRepoPermissionLevels","text":"","code":"reposGetRepoPermissionLevels(client, repo_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposGetRepoPermissionLevels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get repo permission levels. — reposGetRepoPermissionLevels","text":"client Required. Instance DatabricksClient() repo_id Required. repo get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposGetRepoPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get repo permissions. — reposGetRepoPermissions","title":"Get repo permissions. — reposGetRepoPermissions","text":"Gets permissions repo. Repos can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposGetRepoPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get repo permissions. — reposGetRepoPermissions","text":"","code":"reposGetRepoPermissions(client, repo_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposGetRepoPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get repo permissions. — reposGetRepoPermissions","text":"client Required. Instance DatabricksClient() repo_id Required. repo get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposList.html","id":null,"dir":"Reference","previous_headings":"","what":"Get repos. — reposList","title":"Get repos. — reposList","text":"Returns repos calling user Manage permissions . Results paginated page containing twenty repos.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get repos. — reposList","text":"","code":"reposList(client, next_page_token = NULL, path_prefix = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get repos. — reposList","text":"client Required. Instance DatabricksClient() next_page_token Token used get next page results. path_prefix Filters repos paths starting given path prefix.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get repos. — reposList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposSetRepoPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Set repo permissions. — reposSetRepoPermissions","title":"Set repo permissions. — reposSetRepoPermissions","text":"Sets permissions repo. Repos can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposSetRepoPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set repo permissions. — reposSetRepoPermissions","text":"","code":"reposSetRepoPermissions(client, repo_id, access_control_list = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposSetRepoPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set repo permissions. — reposSetRepoPermissions","text":"client Required. Instance DatabricksClient() repo_id Required. repo get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a repo. — reposUpdate","title":"Update a repo. — reposUpdate","text":"Updates repo different branch tag, updates repo latest commit branch.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a repo. — reposUpdate","text":"","code":"reposUpdate(client, repo_id, branch = NULL, sparse_checkout = NULL, tag = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a repo. — reposUpdate","text":"client Required. Instance DatabricksClient() repo_id Required. ID corresponding repo access. branch Branch local version repo checked . sparse_checkout specified, update sparse checkout settings. tag Tag local version repo checked .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposUpdateRepoPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Update repo permissions. — reposUpdateRepoPermissions","title":"Update repo permissions. — reposUpdateRepoPermissions","text":"Updates permissions repo. Repos can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposUpdateRepoPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update repo permissions. — reposUpdateRepoPermissions","text":"","code":"reposUpdateRepoPermissions(client, repo_id, access_control_list = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/reposUpdateRepoPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update repo permissions. — reposUpdateRepoPermissions","text":"client Required. Instance DatabricksClient() repo_id Required. repo get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a schema. — schemasCreate","title":"Create a schema. — schemasCreate","text":"Creates new schema catalog Metatastore. caller must metastore admin, CREATE_SCHEMA privilege parent catalog.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a schema. — schemasCreate","text":"","code":"schemasCreate(   client,   name,   catalog_name,   comment = NULL,   properties = NULL,   storage_root = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a schema. — schemasCreate","text":"client Required. Instance DatabricksClient() name Required. Name schema, relative parent catalog. catalog_name Required. Name parent catalog. comment User-provided free-form text description. properties map key-value properties attached securable. storage_root Storage root URL managed tables within schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a schema. — schemasDelete","title":"Delete a schema. — schemasDelete","text":"Deletes specified schema parent catalog. caller must owner schema owner parent catalog.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a schema. — schemasDelete","text":"","code":"schemasDelete(client, full_name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a schema. — schemasDelete","text":"client Required. Instance DatabricksClient() full_name Required. Full name schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a schema. — schemasGet","title":"Get a schema. — schemasGet","text":"Gets specified schema within metastore. caller must metastore admin, owner schema, user USE_SCHEMA privilege schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a schema. — schemasGet","text":"","code":"schemasGet(client, full_name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a schema. — schemasGet","text":"client Required. Instance DatabricksClient() full_name Required. Full name schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasList.html","id":null,"dir":"Reference","previous_headings":"","what":"List schemas. — schemasList","title":"List schemas. — schemasList","text":"Gets array schemas catalog metastore. caller metastore admin owner parent catalog, schemas catalog retrieved. Otherwise, schemas owned caller (caller USE_SCHEMA privilege) retrieved. guarantee specific ordering elements array.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List schemas. — schemasList","text":"","code":"schemasList(client, catalog_name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List schemas. — schemasList","text":"client Required. Instance DatabricksClient() catalog_name Required. Parent catalog schemas interest.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List schemas. — schemasList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a schema. — schemasUpdate","title":"Update a schema. — schemasUpdate","text":"Updates schema catalog. caller must owner schema metastore admin. caller metastore admin, owner field can changed update. name field must updated, caller must metastore admin CREATE_SCHEMA privilege parent catalog.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a schema. — schemasUpdate","text":"","code":"schemasUpdate(   client,   full_name,   comment = NULL,   name = NULL,   owner = NULL,   properties = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/schemasUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a schema. — schemasUpdate","text":"client Required. Instance DatabricksClient() full_name Required. Full name schema. comment User-provided free-form text description. name Name schema, relative parent catalog. owner Username current owner schema. properties map key-value properties attached securable.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsCreateScope.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new secret scope. — secretsCreateScope","title":"Create a new secret scope. — secretsCreateScope","text":"scope name must consist alphanumeric characters, dashes, underscores, periods, may exceed 128 characters. maximum number scopes workspace 100.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsCreateScope.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new secret scope. — secretsCreateScope","text":"","code":"secretsCreateScope(   client,   scope,   backend_azure_keyvault = NULL,   initial_manage_principal = NULL,   scope_backend_type = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsCreateScope.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new secret scope. — secretsCreateScope","text":"client Required. Instance DatabricksClient() scope Required. Scope name requested user. backend_azure_keyvault metadata secret scope type AZURE_KEYVAULT. initial_manage_principal principal initially granted MANAGE permission created scope. scope_backend_type backend type scope created .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsDeleteAcl.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete an ACL. — secretsDeleteAcl","title":"Delete an ACL. — secretsDeleteAcl","text":"Deletes given ACL given scope.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsDeleteAcl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete an ACL. — secretsDeleteAcl","text":"","code":"secretsDeleteAcl(client, scope, principal)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsDeleteAcl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete an ACL. — secretsDeleteAcl","text":"client Required. Instance DatabricksClient() scope Required. name scope remove permissions . principal Required. principal remove existing ACL .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsDeleteAcl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Delete an ACL. — secretsDeleteAcl","text":"Users must MANAGE permission invoke API. Throws RESOURCE_DOES_NOT_EXIST secret scope, principal, ACL exists. Throws PERMISSION_DENIED user permission make API call.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsDeleteScope.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a secret scope. — secretsDeleteScope","title":"Delete a secret scope. — secretsDeleteScope","text":"Deletes secret scope.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsDeleteScope.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a secret scope. — secretsDeleteScope","text":"","code":"secretsDeleteScope(client, scope)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsDeleteScope.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a secret scope. — secretsDeleteScope","text":"client Required. Instance DatabricksClient() scope Required. Name scope delete.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsDeleteScope.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Delete a secret scope. — secretsDeleteScope","text":"Throws RESOURCE_DOES_NOT_EXIST scope exist. Throws PERMISSION_DENIED user permission make API call.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsDeleteSecret.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a secret. — secretsDeleteSecret","title":"Delete a secret. — secretsDeleteSecret","text":"Deletes secret stored secret scope. must WRITE MANAGE permission secret scope.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsDeleteSecret.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a secret. — secretsDeleteSecret","text":"","code":"secretsDeleteSecret(client, scope, key)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsDeleteSecret.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a secret. — secretsDeleteSecret","text":"client Required. Instance DatabricksClient() scope Required. name scope contains secret delete. key Required. Name secret delete.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsDeleteSecret.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Delete a secret. — secretsDeleteSecret","text":"Throws RESOURCE_DOES_NOT_EXIST secret scope secret exists. Throws PERMISSION_DENIED user permission make API call.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsGetAcl.html","id":null,"dir":"Reference","previous_headings":"","what":"Get secret ACL details. — secretsGetAcl","title":"Get secret ACL details. — secretsGetAcl","text":"Gets details given ACL, group permission. Users must MANAGE permission invoke API.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsGetAcl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get secret ACL details. — secretsGetAcl","text":"","code":"secretsGetAcl(client, scope, principal)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsGetAcl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get secret ACL details. — secretsGetAcl","text":"client Required. Instance DatabricksClient() scope Required. name scope fetch ACL information . principal Required. principal fetch ACL information .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsGetAcl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get secret ACL details. — secretsGetAcl","text":"Throws RESOURCE_DOES_NOT_EXIST secret scope exists. Throws PERMISSION_DENIED user permission make API call.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsListAcls.html","id":null,"dir":"Reference","previous_headings":"","what":"Lists ACLs. — secretsListAcls","title":"Lists ACLs. — secretsListAcls","text":"List ACLs given secret scope. Users must MANAGE permission invoke API.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsListAcls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lists ACLs. — secretsListAcls","text":"","code":"secretsListAcls(client, scope)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsListAcls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lists ACLs. — secretsListAcls","text":"client Required. Instance DatabricksClient() scope Required. name scope fetch ACL information .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsListAcls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lists ACLs. — secretsListAcls","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsListAcls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Lists ACLs. — secretsListAcls","text":"Throws RESOURCE_DOES_NOT_EXIST secret scope exists. Throws PERMISSION_DENIED user permission make API call.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsListScopes.html","id":null,"dir":"Reference","previous_headings":"","what":"List all scopes. — secretsListScopes","title":"List all scopes. — secretsListScopes","text":"Lists secret scopes available workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsListScopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List all scopes. — secretsListScopes","text":"","code":"secretsListScopes(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsListScopes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List all scopes. — secretsListScopes","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsListScopes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List all scopes. — secretsListScopes","text":"Throws PERMISSION_DENIED user permission make API call.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsListSecrets.html","id":null,"dir":"Reference","previous_headings":"","what":"List secret keys. — secretsListSecrets","title":"List secret keys. — secretsListSecrets","text":"Lists secret keys stored scope. metadata-operation; secret data retrieved using API. Users need READ permission make call.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsListSecrets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List secret keys. — secretsListSecrets","text":"","code":"secretsListSecrets(client, scope)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsListSecrets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List secret keys. — secretsListSecrets","text":"client Required. Instance DatabricksClient() scope Required. name scope list secrets within.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsListSecrets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List secret keys. — secretsListSecrets","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsListSecrets.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List secret keys. — secretsListSecrets","text":"lastUpdatedTimestamp returned milliseconds since epoch. Throws RESOURCE_DOES_NOT_EXIST secret scope exists. Throws PERMISSION_DENIED user permission make API call.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsPutAcl.html","id":null,"dir":"Reference","previous_headings":"","what":"Create/update an ACL. — secretsPutAcl","title":"Create/update an ACL. — secretsPutAcl","text":"Creates overwrites Access Control List (ACL) associated given principal (user group) specified scope point.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsPutAcl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create/update an ACL. — secretsPutAcl","text":"","code":"secretsPutAcl(client, scope, principal, permission)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsPutAcl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create/update an ACL. — secretsPutAcl","text":"client Required. Instance DatabricksClient() scope Required. name scope apply permissions . principal Required. principal permission applied. permission Required. permission level applied principal.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsPutAcl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create/update an ACL. — secretsPutAcl","text":"general, user group use powerful permission available , permissions ordered follows: MANAGE - Allowed change ACLs, read write secret scope. WRITE - Allowed read write secret scope. * READ - Allowed read secret scope list secrets available. Note general, secret values can read within command cluster (example, notebook). API read actual secret value material outside cluster. However, user's permission applied based executing command, must least READ permission. Users must MANAGE permission invoke API. principal user group name corresponding existing Databricks principal granted revoked access. Throws RESOURCE_DOES_NOT_EXIST secret scope exists. Throws RESOURCE_ALREADY_EXISTS permission principal already exists. Throws INVALID_PARAMETER_VALUE permission principal invalid. Throws PERMISSION_DENIED user permission make API call.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsPutSecret.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a secret. — secretsPutSecret","title":"Add a secret. — secretsPutSecret","text":"Inserts secret provided scope given name. secret already exists name, command overwrites existing secret's value. server encrypts secret using secret scope's encryption settings storing .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsPutSecret.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a secret. — secretsPutSecret","text":"","code":"secretsPutSecret(client, scope, key, bytes_value = NULL, string_value = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsPutSecret.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a secret. — secretsPutSecret","text":"client Required. Instance DatabricksClient() scope Required. name scope secret associated . key Required. unique name identify secret. bytes_value specified, value stored bytes. string_value specified, note value stored UTF-8 (MB4) form.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/secretsPutSecret.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add a secret. — secretsPutSecret","text":"must WRITE MANAGE permission secret scope. secret key must consist alphanumeric characters, dashes, underscores, periods, exceed 128 characters. maximum allowed secret value size 128 KB. maximum number secrets given scope 1000. input fields 'string_value' 'bytes_value' specify type secret, determine value returned secret value requested. Exactly one must specified. Throws RESOURCE_DOES_NOT_EXIST secret scope exists. Throws RESOURCE_LIMIT_EXCEEDED maximum number secrets scope exceeded. Throws INVALID_PARAMETER_VALUE key name value length invalid. Throws PERMISSION_DENIED user permission make API call.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a service principal. — servicePrincipalsCreate","title":"Create a service principal. — servicePrincipalsCreate","text":"Creates new service principal Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a service principal. — servicePrincipalsCreate","text":"","code":"servicePrincipalsCreate(   client,   active = NULL,   application_id = NULL,   display_name = NULL,   entitlements = NULL,   external_id = NULL,   groups = NULL,   id = NULL,   roles = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a service principal. — servicePrincipalsCreate","text":"client Required. Instance DatabricksClient() active user active. application_id UUID relating service principal. display_name String represents concatenation given family names. entitlements  external_id  groups  id Databricks service principal ID. roles","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a service principal. — servicePrincipalsDelete","title":"Delete a service principal. — servicePrincipalsDelete","text":"Delete single service principal Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a service principal. — servicePrincipalsDelete","text":"","code":"servicePrincipalsDelete(client, id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a service principal. — servicePrincipalsDelete","text":"client Required. Instance DatabricksClient() id Required. Unique ID service principal Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get service principal details. — servicePrincipalsGet","title":"Get service principal details. — servicePrincipalsGet","text":"Gets details single service principal define Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get service principal details. — servicePrincipalsGet","text":"","code":"servicePrincipalsGet(client, id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get service principal details. — servicePrincipalsGet","text":"client Required. Instance DatabricksClient() id Required. Unique ID service principal Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsList.html","id":null,"dir":"Reference","previous_headings":"","what":"List service principals. — servicePrincipalsList","title":"List service principals. — servicePrincipalsList","text":"Gets set service principals associated Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List service principals. — servicePrincipalsList","text":"","code":"servicePrincipalsList(   client,   attributes = NULL,   count = NULL,   excluded_attributes = NULL,   filter = NULL,   sort_by = NULL,   sort_order = NULL,   start_index = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List service principals. — servicePrincipalsList","text":"client Required. Instance DatabricksClient() attributes Comma-separated list attributes return response. count Desired number results per page. excluded_attributes Comma-separated list attributes exclude response. filter Query results filtered. sort_by Attribute sort results. sort_order order sort results. start_index Specifies index first result.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List service principals. — servicePrincipalsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsPatch.html","id":null,"dir":"Reference","previous_headings":"","what":"Update service principal details. — servicePrincipalsPatch","title":"Update service principal details. — servicePrincipalsPatch","text":"Partially updates details single service principal Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsPatch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update service principal details. — servicePrincipalsPatch","text":"","code":"servicePrincipalsPatch(client, id, operations = NULL, schema = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsPatch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update service principal details. — servicePrincipalsPatch","text":"client Required. Instance DatabricksClient() id Required. Unique ID service principal Databricks workspace. operations  schema schema patch request.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace service principal. — servicePrincipalsUpdate","title":"Replace service principal. — servicePrincipalsUpdate","text":"Updates details single service principal.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace service principal. — servicePrincipalsUpdate","text":"","code":"servicePrincipalsUpdate(   client,   id,   active = NULL,   application_id = NULL,   display_name = NULL,   entitlements = NULL,   external_id = NULL,   groups = NULL,   roles = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace service principal. — servicePrincipalsUpdate","text":"client Required. Instance DatabricksClient() id Databricks service principal ID. active user active. application_id UUID relating service principal. display_name String represents concatenation given family names. entitlements  external_id  groups  roles","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servicePrincipalsUpdate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Replace service principal. — servicePrincipalsUpdate","text":"action replaces existing service principal name.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsBuildLogs.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the logs associated with building the model's environment for a\ngiven serving endpoint's served model. — servingEndpointsBuildLogs","title":"Retrieve the logs associated with building the model's environment for a\ngiven serving endpoint's served model. — servingEndpointsBuildLogs","text":"Retrieves build logs associated provided served model.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsBuildLogs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the logs associated with building the model's environment for a\ngiven serving endpoint's served model. — servingEndpointsBuildLogs","text":"","code":"servingEndpointsBuildLogs(client, name, served_model_name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsBuildLogs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the logs associated with building the model's environment for a\ngiven serving endpoint's served model. — servingEndpointsBuildLogs","text":"client Required. Instance DatabricksClient() name Required. name serving endpoint served model belongs . served_model_name Required. name served model build logs retrieved .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new serving endpoint. — servingEndpointsCreate","title":"Create a new serving endpoint. — servingEndpointsCreate","text":"long-running operation, blocks Serving Endpoints Databricks reach NOT_UPDATING state timeout 20 minutes, can change via timeout parameter. default, state Databricks Serving Endpoints reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new serving endpoint. — servingEndpointsCreate","text":"","code":"servingEndpointsCreate(   client,   name,   config,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new serving endpoint. — servingEndpointsCreate","text":"client Required. Instance DatabricksClient() name Required. name serving endpoint. config Required. core config serving endpoint.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a serving endpoint. — servingEndpointsDelete","title":"Delete a serving endpoint. — servingEndpointsDelete","text":"Delete serving endpoint.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a serving endpoint. — servingEndpointsDelete","text":"","code":"servingEndpointsDelete(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a serving endpoint. — servingEndpointsDelete","text":"client Required. Instance DatabricksClient() name Required. name serving endpoint.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsExportMetrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the metrics associated with a serving endpoint. — servingEndpointsExportMetrics","title":"Retrieve the metrics associated with a serving endpoint. — servingEndpointsExportMetrics","text":"Retrieves metrics associated provided serving endpoint either Prometheus OpenMetrics exposition format.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsExportMetrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the metrics associated with a serving endpoint. — servingEndpointsExportMetrics","text":"","code":"servingEndpointsExportMetrics(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsExportMetrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the metrics associated with a serving endpoint. — servingEndpointsExportMetrics","text":"client Required. Instance DatabricksClient() name Required. name serving endpoint retrieve metrics .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a single serving endpoint. — servingEndpointsGet","title":"Get a single serving endpoint. — servingEndpointsGet","text":"Retrieves details single serving endpoint.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a single serving endpoint. — servingEndpointsGet","text":"","code":"servingEndpointsGet(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a single serving endpoint. — servingEndpointsGet","text":"client Required. Instance DatabricksClient() name Required. name serving endpoint.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsGetServingEndpointPermissionLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Get serving endpoint permission levels. — servingEndpointsGetServingEndpointPermissionLevels","title":"Get serving endpoint permission levels. — servingEndpointsGetServingEndpointPermissionLevels","text":"Gets permission levels user can object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsGetServingEndpointPermissionLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get serving endpoint permission levels. — servingEndpointsGetServingEndpointPermissionLevels","text":"","code":"servingEndpointsGetServingEndpointPermissionLevels(client, serving_endpoint_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsGetServingEndpointPermissionLevels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get serving endpoint permission levels. — servingEndpointsGetServingEndpointPermissionLevels","text":"client Required. Instance DatabricksClient() serving_endpoint_id Required. serving endpoint get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsGetServingEndpointPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get serving endpoint permissions. — servingEndpointsGetServingEndpointPermissions","title":"Get serving endpoint permissions. — servingEndpointsGetServingEndpointPermissions","text":"Gets permissions serving endpoint. Serving endpoints can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsGetServingEndpointPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get serving endpoint permissions. — servingEndpointsGetServingEndpointPermissions","text":"","code":"servingEndpointsGetServingEndpointPermissions(client, serving_endpoint_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsGetServingEndpointPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get serving endpoint permissions. — servingEndpointsGetServingEndpointPermissions","text":"client Required. Instance DatabricksClient() serving_endpoint_id Required. serving endpoint get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsList.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve all serving endpoints.#' — servingEndpointsList","title":"Retrieve all serving endpoints.#' — servingEndpointsList","text":"Retrieve serving endpoints.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve all serving endpoints.#' — servingEndpointsList","text":"","code":"servingEndpointsList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve all serving endpoints.#' — servingEndpointsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsLogs.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the most recent log lines associated with a given serving endpoint's\nserved model. — servingEndpointsLogs","title":"Retrieve the most recent log lines associated with a given serving endpoint's\nserved model. — servingEndpointsLogs","text":"Retrieves service logs associated provided served model.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsLogs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the most recent log lines associated with a given serving endpoint's\nserved model. — servingEndpointsLogs","text":"","code":"servingEndpointsLogs(client, name, served_model_name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsLogs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the most recent log lines associated with a given serving endpoint's\nserved model. — servingEndpointsLogs","text":"client Required. Instance DatabricksClient() name Required. name serving endpoint served model belongs . served_model_name Required. name served model logs retrieved .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsQuery.html","id":null,"dir":"Reference","previous_headings":"","what":"Query a serving endpoint with provided model input. — servingEndpointsQuery","title":"Query a serving endpoint with provided model input. — servingEndpointsQuery","text":"Query serving endpoint provided model input.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsQuery.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query a serving endpoint with provided model input. — servingEndpointsQuery","text":"","code":"servingEndpointsQuery(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsQuery.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query a serving endpoint with provided model input. — servingEndpointsQuery","text":"client Required. Instance DatabricksClient() name Required. name serving endpoint.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsSetServingEndpointPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Set serving endpoint permissions. — servingEndpointsSetServingEndpointPermissions","title":"Set serving endpoint permissions. — servingEndpointsSetServingEndpointPermissions","text":"Sets permissions serving endpoint. Serving endpoints can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsSetServingEndpointPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set serving endpoint permissions. — servingEndpointsSetServingEndpointPermissions","text":"","code":"servingEndpointsSetServingEndpointPermissions(   client,   serving_endpoint_id,   access_control_list = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsSetServingEndpointPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set serving endpoint permissions. — servingEndpointsSetServingEndpointPermissions","text":"client Required. Instance DatabricksClient() serving_endpoint_id Required. serving endpoint get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsUpdateConfig.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a serving endpoint with a new config. — servingEndpointsUpdateConfig","title":"Update a serving endpoint with a new config. — servingEndpointsUpdateConfig","text":"long-running operation, blocks Serving Endpoints Databricks reach NOT_UPDATING state timeout 20 minutes, can change via timeout parameter. default, state Databricks Serving Endpoints reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsUpdateConfig.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a serving endpoint with a new config. — servingEndpointsUpdateConfig","text":"","code":"servingEndpointsUpdateConfig(   client,   served_models,   name,   traffic_config = NULL,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsUpdateConfig.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a serving endpoint with a new config. — servingEndpointsUpdateConfig","text":"client Required. Instance DatabricksClient() served_models Required. list served models endpoint serve. name Required. name serving endpoint update. traffic_config traffic config defining invocations serving endpoint routed.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsUpdateConfig.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update a serving endpoint with a new config. — servingEndpointsUpdateConfig","text":"Updates combination serving endpoint's served models, compute configuration served models, endpoint's traffic config. endpoint already update progress can updated current update completes fails.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsUpdateServingEndpointPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Update serving endpoint permissions. — servingEndpointsUpdateServingEndpointPermissions","title":"Update serving endpoint permissions. — servingEndpointsUpdateServingEndpointPermissions","text":"Updates permissions serving endpoint. Serving endpoints can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsUpdateServingEndpointPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update serving endpoint permissions. — servingEndpointsUpdateServingEndpointPermissions","text":"","code":"servingEndpointsUpdateServingEndpointPermissions(   client,   serving_endpoint_id,   access_control_list = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/servingEndpointsUpdateServingEndpointPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update serving endpoint permissions. — servingEndpointsUpdateServingEndpointPermissions","text":"client Required. Instance DatabricksClient() serving_endpoint_id Required. serving endpoint get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a share. — sharesCreate","title":"Create a share. — sharesCreate","text":"Creates new share data objects. Data objects can added creation update. caller must metastore admin CREATE_SHARE privilege metastore.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a share. — sharesCreate","text":"","code":"sharesCreate(client, name, comment = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a share. — sharesCreate","text":"client Required. Instance DatabricksClient() name Required. Name share. comment User-provided free-form text description.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a share. — sharesDelete","title":"Delete a share. — sharesDelete","text":"Deletes data object share metastore. caller must owner share.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a share. — sharesDelete","text":"","code":"sharesDelete(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a share. — sharesDelete","text":"client Required. Instance DatabricksClient() name Required. name share.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a share. — sharesGet","title":"Get a share. — sharesGet","text":"Gets data object share metastore. caller must metastore admin owner share.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a share. — sharesGet","text":"","code":"sharesGet(client, name, include_shared_data = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a share. — sharesGet","text":"client Required. Instance DatabricksClient() name Required. name share. include_shared_data Query data include share.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesList.html","id":null,"dir":"Reference","previous_headings":"","what":"List shares. — sharesList","title":"List shares. — sharesList","text":"Gets array data object shares metastore. caller must metastore admin owner share. guarantee specific ordering elements array.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List shares. — sharesList","text":"","code":"sharesList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List shares. — sharesList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesSharePermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get permissions. — sharesSharePermissions","title":"Get permissions. — sharesSharePermissions","text":"Gets permissions data share metastore. caller must metastore admin owner share.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesSharePermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get permissions. — sharesSharePermissions","text":"","code":"sharesSharePermissions(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesSharePermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get permissions. — sharesSharePermissions","text":"client Required. Instance DatabricksClient() name Required. name share.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a share. — sharesUpdate","title":"Update a share. — sharesUpdate","text":"Updates share changes data objects request. caller must owner share metastore admin.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a share. — sharesUpdate","text":"","code":"sharesUpdate(client, name, comment = NULL, owner = NULL, updates = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a share. — sharesUpdate","text":"client Required. Instance DatabricksClient() name Name share. comment User-provided free-form text description. owner Username current owner share. updates Array shared data object updates.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesUpdate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update a share. — sharesUpdate","text":"caller metastore admin, owner field can updated. case share name changed, updateShare requires caller share owner metastore admin. table added method, share owner must also SELECT privilege table. privilege must maintained indefinitely recipients able access table. Typically, use group share owner. Table removals update require additional privileges.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesUpdatePermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Update permissions. — sharesUpdatePermissions","title":"Update permissions. — sharesUpdatePermissions","text":"Updates permissions data share metastore. caller must metastore admin owner share.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesUpdatePermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update permissions. — sharesUpdatePermissions","text":"","code":"sharesUpdatePermissions(client, name, changes = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesUpdatePermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update permissions. — sharesUpdatePermissions","text":"client Required. Instance DatabricksClient() name Required. name share. changes Array permission changes.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/sharesUpdatePermissions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update permissions. — sharesUpdatePermissions","text":"new recipient grants, user must also owner recipients. recipient revocations require additional privileges.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/statementExecutionCancelExecution.html","id":null,"dir":"Reference","previous_headings":"","what":"Cancel statement execution. — statementExecutionCancelExecution","title":"Cancel statement execution. — statementExecutionCancelExecution","text":"Requests executing statement canceled. Callers must poll status see terminal state.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/statementExecutionCancelExecution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cancel statement execution. — statementExecutionCancelExecution","text":"","code":"statementExecutionCancelExecution(client, statement_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/statementExecutionCancelExecution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cancel statement execution. — statementExecutionCancelExecution","text":"client Required. Instance DatabricksClient() statement_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/statementExecutionExecuteStatement.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute a SQL statement. — statementExecutionExecuteStatement","title":"Execute a SQL statement. — statementExecutionExecuteStatement","text":"Execute SQL statement, flagged , await result specified time.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/statementExecutionExecuteStatement.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Execute a SQL statement. — statementExecutionExecuteStatement","text":"","code":"statementExecutionExecuteStatement(   client,   byte_limit = NULL,   catalog = NULL,   disposition = NULL,   format = NULL,   on_wait_timeout = NULL,   schema = NULL,   statement = NULL,   wait_timeout = NULL,   warehouse_id = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/statementExecutionExecuteStatement.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execute a SQL statement. — statementExecutionExecuteStatement","text":"client Required. Instance DatabricksClient() byte_limit Applies given byte limit statement's result size. catalog Sets default catalog statement execution, similar USE CATALOG SQL. disposition fetch disposition provides two modes fetching results: INLINE EXTERNAL_LINKS. format Statement execution supports three result formats: JSON_ARRAY (default), ARROW_STREAM, CSV. on_wait_timeout synchronous mode wait_timeout > 0s determines action taken timeout reached: CONTINUE → statement execution continues asynchronously call returns statement ID immediately. schema Sets default schema statement execution, similar USE SCHEMA SQL. statement SQL statement execute. wait_timeout time seconds API service wait statement's result set Ns, N can set 0 value 5 50. warehouse_id Warehouse upon execute statement.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/statementExecutionGetStatement.html","id":null,"dir":"Reference","previous_headings":"","what":"Get status, manifest, and result first chunk. — statementExecutionGetStatement","title":"Get status, manifest, and result first chunk. — statementExecutionGetStatement","text":"request can used poll statement's status. status.state field SUCCEEDED also return result manifest first chunk result data. statement terminal states CANCELED, CLOSED FAILED, returns HTTP 200 state set. least 12 hours terminal state, statement removed warehouse calls receive HTTP 404 response.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/statementExecutionGetStatement.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get status, manifest, and result first chunk. — statementExecutionGetStatement","text":"","code":"statementExecutionGetStatement(client, statement_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/statementExecutionGetStatement.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get status, manifest, and result first chunk. — statementExecutionGetStatement","text":"client Required. Instance DatabricksClient() statement_id Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/statementExecutionGetStatement.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get status, manifest, and result first chunk. — statementExecutionGetStatement","text":"NOTE call currently may take 5 seconds get latest status result.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/statementExecutionGetStatementResultChunkN.html","id":null,"dir":"Reference","previous_headings":"","what":"Get result chunk by index. — statementExecutionGetStatementResultChunkN","title":"Get result chunk by index. — statementExecutionGetStatementResultChunkN","text":"statement execution SUCCEEDED, result data can fetched chunks. Whereas first chuck chunk_index=0 typically fetched get status request, subsequent chunks can fetched using get result request. response structure identical nested result element described get status request, similarly includes next_chunk_index next_chunk_internal_link fields simple iteration result set.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/statementExecutionGetStatementResultChunkN.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get result chunk by index. — statementExecutionGetStatementResultChunkN","text":"","code":"statementExecutionGetStatementResultChunkN(client, statement_id, chunk_index)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/statementExecutionGetStatementResultChunkN.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get result chunk by index. — statementExecutionGetStatementResultChunkN","text":"client Required. Instance DatabricksClient() statement_id Required. chunk_index Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a storage credential. — storageCredentialsCreate","title":"Create a storage credential. — storageCredentialsCreate","text":"Creates new storage credential. request object specific cloud:","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a storage credential. — storageCredentialsCreate","text":"","code":"storageCredentialsCreate(   client,   name,   aws_iam_role = NULL,   azure_managed_identity = NULL,   azure_service_principal = NULL,   comment = NULL,   databricks_gcp_service_account = NULL,   read_only = NULL,   skip_validation = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a storage credential. — storageCredentialsCreate","text":"client Required. Instance DatabricksClient() name Required. credential name. aws_iam_role AWS IAM role configuration. azure_managed_identity Azure managed identity configuration. azure_service_principal Azure service principal configuration. comment Comment associated credential. databricks_gcp_service_account  managed GCP service account configuration. read_only Whether storage credential usable read operations. skip_validation Supplying true argument skips validation created credential.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsCreate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a storage credential. — storageCredentialsCreate","text":"AwsIamRole AWS credentials. * AzureServicePrincipal Azure credentials. * AzureManagedIdentity Azure managed credentials. * DatabricksGcpServiceAccount GCP managed credentials. caller must metastore admin CREATE_STORAGE_CREDENTIAL privilege metastore.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a credential. — storageCredentialsDelete","title":"Delete a credential. — storageCredentialsDelete","text":"Deletes storage credential metastore. caller must owner storage credential.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a credential. — storageCredentialsDelete","text":"","code":"storageCredentialsDelete(client, name, force = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a credential. — storageCredentialsDelete","text":"client Required. Instance DatabricksClient() name Required. Name storage credential. force Force deletion even dependent external locations external tables.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a credential. — storageCredentialsGet","title":"Get a credential. — storageCredentialsGet","text":"Gets storage credential metastore. caller must metastore admin, owner storage credential, permission storage credential.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a credential. — storageCredentialsGet","text":"","code":"storageCredentialsGet(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a credential. — storageCredentialsGet","text":"client Required. Instance DatabricksClient() name Required. Name storage credential.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsList.html","id":null,"dir":"Reference","previous_headings":"","what":"List credentials. — storageCredentialsList","title":"List credentials. — storageCredentialsList","text":"Gets array storage credentials (StorageCredentialInfo objects). array limited storage credentials caller permission access. caller metastore admin, storage credentials retrieved. guarantee specific ordering elements array.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List credentials. — storageCredentialsList","text":"","code":"storageCredentialsList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List credentials. — storageCredentialsList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a credential. — storageCredentialsUpdate","title":"Update a credential. — storageCredentialsUpdate","text":"Updates storage credential metastore. caller must owner storage credential metastore admin. caller metastore admin, owner credential can changed.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a credential. — storageCredentialsUpdate","text":"","code":"storageCredentialsUpdate(   client,   name,   aws_iam_role = NULL,   azure_managed_identity = NULL,   azure_service_principal = NULL,   comment = NULL,   databricks_gcp_service_account = NULL,   force = NULL,   owner = NULL,   read_only = NULL,   skip_validation = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a credential. — storageCredentialsUpdate","text":"client Required. Instance DatabricksClient() name credential name. aws_iam_role AWS IAM role configuration. azure_managed_identity Azure managed identity configuration. azure_service_principal Azure service principal configuration. comment Comment associated credential. databricks_gcp_service_account  managed GCP service account configuration. force Force update even dependent external locations external tables. owner Username current owner credential. read_only Whether storage credential usable read operations. skip_validation Supplying true argument skips validation updated credential.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsValidate.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate a storage credential. — storageCredentialsValidate","title":"Validate a storage credential. — storageCredentialsValidate","text":"Validates storage credential. least one external_location_name url need provided. one provided, used validation. provided, url used validation, external_location_name ignored checking overlapping urls.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsValidate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate a storage credential. — storageCredentialsValidate","text":"","code":"storageCredentialsValidate(   client,   aws_iam_role = NULL,   azure_managed_identity = NULL,   azure_service_principal = NULL,   databricks_gcp_service_account = NULL,   external_location_name = NULL,   read_only = NULL,   storage_credential_name = NULL,   url = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsValidate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate a storage credential. — storageCredentialsValidate","text":"client Required. Instance DatabricksClient() aws_iam_role AWS IAM role configuration. azure_managed_identity Azure managed identity configuration. azure_service_principal Azure service principal configuration. databricks_gcp_service_account Databricks created GCP service account configuration. external_location_name name existing external location validate. read_only Whether storage credential usable read operations. storage_credential_name name storage credential validate. url external location url validate.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/storageCredentialsValidate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate a storage credential. — storageCredentialsValidate","text":"Either storage_credential_name cloud-specific credential must provided. caller must metastore admin storage credential owner CREATE_EXTERNAL_LOCATION privilege metastore storage credential.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/systemSchemasDisable.html","id":null,"dir":"Reference","previous_headings":"","what":"Disable a system schema. — systemSchemasDisable","title":"Disable a system schema. — systemSchemasDisable","text":"Disables system schema removes system catalog. caller must account admin metastore admin.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/systemSchemasDisable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Disable a system schema. — systemSchemasDisable","text":"","code":"systemSchemasDisable(client, metastore_id, schema_name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/systemSchemasDisable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Disable a system schema. — systemSchemasDisable","text":"client Required. Instance DatabricksClient() metastore_id Required. metastore ID system schema lives. schema_name Required. Full name system schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/systemSchemasEnable.html","id":null,"dir":"Reference","previous_headings":"","what":"Enable a system schema. — systemSchemasEnable","title":"Enable a system schema. — systemSchemasEnable","text":"Enables system schema adds system catalog. caller must account admin metastore admin.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/systemSchemasEnable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enable a system schema. — systemSchemasEnable","text":"","code":"systemSchemasEnable(client, metastore_id, schema_name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/systemSchemasEnable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enable a system schema. — systemSchemasEnable","text":"client Required. Instance DatabricksClient() metastore_id Required. metastore ID system schema lives. schema_name Required. Full name system schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/systemSchemasList.html","id":null,"dir":"Reference","previous_headings":"","what":"List system schemas. — systemSchemasList","title":"List system schemas. — systemSchemasList","text":"Gets array system schemas metastore. caller must account admin metastore admin.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/systemSchemasList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List system schemas. — systemSchemasList","text":"","code":"systemSchemasList(client, metastore_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/systemSchemasList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List system schemas. — systemSchemasList","text":"client Required. Instance DatabricksClient() metastore_id Required. ID metastore system schema resides.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/systemSchemasList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List system schemas. — systemSchemasList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tableConstraintsCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a table constraint. — tableConstraintsCreate","title":"Create a table constraint. — tableConstraintsCreate","text":"Creates new table constraint.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tableConstraintsCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a table constraint. — tableConstraintsCreate","text":"","code":"tableConstraintsCreate(client, full_name_arg, constraint)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tableConstraintsCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a table constraint. — tableConstraintsCreate","text":"client Required. Instance DatabricksClient() full_name_arg Required. full name table referenced constraint. constraint Required. table constraint, defined one following fields set: primary_key_constraint, foreign_key_constraint, named_table_constraint.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tableConstraintsCreate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a table constraint. — tableConstraintsCreate","text":"table constraint creation succeed, user must satisfy conditions: - user must USE_CATALOG privilege table's parent catalog, USE_SCHEMA privilege table's parent schema, owner table. - new constraint ForeignKeyConstraint, user must USE_CATALOG privilege referenced parent table's catalog, USE_SCHEMA privilege referenced parent table's schema, owner referenced parent table.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tableConstraintsDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a table constraint. — tableConstraintsDelete","title":"Delete a table constraint. — tableConstraintsDelete","text":"Deletes table constraint.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tableConstraintsDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a table constraint. — tableConstraintsDelete","text":"","code":"tableConstraintsDelete(client, full_name, constraint_name, cascade)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tableConstraintsDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a table constraint. — tableConstraintsDelete","text":"client Required. Instance DatabricksClient() full_name Required. Full name table referenced constraint. constraint_name Required. name constraint delete. cascade Required. true, try deleting child constraints current constraint.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tableConstraintsDelete.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Delete a table constraint. — tableConstraintsDelete","text":"table constraint deletion succeed, user must satisfy conditions: - user must USE_CATALOG privilege table's parent catalog, USE_SCHEMA privilege table's parent schema, owner table. - cascade argument true, user must following permissions child tables: USE_CATALOG privilege table's catalog, USE_SCHEMA privilege table's schema, owner table.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a table. — tablesDelete","title":"Delete a table. — tablesDelete","text":"Deletes table specified parent catalog schema. caller must owner parent catalog, USE_CATALOG privilege parent catalog owner parent schema, owner table USE_CATALOG privilege parent catalog USE_SCHEMA privilege parent schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a table. — tablesDelete","text":"","code":"tablesDelete(client, full_name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a table. — tablesDelete","text":"client Required. Instance DatabricksClient() full_name Required. Full name table.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a table. — tablesGet","title":"Get a table. — tablesGet","text":"Gets table metastore specific catalog schema. caller must metastore admin, owner table USE_CATALOG privilege parent catalog USE_SCHEMA privilege parent schema, owner table SELECT privilege well.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a table. — tablesGet","text":"","code":"tablesGet(client, full_name, include_delta_metadata = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a table. — tablesGet","text":"client Required. Instance DatabricksClient() full_name Required. Full name table. include_delta_metadata Whether delta metadata included response.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesList.html","id":null,"dir":"Reference","previous_headings":"","what":"List tables. — tablesList","title":"List tables. — tablesList","text":"Gets array tables current metastore parent catalog schema. caller must metastore admin owner (SELECT privilege ) table. latter case, caller must also owner USE_CATALOG privilege parent catalog USE_SCHEMA privilege parent schema. guarantee specific ordering elements array.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List tables. — tablesList","text":"","code":"tablesList(   client,   catalog_name,   schema_name,   include_delta_metadata = NULL,   max_results = NULL,   page_token = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List tables. — tablesList","text":"client Required. Instance DatabricksClient() catalog_name Required. Name parent catalog tables interest. schema_name Required. Parent schema tables. include_delta_metadata Whether delta metadata included response. max_results Maximum number tables return (page length). page_token Opaque token send next page results (pagination).","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List tables. — tablesList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesListSummaries.html","id":null,"dir":"Reference","previous_headings":"","what":"List table summaries. — tablesListSummaries","title":"List table summaries. — tablesListSummaries","text":"Gets array summaries tables schema catalog within metastore. table summaries returned either:","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesListSummaries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List table summaries. — tablesListSummaries","text":"","code":"tablesListSummaries(   client,   catalog_name,   max_results = NULL,   page_token = NULL,   schema_name_pattern = NULL,   table_name_pattern = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesListSummaries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List table summaries. — tablesListSummaries","text":"client Required. Instance DatabricksClient() catalog_name Required. Name parent catalog tables interest. max_results Maximum number tables return (page length). page_token Opaque token send next page results (pagination). schema_name_pattern sql LIKE pattern (% _) schema names. table_name_pattern sql LIKE pattern (% _) table names.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesListSummaries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List table summaries. — tablesListSummaries","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesListSummaries.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List table summaries. — tablesListSummaries","text":"summaries tables (within current metastore parent catalog schema), user metastore admin, : * summaries tables schemas (within current metastore parent catalog) user ownership SELECT privilege table ownership USE_SCHEMA privilege schema, provided user also ownership USE_CATALOG privilege parent catalog. guarantee specific ordering elements array.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a table owner. — tablesUpdate","title":"Update a table owner. — tablesUpdate","text":"Change owner table. caller must owner parent catalog, USE_CATALOG privilege parent catalog owner parent schema, owner table USE_CATALOG privilege parent catalog USE_SCHEMA privilege parent schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a table owner. — tablesUpdate","text":"","code":"tablesUpdate(client, full_name, owner = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tablesUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a table owner. — tablesUpdate","text":"client Required. Instance DatabricksClient() full_name Required. Full name table. owner","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementCreateOboToken.html","id":null,"dir":"Reference","previous_headings":"","what":"Create on-behalf token. — tokenManagementCreateOboToken","title":"Create on-behalf token. — tokenManagementCreateOboToken","text":"Creates token behalf service principal.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementCreateOboToken.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create on-behalf token. — tokenManagementCreateOboToken","text":"","code":"tokenManagementCreateOboToken(   client,   application_id,   lifetime_seconds,   comment = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementCreateOboToken.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create on-behalf token. — tokenManagementCreateOboToken","text":"client Required. Instance DatabricksClient() application_id Required. Application ID service principal. lifetime_seconds Required. number seconds token expires. comment Comment describes purpose token.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a token. — tokenManagementDelete","title":"Delete a token. — tokenManagementDelete","text":"Deletes token, specified ID.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a token. — tokenManagementDelete","text":"","code":"tokenManagementDelete(client, token_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a token. — tokenManagementDelete","text":"client Required. Instance DatabricksClient() token_id Required. ID token get.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get token info. — tokenManagementGet","title":"Get token info. — tokenManagementGet","text":"Gets information token, specified ID.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get token info. — tokenManagementGet","text":"","code":"tokenManagementGet(client, token_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get token info. — tokenManagementGet","text":"client Required. Instance DatabricksClient() token_id Required. ID token get.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementGetTokenPermissionLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Get token permission levels. — tokenManagementGetTokenPermissionLevels","title":"Get token permission levels. — tokenManagementGetTokenPermissionLevels","text":"Gets permission levels user can object.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementGetTokenPermissionLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get token permission levels. — tokenManagementGetTokenPermissionLevels","text":"","code":"tokenManagementGetTokenPermissionLevels(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementGetTokenPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get token permissions. — tokenManagementGetTokenPermissions","title":"Get token permissions. — tokenManagementGetTokenPermissions","text":"Gets permissions tokens. Tokens can inherit permissions root object.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementGetTokenPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get token permissions. — tokenManagementGetTokenPermissions","text":"","code":"tokenManagementGetTokenPermissions(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementList.html","id":null,"dir":"Reference","previous_headings":"","what":"List all tokens. — tokenManagementList","title":"List all tokens. — tokenManagementList","text":"Lists tokens associated specified workspace user.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List all tokens. — tokenManagementList","text":"","code":"tokenManagementList(client, created_by_id = NULL, created_by_username = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List all tokens. — tokenManagementList","text":"client Required. Instance DatabricksClient() created_by_id User ID user created token. created_by_username Username user created token.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List all tokens. — tokenManagementList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementSetTokenPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Set token permissions. — tokenManagementSetTokenPermissions","title":"Set token permissions. — tokenManagementSetTokenPermissions","text":"Sets permissions tokens. Tokens can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementSetTokenPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set token permissions. — tokenManagementSetTokenPermissions","text":"","code":"tokenManagementSetTokenPermissions(client, access_control_list = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementSetTokenPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set token permissions. — tokenManagementSetTokenPermissions","text":"client Required. Instance DatabricksClient() access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementUpdateTokenPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Update token permissions. — tokenManagementUpdateTokenPermissions","title":"Update token permissions. — tokenManagementUpdateTokenPermissions","text":"Updates permissions tokens. Tokens can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementUpdateTokenPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update token permissions. — tokenManagementUpdateTokenPermissions","text":"","code":"tokenManagementUpdateTokenPermissions(client, access_control_list = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokenManagementUpdateTokenPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update token permissions. — tokenManagementUpdateTokenPermissions","text":"client Required. Instance DatabricksClient() access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokensCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a user token. — tokensCreate","title":"Create a user token. — tokensCreate","text":"Creates returns token user. call made token authentication, creates token client ID authenticated token. user's token quota exceeded, call returns error QUOTA_EXCEEDED.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokensCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a user token. — tokensCreate","text":"","code":"tokensCreate(client, comment = NULL, lifetime_seconds = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokensCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a user token. — tokensCreate","text":"client Required. Instance DatabricksClient() comment Optional description attach token. lifetime_seconds lifetime token, seconds.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokensDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Revoke token. — tokensDelete","title":"Revoke token. — tokensDelete","text":"Revokes access token.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokensDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Revoke token. — tokensDelete","text":"","code":"tokensDelete(client, token_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokensDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Revoke token. — tokensDelete","text":"client Required. Instance DatabricksClient() token_id Required. ID token revoked.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokensDelete.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Revoke token. — tokensDelete","text":"token specified ID valid, call returns error RESOURCE_DOES_NOT_EXIST.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokensList.html","id":null,"dir":"Reference","previous_headings":"","what":"List tokens. — tokensList","title":"List tokens. — tokensList","text":"Lists valid tokens user-workspace pair.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokensList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List tokens. — tokensList","text":"","code":"tokensList(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/tokensList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List tokens. — tokensList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new user. — usersCreate","title":"Create a new user. — usersCreate","text":"Creates new user Databricks workspace. new user also added Databricks account.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new user. — usersCreate","text":"","code":"usersCreate(   client,   active = NULL,   display_name = NULL,   emails = NULL,   entitlements = NULL,   external_id = NULL,   groups = NULL,   id = NULL,   name = NULL,   roles = NULL,   user_name = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new user. — usersCreate","text":"client Required. Instance DatabricksClient() active user active. display_name String represents concatenation given family names. emails emails associated Databricks user. entitlements  external_id  groups  id Databricks user ID. name  roles  user_name Email address Databricks user.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a user. — usersDelete","title":"Delete a user. — usersDelete","text":"Deletes user. Deleting user Databricks workspace also removes objects associated user.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a user. — usersDelete","text":"","code":"usersDelete(client, id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a user. — usersDelete","text":"client Required. Instance DatabricksClient() id Required. Unique ID user Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get user details. — usersGet","title":"Get user details. — usersGet","text":"Gets information specific user Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get user details. — usersGet","text":"","code":"usersGet(client, id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get user details. — usersGet","text":"client Required. Instance DatabricksClient() id Required. Unique ID user Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersGetPasswordPermissionLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Get password permission levels. — usersGetPasswordPermissionLevels","title":"Get password permission levels. — usersGetPasswordPermissionLevels","text":"Gets permission levels user can object.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersGetPasswordPermissionLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get password permission levels. — usersGetPasswordPermissionLevels","text":"","code":"usersGetPasswordPermissionLevels(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersGetPasswordPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get password permissions. — usersGetPasswordPermissions","title":"Get password permissions. — usersGetPasswordPermissions","text":"Gets permissions passwords. Passwords can inherit permissions root object.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersGetPasswordPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get password permissions. — usersGetPasswordPermissions","text":"","code":"usersGetPasswordPermissions(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersList.html","id":null,"dir":"Reference","previous_headings":"","what":"List users. — usersList","title":"List users. — usersList","text":"Gets details users associated Databricks workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List users. — usersList","text":"","code":"usersList(   client,   attributes = NULL,   count = NULL,   excluded_attributes = NULL,   filter = NULL,   sort_by = NULL,   sort_order = NULL,   start_index = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List users. — usersList","text":"client Required. Instance DatabricksClient() attributes Comma-separated list attributes return response. count Desired number results per page. excluded_attributes Comma-separated list attributes exclude response. filter Query results filtered. sort_by Attribute sort results. sort_order order sort results. start_index Specifies index first result.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List users. — usersList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersPatch.html","id":null,"dir":"Reference","previous_headings":"","what":"Update user details. — usersPatch","title":"Update user details. — usersPatch","text":"Partially updates user resource applying supplied operations specific user attributes.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersPatch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update user details. — usersPatch","text":"","code":"usersPatch(client, id, operations = NULL, schema = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersPatch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update user details. — usersPatch","text":"client Required. Instance DatabricksClient() id Required. Unique ID user Databricks workspace. operations  schema schema patch request.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersSetPasswordPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Set password permissions. — usersSetPasswordPermissions","title":"Set password permissions. — usersSetPasswordPermissions","text":"Sets permissions passwords. Passwords can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersSetPasswordPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set password permissions. — usersSetPasswordPermissions","text":"","code":"usersSetPasswordPermissions(client, access_control_list = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersSetPasswordPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set password permissions. — usersSetPasswordPermissions","text":"client Required. Instance DatabricksClient() access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace a user. — usersUpdate","title":"Replace a user. — usersUpdate","text":"Replaces user's information data supplied request.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace a user. — usersUpdate","text":"","code":"usersUpdate(   client,   id,   active = NULL,   display_name = NULL,   emails = NULL,   entitlements = NULL,   external_id = NULL,   groups = NULL,   name = NULL,   roles = NULL,   user_name = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace a user. — usersUpdate","text":"client Required. Instance DatabricksClient() id Databricks user ID. active user active. display_name String represents concatenation given family names. emails emails associated Databricks user. entitlements  external_id  groups  name  roles  user_name Email address Databricks user.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersUpdatePasswordPermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Update password permissions. — usersUpdatePasswordPermissions","title":"Update password permissions. — usersUpdatePasswordPermissions","text":"Updates permissions passwords. Passwords can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersUpdatePasswordPermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update password permissions. — usersUpdatePasswordPermissions","text":"","code":"usersUpdatePasswordPermissions(client, access_control_list = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/usersUpdatePasswordPermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update password permissions. — usersUpdatePasswordPermissions","text":"client Required. Instance DatabricksClient() access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Volume. — volumesCreate","title":"Create a Volume. — volumesCreate","text":"Creates new volume.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Volume. — volumesCreate","text":"","code":"volumesCreate(   client,   catalog_name,   name,   schema_name,   volume_type,   comment = NULL,   storage_location = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Volume. — volumesCreate","text":"client Required. Instance DatabricksClient() catalog_name Required. name catalog schema volume . name Required. name volume. schema_name Required. name schema volume . volume_type Required. comment comment attached volume. storage_location storage location cloud.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesCreate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Volume. — volumesCreate","text":"user create either external volume managed volume. external volume created specified external location, managed volume located default location specified parent schema, parent catalog, Metastore. volume creation succeed, user must satisfy following conditions: - caller must metastore admin, owner parent catalog schema, USE_CATALOG privilege parent catalog USE_SCHEMA privilege parent schema. - caller must CREATE VOLUME privilege parent schema. external volume, following conditions also need satisfy - caller must CREATE EXTERNAL VOLUME privilege external location. - tables, volumes existing specified storage location. - specified storage location location tables, volumes, catalogs schemas.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a Volume. — volumesDelete","title":"Delete a Volume. — volumesDelete","text":"Deletes volume specified parent catalog schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a Volume. — volumesDelete","text":"","code":"volumesDelete(client, full_name_arg)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a Volume. — volumesDelete","text":"client Required. Instance DatabricksClient() full_name_arg Required. three-level (fully qualified) name volume.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesDelete.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Delete a Volume. — volumesDelete","text":"caller must metastore admin owner volume. latter case, caller must also owner USE_CATALOG privilege parent catalog USE_SCHEMA privilege parent schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesList.html","id":null,"dir":"Reference","previous_headings":"","what":"List Volumes. — volumesList","title":"List Volumes. — volumesList","text":"Gets array volumes current metastore parent catalog schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List Volumes. — volumesList","text":"","code":"volumesList(client, catalog_name, schema_name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List Volumes. — volumesList","text":"client Required. Instance DatabricksClient() catalog_name Required. identifier catalog. schema_name Required. identifier schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List Volumes. — volumesList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesList.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"List Volumes. — volumesList","text":"returned volumes filtered based privileges calling user. example, metastore admin able list volumes. regular user needs owner READ VOLUME privilege volume recieve volumes response. latter case, caller must also owner USE_CATALOG privilege parent catalog USE_SCHEMA privilege parent schema. guarantee specific ordering elements array.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesRead.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a Volume. — volumesRead","title":"Get a Volume. — volumesRead","text":"Gets volume metastore specific catalog schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesRead.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a Volume. — volumesRead","text":"","code":"volumesRead(client, full_name_arg)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesRead.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a Volume. — volumesRead","text":"client Required. Instance DatabricksClient() full_name_arg Required. three-level (fully qualified) name volume.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesRead.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get a Volume. — volumesRead","text":"caller must metastore admin owner (READ VOLUME privilege ) volume. latter case, caller must also owner USE_CATALOG privilege parent catalog USE_SCHEMA privilege parent schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a Volume. — volumesUpdate","title":"Update a Volume. — volumesUpdate","text":"Updates specified volume specified parent catalog schema.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a Volume. — volumesUpdate","text":"","code":"volumesUpdate(client, full_name_arg, comment = NULL, name = NULL, owner = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a Volume. — volumesUpdate","text":"client Required. Instance DatabricksClient() full_name_arg Required. three-level (fully qualified) name volume. comment comment attached volume. name name volume. owner identifier user owns volume.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/volumesUpdate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update a Volume. — volumesUpdate","text":"caller must metastore admin owner volume. latter case, caller must also owner USE_CATALOG privilege parent catalog USE_SCHEMA privilege parent schema. Currently name, owner comment volume updated.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesCreate.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a warehouse. — warehousesCreate","title":"Create a warehouse. — warehousesCreate","text":"long-running operation, blocks Warehouses Databricks reach RUNNING state timeout 20 minutes, can change via timeout parameter. default, state Databricks Warehouses reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesCreate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a warehouse. — warehousesCreate","text":"","code":"warehousesCreate(   client,   auto_stop_mins = NULL,   channel = NULL,   cluster_size = NULL,   creator_name = NULL,   enable_photon = NULL,   enable_serverless_compute = NULL,   instance_profile_arn = NULL,   max_num_clusters = NULL,   min_num_clusters = NULL,   name = NULL,   spot_instance_policy = NULL,   tags = NULL,   warehouse_type = NULL,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesCreate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a warehouse. — warehousesCreate","text":"client Required. Instance DatabricksClient() auto_stop_mins amount time minutes SQL warehouse must idle (.e., RUNNING queries) automatically stopped. channel Channel Details. cluster_size Size clusters allocated warehouse. creator_name warehouse creator name. enable_photon Configures whether warehouse use Photon optimized clusters. enable_serverless_compute Configures whether warehouse use serverless compute. instance_profile_arn Deprecated. max_num_clusters Maximum number clusters autoscaler create handle concurrent queries. min_num_clusters Minimum number available clusters maintained SQL warehouse. name Logical name cluster. spot_instance_policy Configurations whether warehouse use spot instances. tags set key-value pairs tagged resources (e.g., AWS instances EBS volumes) associated SQL warehouse. warehouse_type Warehouse type: PRO CLASSIC.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesCreate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a warehouse. — warehousesCreate","text":"Creates new SQL warehouse.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a warehouse. — warehousesDelete","title":"Delete a warehouse. — warehousesDelete","text":"Deletes SQL warehouse.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a warehouse. — warehousesDelete","text":"","code":"warehousesDelete(client, id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a warehouse. — warehousesDelete","text":"client Required. Instance DatabricksClient() id Required. Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesEdit.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a warehouse. — warehousesEdit","title":"Update a warehouse. — warehousesEdit","text":"long-running operation, blocks Warehouses Databricks reach RUNNING state timeout 20 minutes, can change via timeout parameter. default, state Databricks Warehouses reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesEdit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a warehouse. — warehousesEdit","text":"","code":"warehousesEdit(   client,   id,   auto_stop_mins = NULL,   channel = NULL,   cluster_size = NULL,   creator_name = NULL,   enable_photon = NULL,   enable_serverless_compute = NULL,   instance_profile_arn = NULL,   max_num_clusters = NULL,   min_num_clusters = NULL,   name = NULL,   spot_instance_policy = NULL,   tags = NULL,   warehouse_type = NULL,   timeout = 20,   callback = cli_reporter )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesEdit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a warehouse. — warehousesEdit","text":"client Required. Instance DatabricksClient() id Required. Required. auto_stop_mins amount time minutes SQL warehouse must idle (.e., RUNNING queries) automatically stopped. channel Channel Details. cluster_size Size clusters allocated warehouse. creator_name warehouse creator name. enable_photon Configures whether warehouse use Photon optimized clusters. enable_serverless_compute Configures whether warehouse use serverless compute. instance_profile_arn Deprecated. max_num_clusters Maximum number clusters autoscaler create handle concurrent queries. min_num_clusters Minimum number available clusters maintained SQL warehouse. name Logical name cluster. spot_instance_policy Configurations whether warehouse use spot instances. tags set key-value pairs tagged resources (e.g., AWS instances EBS volumes) associated SQL warehouse. warehouse_type Warehouse type: PRO CLASSIC.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesEdit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update a warehouse. — warehousesEdit","text":"Updates configuration SQL warehouse.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get warehouse info. — warehousesGet","title":"Get warehouse info. — warehousesGet","text":"Gets information single SQL warehouse.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get warehouse info. — warehousesGet","text":"","code":"warehousesGet(client, id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get warehouse info. — warehousesGet","text":"client Required. Instance DatabricksClient() id Required. Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesGetWarehousePermissionLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Get SQL warehouse permission levels. — warehousesGetWarehousePermissionLevels","title":"Get SQL warehouse permission levels. — warehousesGetWarehousePermissionLevels","text":"Gets permission levels user can object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesGetWarehousePermissionLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get SQL warehouse permission levels. — warehousesGetWarehousePermissionLevels","text":"","code":"warehousesGetWarehousePermissionLevels(client, warehouse_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesGetWarehousePermissionLevels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get SQL warehouse permission levels. — warehousesGetWarehousePermissionLevels","text":"client Required. Instance DatabricksClient() warehouse_id Required. SQL warehouse get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesGetWarehousePermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get SQL warehouse permissions. — warehousesGetWarehousePermissions","title":"Get SQL warehouse permissions. — warehousesGetWarehousePermissions","text":"Gets permissions SQL warehouse. SQL warehouses can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesGetWarehousePermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get SQL warehouse permissions. — warehousesGetWarehousePermissions","text":"","code":"warehousesGetWarehousePermissions(client, warehouse_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesGetWarehousePermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get SQL warehouse permissions. — warehousesGetWarehousePermissions","text":"client Required. Instance DatabricksClient() warehouse_id Required. SQL warehouse get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesGetWorkspaceWarehouseConfig.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the workspace configuration. — warehousesGetWorkspaceWarehouseConfig","title":"Get the workspace configuration. — warehousesGetWorkspaceWarehouseConfig","text":"Gets workspace level configuration shared SQL warehouses workspace.#'","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesGetWorkspaceWarehouseConfig.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the workspace configuration. — warehousesGetWorkspaceWarehouseConfig","text":"","code":"warehousesGetWorkspaceWarehouseConfig(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesList.html","id":null,"dir":"Reference","previous_headings":"","what":"List warehouses. — warehousesList","title":"List warehouses. — warehousesList","text":"Lists SQL warehouses user manager permissions .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List warehouses. — warehousesList","text":"","code":"warehousesList(client, run_as_user_id = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List warehouses. — warehousesList","text":"client Required. Instance DatabricksClient() run_as_user_id Service Principal used fetch list warehouses.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List warehouses. — warehousesList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesSetWarehousePermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Set SQL warehouse permissions. — warehousesSetWarehousePermissions","title":"Set SQL warehouse permissions. — warehousesSetWarehousePermissions","text":"Sets permissions SQL warehouse. SQL warehouses can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesSetWarehousePermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set SQL warehouse permissions. — warehousesSetWarehousePermissions","text":"","code":"warehousesSetWarehousePermissions(   client,   warehouse_id,   access_control_list = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesSetWarehousePermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set SQL warehouse permissions. — warehousesSetWarehousePermissions","text":"client Required. Instance DatabricksClient() warehouse_id Required. SQL warehouse get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesSetWorkspaceWarehouseConfig.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the workspace configuration. — warehousesSetWorkspaceWarehouseConfig","title":"Set the workspace configuration. — warehousesSetWorkspaceWarehouseConfig","text":"Sets workspace level configuration shared SQL warehouses workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesSetWorkspaceWarehouseConfig.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the workspace configuration. — warehousesSetWorkspaceWarehouseConfig","text":"","code":"warehousesSetWorkspaceWarehouseConfig(   client,   channel = NULL,   config_param = NULL,   data_access_config = NULL,   enabled_warehouse_types = NULL,   global_param = NULL,   google_service_account = NULL,   instance_profile_arn = NULL,   security_policy = NULL,   sql_configuration_parameters = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesSetWorkspaceWarehouseConfig.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the workspace configuration. — warehousesSetWorkspaceWarehouseConfig","text":"client Required. Instance DatabricksClient() channel Optional: Channel selection details. config_param Deprecated: Use sql_configuration_parameters. data_access_config Spark confs external hive metastore configuration JSON serialized size must less <= 512K. enabled_warehouse_types List Warehouse Types allowed workspace (limits allowed value type field CreateWarehouse EditWarehouse). global_param Deprecated: Use sql_configuration_parameters. google_service_account GCP : Google Service Account used pass cluster access Google Cloud Storage. instance_profile_arn AWS : Instance profile used pass IAM role cluster. security_policy Security policy warehouses. sql_configuration_parameters SQL configuration parameters.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesStart.html","id":null,"dir":"Reference","previous_headings":"","what":"Start a warehouse. — warehousesStart","title":"Start a warehouse. — warehousesStart","text":"long-running operation, blocks Warehouses Databricks reach RUNNING state timeout 20 minutes, can change via timeout parameter. default, state Databricks Warehouses reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesStart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Start a warehouse. — warehousesStart","text":"","code":"warehousesStart(client, id, timeout = 20, callback = cli_reporter)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesStart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Start a warehouse. — warehousesStart","text":"client Required. Instance DatabricksClient() id Required. Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesStart.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Start a warehouse. — warehousesStart","text":"Starts SQL warehouse.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesStop.html","id":null,"dir":"Reference","previous_headings":"","what":"Stop a warehouse. — warehousesStop","title":"Stop a warehouse. — warehousesStop","text":"long-running operation, blocks Warehouses Databricks reach STOPPED state timeout 20 minutes, can change via timeout parameter. default, state Databricks Warehouses reported console. can change behavior changing callback parameter.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesStop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stop a warehouse. — warehousesStop","text":"","code":"warehousesStop(client, id, timeout = 20, callback = cli_reporter)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesStop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stop a warehouse. — warehousesStop","text":"client Required. Instance DatabricksClient() id Required. Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesStop.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Stop a warehouse. — warehousesStop","text":"Stops SQL warehouse.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesUpdateWarehousePermissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Update SQL warehouse permissions. — warehousesUpdateWarehousePermissions","title":"Update SQL warehouse permissions. — warehousesUpdateWarehousePermissions","text":"Updates permissions SQL warehouse. SQL warehouses can inherit permissions root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesUpdateWarehousePermissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update SQL warehouse permissions. — warehousesUpdateWarehousePermissions","text":"","code":"warehousesUpdateWarehousePermissions(   client,   warehouse_id,   access_control_list = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/warehousesUpdateWarehousePermissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update SQL warehouse permissions. — warehousesUpdateWarehousePermissions","text":"client Required. Instance DatabricksClient() warehouse_id Required. SQL warehouse get manage permissions. access_control_list","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceBindingsGet.html","id":null,"dir":"Reference","previous_headings":"","what":"Get catalog workspace bindings. — workspaceBindingsGet","title":"Get catalog workspace bindings. — workspaceBindingsGet","text":"Gets workspace bindings catalog. caller must metastore admin owner catalog.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceBindingsGet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get catalog workspace bindings. — workspaceBindingsGet","text":"","code":"workspaceBindingsGet(client, name)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceBindingsGet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get catalog workspace bindings. — workspaceBindingsGet","text":"client Required. Instance DatabricksClient() name Required. name catalog.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceBindingsUpdate.html","id":null,"dir":"Reference","previous_headings":"","what":"Update catalog workspace bindings. — workspaceBindingsUpdate","title":"Update catalog workspace bindings. — workspaceBindingsUpdate","text":"Updates workspace bindings catalog. caller must metastore admin owner catalog.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceBindingsUpdate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update catalog workspace bindings. — workspaceBindingsUpdate","text":"","code":"workspaceBindingsUpdate(   client,   name,   assign_workspaces = NULL,   unassign_workspaces = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceBindingsUpdate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update catalog workspace bindings. — workspaceBindingsUpdate","text":"client Required. Instance DatabricksClient() name Required. name catalog. assign_workspaces list workspace IDs. unassign_workspaces list workspace IDs.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceConfGetStatus.html","id":null,"dir":"Reference","previous_headings":"","what":"Check configuration status. — workspaceConfGetStatus","title":"Check configuration status. — workspaceConfGetStatus","text":"Gets configuration status workspace.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceConfGetStatus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check configuration status. — workspaceConfGetStatus","text":"","code":"workspaceConfGetStatus(client, keys)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceConfGetStatus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check configuration status. — workspaceConfGetStatus","text":"client Required. Instance DatabricksClient() keys Required.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceConfSetStatus.html","id":null,"dir":"Reference","previous_headings":"","what":"Enable/disable features. — workspaceConfSetStatus","title":"Enable/disable features. — workspaceConfSetStatus","text":"Sets configuration status workspace, including enabling disabling .","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceConfSetStatus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enable/disable features. — workspaceConfSetStatus","text":"","code":"workspaceConfSetStatus(client)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceConfSetStatus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enable/disable features. — workspaceConfSetStatus","text":"client Required. Instance DatabricksClient()","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceDelete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a workspace object. — workspaceDelete","title":"Delete a workspace object. — workspaceDelete","text":"Deletes object directory (optionally recursively deletes objects directory). * path exist, call returns error RESOURCE_DOES_NOT_EXIST. * path non-empty directory recursive set false, call returns error DIRECTORY_NOT_EMPTY.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceDelete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a workspace object. — workspaceDelete","text":"","code":"workspaceDelete(client, path, recursive = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceDelete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a workspace object. — workspaceDelete","text":"client Required. Instance DatabricksClient() path Required. absolute path notebook directory. recursive flag specifies whether delete object recursively.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceDelete.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Delete a workspace object. — workspaceDelete","text":"Object deletion undone deleting directory recursively atomic.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceExport.html","id":null,"dir":"Reference","previous_headings":"","what":"Export a workspace object. — workspaceExport","title":"Export a workspace object. — workspaceExport","text":"Exports object contents entire directory.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceExport.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export a workspace object. — workspaceExport","text":"","code":"workspaceExport(client, path, format = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceExport.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export a workspace object. — workspaceExport","text":"client Required. Instance DatabricksClient() path Required. absolute path object directory. format specifies format exported file.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceExport.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Export a workspace object. — workspaceExport","text":"path exist, call returns error RESOURCE_DOES_NOT_EXIST. exported data exceed size limit, call returns MAX_NOTEBOOK_SIZE_EXCEEDED. Currently, API support exporting library.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceGetStatus.html","id":null,"dir":"Reference","previous_headings":"","what":"Get status. — workspaceGetStatus","title":"Get status. — workspaceGetStatus","text":"Gets status object directory. path exist, call returns error RESOURCE_DOES_NOT_EXIST.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceGetStatus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get status. — workspaceGetStatus","text":"","code":"workspaceGetStatus(client, path)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceGetStatus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get status. — workspaceGetStatus","text":"client Required. Instance DatabricksClient() path Required. absolute path notebook directory.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceImport.html","id":null,"dir":"Reference","previous_headings":"","what":"Import a workspace object. — workspaceImport","title":"Import a workspace object. — workspaceImport","text":"Imports workspace object (example, notebook file) contents entire directory. path already exists overwrite set false, call returns error RESOURCE_ALREADY_EXISTS. One can use DBC format import directory.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceImport.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import a workspace object. — workspaceImport","text":"","code":"workspaceImport(   client,   path,   content = NULL,   format = NULL,   language = NULL,   overwrite = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceImport.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import a workspace object. — workspaceImport","text":"client Required. Instance DatabricksClient() path Required. absolute path object directory. content base64-encoded content. format specifies format file imported. language language object. overwrite flag specifies whether overwrite existing object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceList.html","id":null,"dir":"Reference","previous_headings":"","what":"List contents. — workspaceList","title":"List contents. — workspaceList","text":"Lists contents directory, object directory. input path exist, call returns error RESOURCE_DOES_NOT_EXIST.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceList.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List contents. — workspaceList","text":"","code":"workspaceList(client, path, notebooks_modified_after = NULL)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceList.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List contents. — workspaceList","text":"client Required. Instance DatabricksClient() path Required. absolute path notebook directory. notebooks_modified_after UTC timestamp milliseconds.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceList.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List contents. — workspaceList","text":"data.frame response pages.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceMkdirs.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a directory. — workspaceMkdirs","title":"Create a directory. — workspaceMkdirs","text":"Creates specified directory (necessary parent directories exist). object (directory) prefix input path, call returns error RESOURCE_ALREADY_EXISTS.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceMkdirs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a directory. — workspaceMkdirs","text":"","code":"workspaceMkdirs(client, path)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceMkdirs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a directory. — workspaceMkdirs","text":"client Required. Instance DatabricksClient() path Required. absolute path directory.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceMkdirs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a directory. — workspaceMkdirs","text":"Note operation fails may succeeded creating necessary parent directories.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspacePermissionLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Get workspace object permission levels. — workspacePermissionLevels","title":"Get workspace object permission levels. — workspacePermissionLevels","text":"Gets permission levels user can object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspacePermissionLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get workspace object permission levels. — workspacePermissionLevels","text":"","code":"workspacePermissionLevels(client, workspace_object_type, workspace_object_id)"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspacePermissionLevels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get workspace object permission levels. — workspacePermissionLevels","text":"client Required. Instance DatabricksClient() workspace_object_type Required. workspace object type get manage permissions. workspace_object_id Required. workspace object get manage permissions.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceWorkspaceObjectId.html","id":null,"dir":"Reference","previous_headings":"","what":"Update workspace object permissions. — workspaceWorkspaceObjectId","title":"Update workspace object permissions. — workspaceWorkspaceObjectId","text":"Updates permissions workspace object. Workspace objects can inherit permissions parent objects root object.","code":""},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceWorkspaceObjectId.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update workspace object permissions. — workspaceWorkspaceObjectId","text":"","code":"workspaceWorkspaceObjectId(   client,   workspace_object_type,   workspace_object_id,   access_control_list = NULL )"},{"path":"https://databrickslabs.github.io/databricks-sdk-r/reference/workspaceWorkspaceObjectId.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update workspace object permissions. — workspaceWorkspaceObjectId","text":"client Required. Instance DatabricksClient() workspace_object_type Required. workspace object type get manage permissions. workspace_object_id Required. workspace object get manage permissions. access_control_list","code":""}]
